{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"SUMMARY/","title":"SUMMARY","text":"<ul> <li>Temporal Predictions Kit</li> <li>Release Notes</li> </ul>"},{"location":"","title":"tpk (Temporal Predictions Kit)","text":"<p>A collection of tools, models and functionalities for hanling timeseries datasets</p> <p> </p>"},{"location":"#installation","title":"Installation","text":"<p>tpk requires Python 3.7 or newer, and the easiest way to install it is via <code>pip</code>:</p> <pre><code>pip install tpk\n</code></pre>"},{"location":"#simple-example","title":"Simple Example","text":"<p>To illustrate how to use tpk, we train a model and make predictions using the airpassengers dataset. The dataset consists of a single time series of monthly passenger numbers between 1949 and 1960. We train the model on the first nine years and make predictions for the remaining three years.</p> <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom gluonts.dataset.pandas import PandasDataset\nfrom gluonts.dataset.split import split\nfrom gluonts.torch import DeepAREstimator\nfrom tpk.torch import TPKEstimator\n\n# Load data from a CSV file into a PandasDataset\ndf = pd.read_csv(\n    \"https://raw.githubusercontent.com/AileenNielsen/\"\n    \"TimeSeriesAnalysisWithPython/master/data/AirPassengers.csv\",\n    index_col=0,\n    parse_dates=True,\n)\ndataset = PandasDataset(df, target=\"#Passengers\")\n\n# Split the data for training and testing\ntraining_data, test_gen = split(dataset, offset=-36)\ntest_data = test_gen.generate_instances(prediction_length=12, windows=3)\n\n# Train the model and make predictions\nmodel = TPKEstimator(\n    prediction_length=12, freq=\"M\", trainer_kwargs={\"max_epochs\": 5}\n).train(training_data)\n\nforecasts = list(model.predict(test_data.input))\n\n# Plot predictions\nplt.plot(df[\"1954\":], color=\"black\")\nfor forecast in forecasts:\n  forecast.plot()\nplt.legend([\"True values\"], loc=\"upper left\", fontsize=\"xx-large\")\nplt.show()\n</code></pre>"},{"location":"#todo-replace-me","title":"todo: replace me","text":"<p>Note, the forecasts are displayed in terms of a probability distribution and the shaded areas represent the 50% and 90% prediction intervals.</p>"},{"location":"#contributing","title":"Contributing","text":"<p>If you wish to contribute to the project, please refer to our contribution guidelines.</p>"},{"location":"#citing","title":"Citing","text":"<p>If you use tpk in a scientific publication, we encourage you to add the following references to the related papers, in addition to any model-specific references that are relevant for your work:</p>"},{"location":"#links","title":"Links","text":""},{"location":"#documentation","title":"Documentation","text":"<ul> <li>Documentation</li> </ul>"},{"location":"#stay-in-touch","title":"Stay in touch","text":"<p>Please show your support and stay in touch by:</p> <ul> <li>giving our GitHub repository a star, and</li> <li>joining our Discord server</li> </ul> <p>Your support helps us to stay in touch with you and encourages us to continue developing and improving the framework. Thank you for your support!</p>"},{"location":"#contributors","title":"Contributors","text":"<p>Thanks to all of these amazing people who made the project better!</p> <p> </p>"},{"location":"release/","title":"Release Notes","text":""},{"location":"release/#001dev","title":"0.0.1dev","text":""},{"location":"release/#whats-changed","title":"What's Changed","text":"<ul> <li>Refactoring by @davorrunje in https://github.com/airtai/tpk/pull/8</li> <li>2 feature import timeseries datasets by @sternakt in https://github.com/airtai/tpk/pull/7</li> <li>Bump mkdocs-glightbox from 0.3.4 to 0.3.5 by @dependabot in https://github.com/airtai/tpk/pull/6</li> <li>Bump semgrep from 1.48.0 to 1.50.0 by @dependabot in https://github.com/airtai/tpk/pull/5</li> <li>Bump ruff from 0.1.5 to 0.1.6 by @dependabot in https://github.com/airtai/tpk/pull/4</li> <li>Bump dirty-equals from 0.6.0 to 0.7.1 by @dependabot in https://github.com/airtai/tpk/pull/1</li> <li>Hypervalidation by @sternakt in https://github.com/airtai/tpk/pull/15</li> <li>Bump mypy from 1.7.0 to 1.7.1 by @dependabot in https://github.com/airtai/tpk/pull/14</li> <li>16 rename temporal data kit to temporal prediction kit by @sternakt in https://github.com/airtai/tpk/pull/17</li> <li>Bump ruff from 0.1.6 to 0.1.7 by @dependabot in https://github.com/airtai/tpk/pull/18</li> <li>Bump bandit from 1.7.5 to 1.7.6 by @dependabot in https://github.com/airtai/tpk/pull/20</li> <li>Bump actions/setup-python from 4 to 5 by @dependabot in https://github.com/airtai/tpk/pull/23</li> <li>chore: add pypi publish by @davorrunje in https://github.com/airtai/tpk/pull/25</li> </ul>"},{"location":"release/#new-contributors","title":"New Contributors","text":"<ul> <li>@davorrunje made their first contribution in https://github.com/airtai/tpk/pull/8</li> <li>@sternakt made their first contribution in https://github.com/airtai/tpk/pull/7</li> <li>@dependabot made their first contribution in https://github.com/airtai/tpk/pull/6</li> </ul> <p>Full Changelog: https://github.com/airtai/tpk/commits/0.0.1dev</p>"},{"location":"release/#000","title":"0.0.0","text":"<p>Initial empty release.</p>"},{"location":"api/tpk/MyEstimator/","title":"MyEstimator","text":""},{"location":"api/tpk/MyEstimator/#tpk.MyEstimator","title":"tpk.MyEstimator","text":"<pre><code>MyEstimator(*, model_cls: Type[LightningModule], freq: str, prediction_length: int, epochs: int, context_length: Optional[int] = None, n_block: int = 2, hidden_size: int = 128, weight_decay: float = 1e-08, dropout_rate: float = 0.1, patience: int = 10, num_feat_dynamic_real: int = 0, disable_future_feature: bool = False, num_feat_static_cat: int = 0, num_feat_static_real: int = 0, cardinality: Optional[List[int]] = None, embedding_dimension: Optional[List[int]] = None, distr_output: Optional[DistributionOutput] = None, loss: Optional[DistributionLoss] = None, scaling: bool = True, time_features: Optional[List[TimeFeature]] = None, batch_size: int = 32, num_batches_per_epoch: int = 50, trainer_kwargs: Optional[Dict[str, Any]] = None, train_sampler: Optional[InstanceSampler] = None, validation_sampler: Optional[InstanceSampler] = None)\n</code></pre> <p>             Bases: <code>PyTorchLightningEstimator</code></p> <p>Estimator class to train a TPK model.</p> <p>This class is uses the model defined in <code>TPKModel</code>, and wraps it into a <code>MyLightningModule</code> for training purposes: training is performed using PyTorch Lightning's <code>pl.Trainer</code> class.</p>"},{"location":"api/tpk/MyEstimator/#tpk.MyEstimator--parameters","title":"Parameters","text":"<p>freq     Frequency of the data to train on and predict. prediction_length     Length of the prediction horizon. context_length     Number of steps to unroll the RNN for before computing predictions     (default: None, in which case context_length = prediction_length). n_block     Number of TPK blocks (default: 2). hidden_size     Number of hidden size for each layer (default: 128). weight_decay     Weight decay regularization parameter (default: <code>1e-8</code>). dropout_rate     Dropout regularization parameter (default: 0.1). patience     Patience parameter for learning rate scheduler. num_feat_dynamic_real     Number of dynamic real features in the data (default: 0). num_feat_static_real     Number of static real features in the data (default: 0). num_feat_static_cat     Number of static categorical features in the data (default: 0). cardinality     Number of values of each categorical feature.     This must be set if <code>num_feat_static_cat &gt; 0</code> (default: None). embedding_dimension     Dimension of the embeddings for categorical features     (default: <code>[min(50, (cat+1)//2) for cat in cardinality]</code>). distr_output     Distribution to use to evaluate observations and sample predictions     (default: StudentTOutput()). loss     Loss to be optimized during training     (default: <code>NegativeLogLikelihood()</code>). scaling     Whether to automatically scale the target values (default: true). time_features     List of time features, from :py:mod:<code>gluonts.time_feature</code>, to use as     inputs of the RNN in addition to the provided data (default: None,     in which case these are automatically determined based on freq). batch_size     The size of the batches to be used for training (default: 32). num_batches_per_epoch     Number of batches to be processed in each training epoch     (default: 50). trainer_kwargs     Additional arguments to provide to <code>pl.Trainer</code> for construction. train_sampler     Controls the sampling of windows during training. validation_sampler     Controls the sampling of windows during validation.</p> Source code in <code>tpk/torch/estimator.py</code> <pre><code>@validated()  # type: ignore\ndef __init__(\n    self,\n    *,\n    model_cls: Type[LightningModule],\n    freq: str,\n    prediction_length: int,\n    epochs: int,\n    context_length: Optional[int] = None,\n    n_block: int = 2,\n    hidden_size: int = 128,\n    weight_decay: float = 1e-8,\n    dropout_rate: float = 0.1,\n    patience: int = 10,\n    num_feat_dynamic_real: int = 0,\n    disable_future_feature: bool = False,\n    num_feat_static_cat: int = 0,\n    num_feat_static_real: int = 0,\n    cardinality: Optional[List[int]] = None,\n    embedding_dimension: Optional[List[int]] = None,\n    distr_output: Optional[DistributionOutput] = None,\n    loss: Optional[DistributionLoss] = None,\n    scaling: bool = True,\n    time_features: Optional[List[TimeFeature]] = None,\n    batch_size: int = 32,\n    num_batches_per_epoch: int = 50,\n    trainer_kwargs: Optional[Dict[str, Any]] = None,\n    train_sampler: Optional[InstanceSampler] = None,\n    validation_sampler: Optional[InstanceSampler] = None,\n) -&gt; None:\n    default_trainer_kwargs = {\n        \"max_epochs\": 100,\n        \"gradient_clip_val\": 10.0,\n    }\n    if trainer_kwargs is not None:\n        default_trainer_kwargs.update(trainer_kwargs)\n    super().__init__(trainer_kwargs=default_trainer_kwargs)\n\n    self.model_cls = model_cls\n    self.epochs = epochs\n    self.freq = freq\n    self.context_length = (\n        context_length if context_length is not None else prediction_length\n    )\n    self.prediction_length = prediction_length\n    self.patience = patience\n    self.distr_output = StudentTOutput() if distr_output is None else distr_output\n    self.loss = NegativeLogLikelihood() if loss is None else loss\n    self.n_block = n_block\n    self.hidden_size = hidden_size\n    self.weight_decay = weight_decay\n    self.dropout_rate = dropout_rate\n    self.num_feat_dynamic_real = num_feat_dynamic_real\n    self.disable_future_feature = disable_future_feature\n    self.num_feat_static_cat = num_feat_static_cat\n    self.num_feat_static_real = num_feat_static_real\n    self.cardinality = (\n        cardinality if cardinality and num_feat_static_cat &gt; 0 else [1]\n    )\n    self.embedding_dimension = embedding_dimension\n    self.scaling = scaling\n    self.time_features = (\n        time_features\n        if time_features is not None\n        else time_features_from_frequency_str(self.freq)\n    )\n\n    self.batch_size = batch_size\n    self.num_batches_per_epoch = num_batches_per_epoch\n\n    self.train_sampler = train_sampler or ExpectedNumInstanceSampler(\n        num_instances=1.0, min_future=prediction_length\n    )\n    self.validation_sampler = validation_sampler or ValidationSplitSampler(\n        min_future=prediction_length\n    )\n</code></pre>"},{"location":"api/tpk/MyEstimator/#tpk.MyEstimator.batch_size","title":"batch_size  <code>instance-attribute</code>","text":"<pre><code>batch_size = batch_size\n</code></pre>"},{"location":"api/tpk/MyEstimator/#tpk.MyEstimator.cardinality","title":"cardinality  <code>instance-attribute</code>","text":"<pre><code>cardinality = cardinality if cardinality and num_feat_static_cat &gt; 0 else [1]\n</code></pre>"},{"location":"api/tpk/MyEstimator/#tpk.MyEstimator.context_length","title":"context_length  <code>instance-attribute</code>","text":"<pre><code>context_length = context_length if context_length is not None else prediction_length\n</code></pre>"},{"location":"api/tpk/MyEstimator/#tpk.MyEstimator.disable_future_feature","title":"disable_future_feature  <code>instance-attribute</code>","text":"<pre><code>disable_future_feature = disable_future_feature\n</code></pre>"},{"location":"api/tpk/MyEstimator/#tpk.MyEstimator.distr_output","title":"distr_output  <code>instance-attribute</code>","text":"<pre><code>distr_output = StudentTOutput() if distr_output is None else distr_output\n</code></pre>"},{"location":"api/tpk/MyEstimator/#tpk.MyEstimator.dropout_rate","title":"dropout_rate  <code>instance-attribute</code>","text":"<pre><code>dropout_rate = dropout_rate\n</code></pre>"},{"location":"api/tpk/MyEstimator/#tpk.MyEstimator.embedding_dimension","title":"embedding_dimension  <code>instance-attribute</code>","text":"<pre><code>embedding_dimension = embedding_dimension\n</code></pre>"},{"location":"api/tpk/MyEstimator/#tpk.MyEstimator.epochs","title":"epochs  <code>instance-attribute</code>","text":"<pre><code>epochs = epochs\n</code></pre>"},{"location":"api/tpk/MyEstimator/#tpk.MyEstimator.freq","title":"freq  <code>instance-attribute</code>","text":"<pre><code>freq = freq\n</code></pre>"},{"location":"api/tpk/MyEstimator/#tpk.MyEstimator.hidden_size","title":"hidden_size  <code>instance-attribute</code>","text":"<pre><code>hidden_size = hidden_size\n</code></pre>"},{"location":"api/tpk/MyEstimator/#tpk.MyEstimator.loss","title":"loss  <code>instance-attribute</code>","text":"<pre><code>loss = NegativeLogLikelihood() if loss is None else loss\n</code></pre>"},{"location":"api/tpk/MyEstimator/#tpk.MyEstimator.model_cls","title":"model_cls  <code>instance-attribute</code>","text":"<pre><code>model_cls = model_cls\n</code></pre>"},{"location":"api/tpk/MyEstimator/#tpk.MyEstimator.n_block","title":"n_block  <code>instance-attribute</code>","text":"<pre><code>n_block = n_block\n</code></pre>"},{"location":"api/tpk/MyEstimator/#tpk.MyEstimator.num_batches_per_epoch","title":"num_batches_per_epoch  <code>instance-attribute</code>","text":"<pre><code>num_batches_per_epoch = num_batches_per_epoch\n</code></pre>"},{"location":"api/tpk/MyEstimator/#tpk.MyEstimator.num_feat_dynamic_real","title":"num_feat_dynamic_real  <code>instance-attribute</code>","text":"<pre><code>num_feat_dynamic_real = num_feat_dynamic_real\n</code></pre>"},{"location":"api/tpk/MyEstimator/#tpk.MyEstimator.num_feat_static_cat","title":"num_feat_static_cat  <code>instance-attribute</code>","text":"<pre><code>num_feat_static_cat = num_feat_static_cat\n</code></pre>"},{"location":"api/tpk/MyEstimator/#tpk.MyEstimator.num_feat_static_real","title":"num_feat_static_real  <code>instance-attribute</code>","text":"<pre><code>num_feat_static_real = num_feat_static_real\n</code></pre>"},{"location":"api/tpk/MyEstimator/#tpk.MyEstimator.patience","title":"patience  <code>instance-attribute</code>","text":"<pre><code>patience = patience\n</code></pre>"},{"location":"api/tpk/MyEstimator/#tpk.MyEstimator.prediction_length","title":"prediction_length  <code>instance-attribute</code>","text":"<pre><code>prediction_length = prediction_length\n</code></pre>"},{"location":"api/tpk/MyEstimator/#tpk.MyEstimator.scaling","title":"scaling  <code>instance-attribute</code>","text":"<pre><code>scaling = scaling\n</code></pre>"},{"location":"api/tpk/MyEstimator/#tpk.MyEstimator.time_features","title":"time_features  <code>instance-attribute</code>","text":"<pre><code>time_features = time_features if time_features is not None else time_features_from_frequency_str(self.freq)\n</code></pre>"},{"location":"api/tpk/MyEstimator/#tpk.MyEstimator.train_sampler","title":"train_sampler  <code>instance-attribute</code>","text":"<pre><code>train_sampler = train_sampler or ExpectedNumInstanceSampler(num_instances=1.0, min_future=prediction_length)\n</code></pre>"},{"location":"api/tpk/MyEstimator/#tpk.MyEstimator.validation_sampler","title":"validation_sampler  <code>instance-attribute</code>","text":"<pre><code>validation_sampler = validation_sampler or ValidationSplitSampler(min_future=prediction_length)\n</code></pre>"},{"location":"api/tpk/MyEstimator/#tpk.MyEstimator.weight_decay","title":"weight_decay  <code>instance-attribute</code>","text":"<pre><code>weight_decay = weight_decay\n</code></pre>"},{"location":"api/tpk/MyEstimator/#tpk.MyEstimator.create_lightning_module","title":"create_lightning_module","text":"<pre><code>create_lightning_module() -&gt; LightningModule\n</code></pre> Source code in <code>tpk/torch/estimator.py</code> <pre><code>def create_lightning_module(self) -&gt; LightningModule:\n    model = self.model_cls(\n        freq=self.freq,\n        context_length=self.context_length,\n        prediction_length=self.prediction_length,\n        num_feat_dynamic_real=(\n            self.num_feat_dynamic_real + len(self.time_features)\n        ),\n        num_future_feat=(\n            # len(self.time_features)\n            0\n            if self.disable_future_feature\n            else self.num_feat_dynamic_real + len(self.time_features)\n        ),\n        num_feat_static_real=max(1, self.num_feat_static_real),\n        num_feat_static_cat=max(1, self.num_feat_static_cat),\n        cardinality=self.cardinality,\n        embedding_dimension=self.embedding_dimension,\n        n_block=self.n_block,\n        hidden_size=self.hidden_size,\n        distr_output=self.distr_output,\n        dropout_rate=self.dropout_rate,\n        scaling=self.scaling,\n    )\n\n    return MyLightningModule(  # type: ignore\n        model=model,\n        loss=self.loss,\n        weight_decay=self.weight_decay,\n        patience=self.patience,\n        epochs=self.epochs,\n        steps_per_epoch=self.num_batches_per_epoch,\n    )\n</code></pre>"},{"location":"api/tpk/MyEstimator/#tpk.MyEstimator.create_predictor","title":"create_predictor","text":"<pre><code>create_predictor(transformation: Transformation, module: LightningModule) -&gt; PyTorchPredictor\n</code></pre> Source code in <code>tpk/torch/estimator.py</code> <pre><code>def create_predictor(\n    self,\n    transformation: Transformation,\n    module: LightningModule,\n) -&gt; PyTorchPredictor:\n    prediction_splitter = self._create_instance_splitter(module, \"test\")\n\n    return PyTorchPredictor(\n        input_transform=transformation + prediction_splitter,\n        input_names=PREDICTION_INPUT_NAMES,\n        prediction_net=module,\n        forecast_generator=DistributionForecastGenerator(self.distr_output),\n        batch_size=self.batch_size,\n        prediction_length=self.prediction_length,\n        device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n    )\n</code></pre>"},{"location":"api/tpk/MyEstimator/#tpk.MyEstimator.create_training_data_loader","title":"create_training_data_loader","text":"<pre><code>create_training_data_loader(data: Dataset, module: LightningModule, shuffle_buffer_length: Optional[int] = None, **kwargs: Any) -&gt; Any\n</code></pre> Source code in <code>tpk/torch/estimator.py</code> <pre><code>def create_training_data_loader(\n    self,\n    data: Dataset,\n    module: LightningModule,\n    shuffle_buffer_length: Optional[int] = None,\n    **kwargs: Any,\n) -&gt; Any:\n    transformation = self._create_instance_splitter(\n        module, \"training\"\n    ) + SelectFields(TRAINING_INPUT_NAMES)\n\n    training_instances = transformation.apply(\n        Cyclic(data)\n        if shuffle_buffer_length is None\n        else PseudoShuffled(\n            Cyclic(data), shuffle_buffer_length=shuffle_buffer_length\n        )\n    )\n\n    return IterableSlice(\n        iter(\n            # nosemgrep\n            DataLoader(\n                IterableDataset(training_instances),\n                batch_size=self.batch_size,\n                num_workers=2,\n                persistent_workers=True,\n                **kwargs,\n            )\n        ),\n        self.num_batches_per_epoch,\n    )\n</code></pre>"},{"location":"api/tpk/MyEstimator/#tpk.MyEstimator.create_transformation","title":"create_transformation","text":"<pre><code>create_transformation() -&gt; Transformation\n</code></pre> Source code in <code>tpk/torch/estimator.py</code> <pre><code>def create_transformation(self) -&gt; Transformation:\n    remove_field_names = []\n    if self.num_feat_static_real == 0:\n        remove_field_names.append(FieldName.FEAT_STATIC_REAL)\n    if self.num_feat_dynamic_real == 0:\n        remove_field_names.append(FieldName.FEAT_DYNAMIC_REAL)\n\n    return Chain(\n        [RemoveFields(field_names=remove_field_names)]\n        + (\n            [SetField(output_field=FieldName.FEAT_STATIC_CAT, value=[0])]\n            if not self.num_feat_static_cat &gt; 0\n            else []\n        )\n        + (\n            [SetField(output_field=FieldName.FEAT_STATIC_REAL, value=[0.0])]\n            if not self.num_feat_static_real &gt; 0\n            else []\n        )\n        + [\n            AsNumpyArray(\n                field=FieldName.FEAT_STATIC_CAT,\n                expected_ndim=1,\n                dtype=int,\n            ),\n            AsNumpyArray(\n                field=FieldName.FEAT_STATIC_REAL,\n                expected_ndim=1,\n            ),\n            AsNumpyArray(\n                field=FieldName.TARGET,\n                # in the following line, we add 1 for the time dimension\n                expected_ndim=1 + len(self.distr_output.event_shape),\n            ),\n            AddObservedValuesIndicator(\n                target_field=FieldName.TARGET,\n                output_field=FieldName.OBSERVED_VALUES,\n            ),\n            AddTimeFeatures(\n                start_field=FieldName.START,\n                target_field=FieldName.TARGET,\n                output_field=FieldName.FEAT_TIME,\n                time_features=self.time_features,\n                pred_length=self.prediction_length,\n            ),\n            VstackFeatures(\n                output_field=FieldName.FEAT_TIME,\n                input_fields=[FieldName.FEAT_TIME]\n                + (\n                    [FieldName.FEAT_DYNAMIC_REAL]\n                    if self.num_feat_dynamic_real &gt; 0\n                    else []\n                ),\n            ),\n        ]\n    )\n</code></pre>"},{"location":"api/tpk/MyEstimator/#tpk.MyEstimator.create_validation_data_loader","title":"create_validation_data_loader","text":"<pre><code>create_validation_data_loader(data: Dataset, module: LightningModule, **kwargs: Any) -&gt; DataLoader\n</code></pre> Source code in <code>tpk/torch/estimator.py</code> <pre><code>def create_validation_data_loader(\n    self,\n    data: Dataset,\n    module: LightningModule,\n    **kwargs: Any,\n) -&gt; DataLoader:  # type: ignore\n    transformation = self._create_instance_splitter(\n        module, \"validation\"\n    ) + SelectFields(TRAINING_INPUT_NAMES)\n\n    validation_instances = transformation.apply(data)\n\n    # nosemgrep\n    return DataLoader(\n        IterableDataset(validation_instances),\n        batch_size=self.batch_size,\n        num_workers=2,\n        persistent_workers=True,\n        **kwargs,\n    )\n</code></pre>"},{"location":"api/tpk/MyEstimator/#tpk.MyEstimator.train_model","title":"train_model","text":"<pre><code>train_model(training_data: Dataset, validation_data: Optional[Dataset] = None, from_predictor: Optional[PyTorchPredictor] = None, shuffle_buffer_length: Optional[int] = None, cache_data: bool = False, ckpt_path: Optional[str] = None, **kwargs: Any) -&gt; TrainOutput\n</code></pre> Source code in <code>tpk/torch/estimator.py</code> <pre><code>def train_model(\n    self,\n    training_data: Dataset,\n    validation_data: Optional[Dataset] = None,\n    from_predictor: Optional[PyTorchPredictor] = None,\n    shuffle_buffer_length: Optional[int] = None,\n    cache_data: bool = False,\n    ckpt_path: Optional[str] = None,\n    **kwargs: Any,\n) -&gt; TrainOutput:\n    transformation = self.create_transformation()\n\n    with env._let(max_idle_transforms=max(len(training_data), 100)):\n        transformed_training_data: Dataset = transformation.apply(\n            training_data, is_train=True\n        )\n        if cache_data:\n            transformed_training_data = Cached(transformed_training_data)\n\n        training_network = self.create_lightning_module()\n\n        training_data_loader = self.create_training_data_loader(\n            transformed_training_data,\n            training_network,\n            shuffle_buffer_length=shuffle_buffer_length,\n        )\n\n    validation_data_loader = None\n\n    if validation_data is not None:\n        with env._let(max_idle_transforms=max(len(validation_data), 100)):\n            transformed_validation_data: Dataset = transformation.apply(\n                validation_data, is_train=True\n            )\n            if cache_data:\n                transformed_validation_data = Cached(transformed_validation_data)\n\n            validation_data_loader = self.create_validation_data_loader(\n                transformed_validation_data,\n                training_network,\n            )\n\n    if from_predictor is not None:\n        training_network.load_state_dict(from_predictor.network.state_dict())\n\n    monitor = \"train_loss\" if validation_data is None else \"val_loss\"\n    checkpoint = pl.callbacks.ModelCheckpoint(\n        monitor=monitor, mode=\"min\", verbose=True\n    )\n\n    custom_callbacks = self.trainer_kwargs.pop(\"callbacks\", [])\n    trainer = pl.Trainer(\n        **{\n            \"accelerator\": \"auto\",\n            \"callbacks\": [checkpoint] + custom_callbacks,\n            **self.trainer_kwargs,\n        }\n    )\n\n    tuner = Tuner(trainer)\n\n    tuner.lr_find(\n        model=training_network,\n        train_dataloaders=training_data_loader,\n        val_dataloaders=validation_data_loader,\n        early_stop_threshold=50.0,\n    )\n\n    trainer.fit(\n        model=training_network,\n        train_dataloaders=training_data_loader,\n        val_dataloaders=validation_data_loader,\n        ckpt_path=ckpt_path,\n    )\n\n    if checkpoint.best_model_path != \"\":\n        logger.info(f\"Loading best model from {checkpoint.best_model_path}\")\n        best_model = training_network.__class__.load_from_checkpoint(\n            checkpoint.best_model_path\n        )\n    else:\n        best_model = training_network\n\n    return TrainOutput(\n        transformation=transformation,\n        trained_net=best_model,\n        trainer=trainer,\n        predictor=self.create_predictor(transformation, best_model),\n    )\n</code></pre>"},{"location":"api/tpk/TPKModel/","title":"TPKModel","text":""},{"location":"api/tpk/TPKModel/#tpk.TPKModel","title":"tpk.TPKModel","text":"<pre><code>TPKModel(freq: str, context_length: int, prediction_length: int, num_feat_dynamic_real: int, num_future_feat: int, num_feat_static_real: int, num_feat_static_cat: int, cardinality: List[int], distr_output: DistributionOutput, embedding_dimension: Optional[List[int]] = None, n_block: int = 2, hidden_size: int = 128, dropout_rate: float = 0.1, scaling: bool = True)\n</code></pre> <p>             Bases: <code>Module</code></p> <p>Module implementing the TPK model, see [SFG17]_.</p> <p>Note: the code of this model is unrelated to the implementation behind <code>SageMaker's TPK Forecasting Algorithm &lt;https://docs.aws.amazon.com/sagemaker/latest/dg/deepar.html&gt;</code>_.</p>"},{"location":"api/tpk/TPKModel/#tpk.TPKModel--parameters","title":"Parameters","text":"<p>freq     String indicating the sampling frequency of the data to be processed. context_length     Length of the RNN unrolling prior to the forecast date. prediction_length     Number of time points to predict. num_feat_dynamic_real     Number of dynamic real features that will be provided to <code>forward</code>. num_feat_static_real     Number of static real features that will be provided to <code>forward</code>. num_feat_static_cat     Number of static categorical features that will be provided to     <code>forward</code>. cardinality     List of cardinalities, one for each static categorical feature. embedding_dimension     Dimension of the embedding space, one for each static categorical     feature. n_block     Number of layers in the RNN. hidden_size     Size of the hidden layers in the RNN. dropout_rate     Dropout rate to be applied at training time. distr_output     Type of distribution to be output by the model at each time step scaling     Whether to apply mean scaling to the observations (target).</p> Source code in <code>tpk/torch/tpk/module.py</code> <pre><code>@validated()  # type: ignore\ndef __init__(\n    self,\n    freq: str,\n    context_length: int,\n    prediction_length: int,\n    num_feat_dynamic_real: int,\n    num_future_feat: int,\n    num_feat_static_real: int,\n    num_feat_static_cat: int,\n    cardinality: List[int],\n    distr_output: DistributionOutput,\n    embedding_dimension: Optional[List[int]] = None,\n    n_block: int = 2,\n    hidden_size: int = 128,\n    dropout_rate: float = 0.1,\n    scaling: bool = True,\n) -&gt; None:\n    super().__init__()\n\n    # assert distr_output.event_shape == ()\n\n    self.context_length = context_length\n    self.prediction_length = prediction_length\n    self.num_feat_dynamic_real = num_feat_dynamic_real\n    self.num_future_feat = num_future_feat\n    self.num_feat_static_cat = num_feat_static_cat\n    self.num_feat_static_real = num_feat_static_real\n    self.embedding_dimension = (\n        embedding_dimension\n        if embedding_dimension is not None or cardinality is None\n        else [min(32, (cat + 1) // 2) for cat in cardinality]\n    )\n    self.past_length = self.context_length\n    self.embedder = FeatureEmbedder(\n        cardinalities=cardinality,\n        embedding_dims=self.embedding_dimension,\n    )\n\n    if scaling:\n        self.scaler = MeanScaler(dim=-1, keepdim=True)\n    else:\n        self.scaler = NOPScaler(dim=-1, keepdim=True)\n\n    self.distr_output = StudentTOutput() if distr_output is None else distr_output\n    self.args_proj = distr_output.get_args_proj(hidden_size)\n\n    self.tsmixer_encoder = TPKEncoder(\n        input_len=context_length,\n        output_len=prediction_length,\n        past_feat_size=self.num_feat_dynamic_real + 1,  # target\n        future_feat_size=max(1, self.num_future_feat),\n        static_feat_size=(sum(self.embedding_dimension) + num_feat_static_real + 1),\n        activation=\"relu\",\n        dropout=dropout_rate,\n        n_block=n_block,\n        hidden_size=hidden_size,\n    )\n</code></pre>"},{"location":"api/tpk/TPKModel/#tpk.TPKModel.args_proj","title":"args_proj  <code>instance-attribute</code>","text":"<pre><code>args_proj = distr_output.get_args_proj(hidden_size)\n</code></pre>"},{"location":"api/tpk/TPKModel/#tpk.TPKModel.context_length","title":"context_length  <code>instance-attribute</code>","text":"<pre><code>context_length = context_length\n</code></pre>"},{"location":"api/tpk/TPKModel/#tpk.TPKModel.distr_output","title":"distr_output  <code>instance-attribute</code>","text":"<pre><code>distr_output = StudentTOutput() if distr_output is None else distr_output\n</code></pre>"},{"location":"api/tpk/TPKModel/#tpk.TPKModel.embedder","title":"embedder  <code>instance-attribute</code>","text":"<pre><code>embedder = FeatureEmbedder(cardinalities=cardinality, embedding_dims=self.embedding_dimension)\n</code></pre>"},{"location":"api/tpk/TPKModel/#tpk.TPKModel.embedding_dimension","title":"embedding_dimension  <code>instance-attribute</code>","text":"<pre><code>embedding_dimension = embedding_dimension if embedding_dimension is not None or cardinality is None else [min(32, cat + 1 // 2) for cat in cardinality]\n</code></pre>"},{"location":"api/tpk/TPKModel/#tpk.TPKModel.num_feat_dynamic_real","title":"num_feat_dynamic_real  <code>instance-attribute</code>","text":"<pre><code>num_feat_dynamic_real = num_feat_dynamic_real\n</code></pre>"},{"location":"api/tpk/TPKModel/#tpk.TPKModel.num_feat_static_cat","title":"num_feat_static_cat  <code>instance-attribute</code>","text":"<pre><code>num_feat_static_cat = num_feat_static_cat\n</code></pre>"},{"location":"api/tpk/TPKModel/#tpk.TPKModel.num_feat_static_real","title":"num_feat_static_real  <code>instance-attribute</code>","text":"<pre><code>num_feat_static_real = num_feat_static_real\n</code></pre>"},{"location":"api/tpk/TPKModel/#tpk.TPKModel.num_future_feat","title":"num_future_feat  <code>instance-attribute</code>","text":"<pre><code>num_future_feat = num_future_feat\n</code></pre>"},{"location":"api/tpk/TPKModel/#tpk.TPKModel.past_length","title":"past_length  <code>instance-attribute</code>","text":"<pre><code>past_length = self.context_length\n</code></pre>"},{"location":"api/tpk/TPKModel/#tpk.TPKModel.prediction_length","title":"prediction_length  <code>instance-attribute</code>","text":"<pre><code>prediction_length = prediction_length\n</code></pre>"},{"location":"api/tpk/TPKModel/#tpk.TPKModel.scaler","title":"scaler  <code>instance-attribute</code>","text":"<pre><code>scaler = MeanScaler(dim=-1, keepdim=True)\n</code></pre>"},{"location":"api/tpk/TPKModel/#tpk.TPKModel.tsmixer_encoder","title":"tsmixer_encoder  <code>instance-attribute</code>","text":"<pre><code>tsmixer_encoder = TPKEncoder(input_len=context_length, output_len=prediction_length, past_feat_size=self.num_feat_dynamic_real + 1, future_feat_size=max(1, self.num_future_feat), static_feat_size=sum(self.embedding_dimension) + num_feat_static_real + 1, activation='relu', dropout=dropout_rate, n_block=n_block, hidden_size=hidden_size)\n</code></pre>"},{"location":"api/tpk/TPKModel/#tpk.TPKModel.forward","title":"forward","text":"<pre><code>forward(feat_static_cat: torch.Tensor, feat_static_real: torch.Tensor, past_time_feat: torch.Tensor, past_target: torch.Tensor, past_observed_values: torch.Tensor, future_time_feat: torch.Tensor) -&gt; Tuple[Any, torch.Tensor, Any]\n</code></pre> <p>Invokes the model on input data, and produce outputs future samples.</p>"},{"location":"api/tpk/TPKModel/#tpk.TPKModel.forward--parameters","title":"Parameters","text":"<p>feat_static_cat     Tensor of static categorical features,     shape: <code>(batch_size, num_feat_static_cat)</code>. feat_static_real     Tensor of static real features,     shape: <code>(batch_size, num_feat_static_real)</code>. past_time_feat     Tensor of dynamic real features in the past,     shape: <code>(batch_size, past_length, num_feat_dynamic_real)</code>. past_target     Tensor of past target values,     shape: <code>(batch_size, past_length)</code>. past_observed_values     Tensor of observed values indicators,     shape: <code>(batch_size, past_length)</code>. future_time_feat     (Optional) tensor of dynamic real features in the past,     shape: <code>(batch_size, prediction_length, num_feat_dynamic_real)</code>.</p> Source code in <code>tpk/torch/tpk/module.py</code> <pre><code>def forward(\n    self,\n    feat_static_cat: torch.Tensor,\n    feat_static_real: torch.Tensor,\n    past_time_feat: torch.Tensor,\n    past_target: torch.Tensor,\n    past_observed_values: torch.Tensor,\n    future_time_feat: torch.Tensor,\n) -&gt; Tuple[Any, torch.Tensor, Any]:\n    \"\"\"\n    Invokes the model on input data, and produce outputs future samples.\n\n    Parameters\n    ----------\n    feat_static_cat\n        Tensor of static categorical features,\n        shape: ``(batch_size, num_feat_static_cat)``.\n    feat_static_real\n        Tensor of static real features,\n        shape: ``(batch_size, num_feat_static_real)``.\n    past_time_feat\n        Tensor of dynamic real features in the past,\n        shape: ``(batch_size, past_length, num_feat_dynamic_real)``.\n    past_target\n        Tensor of past target values,\n        shape: ``(batch_size, past_length)``.\n    past_observed_values\n        Tensor of observed values indicators,\n        shape: ``(batch_size, past_length)``.\n    future_time_feat\n        (Optional) tensor of dynamic real features in the past,\n        shape: ``(batch_size, prediction_length, num_feat_dynamic_real)``.\n    \"\"\"\n    if self.num_future_feat == 0:\n        future_time_feat = torch.zeros_like(future_time_feat)[:, :, [0]]\n    else:\n        future_time_feat = future_time_feat[:, :, : self.num_future_feat]\n    _, _, scale = self.scaler(past_target, past_observed_values)\n\n    scaled_past_target = past_target / scale\n\n    embedded_cat = self.embedder(feat_static_cat)\n    static_feat = torch.cat(\n        (embedded_cat, feat_static_real, scale.log()),\n        dim=-1,\n    )\n    past_feature = torch.cat(\n        (scaled_past_target.unsqueeze(-1), past_time_feat), dim=-1\n    )\n    output = self.tsmixer_encoder(past_feature, future_time_feat, static_feat)\n    distr_args = self.args_proj(output)\n    return distr_args, torch.zeros_like(scale), scale\n</code></pre>"},{"location":"api/tpk/TPKModel/#tpk.TPKModel.input_shapes","title":"input_shapes","text":"<pre><code>input_shapes(batch_size: int = 1) -&gt; Dict[str, Tuple[int, ...]]\n</code></pre> Source code in <code>tpk/torch/tpk/module.py</code> <pre><code>def input_shapes(self, batch_size: int = 1) -&gt; Dict[str, Tuple[int, ...]]:\n    return {\n        \"feat_static_cat\": (batch_size, self.num_feat_static_cat),\n        \"feat_static_real\": (batch_size, self.num_feat_static_real),\n        \"past_time_feat\": (\n            batch_size,\n            self._past_length,\n            self.num_feat_dynamic_real,\n        ),\n        \"past_target\": (batch_size, self._past_length),\n        \"past_observed_values\": (batch_size, self._past_length),\n        \"future_time_feat\": (\n            batch_size,\n            self.prediction_length,\n            self.num_feat_dynamic_real,\n        ),\n    }\n</code></pre>"},{"location":"api/tpk/TPKModel/#tpk.TPKModel.input_types","title":"input_types","text":"<pre><code>input_types() -&gt; Dict[str, torch.dtype]\n</code></pre> Source code in <code>tpk/torch/tpk/module.py</code> <pre><code>def input_types(self) -&gt; Dict[str, torch.dtype]:\n    return {\n        \"feat_static_cat\": torch.long,\n        \"feat_static_real\": torch.float,\n        \"past_time_feat\": torch.float,\n        \"past_target\": torch.float,\n        \"past_observed_values\": torch.float,\n        \"future_time_feat\": torch.float,\n    }\n</code></pre>"},{"location":"api/tpk/TSMixerModel/","title":"TSMixerModel","text":""},{"location":"api/tpk/TSMixerModel/#tpk.TSMixerModel","title":"tpk.TSMixerModel","text":"<pre><code>TSMixerModel(freq: str, context_length: int, prediction_length: int, num_feat_dynamic_real: int, num_future_feat: int, num_feat_static_real: int, num_feat_static_cat: int, cardinality: List[int], distr_output: DistributionOutput, embedding_dimension: Optional[List[int]] = None, n_block: int = 2, hidden_size: int = 128, dropout_rate: float = 0.1, scaling: bool = True)\n</code></pre> <p>             Bases: <code>Module</code></p> <p>Module implementing the TSMixer model, see [SFG17]_.</p> <p>Note: the code of this model is unrelated to the implementation behind <code>SageMaker's TSMixer Forecasting Algorithm &lt;https://docs.aws.amazon.com/sagemaker/latest/dg/deepar.html&gt;</code>_.</p>"},{"location":"api/tpk/TSMixerModel/#tpk.TSMixerModel--parameters","title":"Parameters","text":"<p>freq     String indicating the sampling frequency of the data to be processed. context_length     Length of the RNN unrolling prior to the forecast date. prediction_length     Number of time points to predict. num_feat_dynamic_real     Number of dynamic real features that will be provided to <code>forward</code>. num_feat_static_real     Number of static real features that will be provided to <code>forward</code>. num_feat_static_cat     Number of static categorical features that will be provided to     <code>forward</code>. cardinality     List of cardinalities, one for each static categorical feature. embedding_dimension     Dimension of the embedding space, one for each static categorical     feature. n_block     Number of layers in the RNN. hidden_size     Size of the hidden layers in the RNN. dropout_rate     Dropout rate to be applied at training time. distr_output     Type of distribution to be output by the model at each time step scaling     Whether to apply mean scaling to the observations (target).</p> Source code in <code>tpk/torch/tsmixer/module.py</code> <pre><code>@validated()  # type: ignore\ndef __init__(\n    self,\n    freq: str,\n    context_length: int,\n    prediction_length: int,\n    num_feat_dynamic_real: int,\n    num_future_feat: int,\n    num_feat_static_real: int,\n    num_feat_static_cat: int,\n    cardinality: List[int],\n    distr_output: DistributionOutput,\n    embedding_dimension: Optional[List[int]] = None,\n    n_block: int = 2,\n    hidden_size: int = 128,\n    dropout_rate: float = 0.1,\n    scaling: bool = True,\n) -&gt; None:\n    super().__init__()\n\n    # assert distr_output.event_shape == ()\n\n    self.context_length = context_length\n    self.prediction_length = prediction_length\n    self.num_feat_dynamic_real = num_feat_dynamic_real\n    self.num_future_feat = num_future_feat\n    self.num_feat_static_cat = num_feat_static_cat\n    self.num_feat_static_real = num_feat_static_real\n    self.embedding_dimension = (\n        embedding_dimension\n        if embedding_dimension is not None or cardinality is None\n        else [min(32, (cat + 1) // 2) for cat in cardinality]\n    )\n    self.past_length = self.context_length\n    self.embedder = FeatureEmbedder(\n        cardinalities=cardinality,\n        embedding_dims=self.embedding_dimension,\n    )\n\n    if scaling:\n        self.scaler = MeanScaler(dim=-1, keepdim=True)\n    else:\n        self.scaler = NOPScaler(dim=-1, keepdim=True)\n\n    self.distr_output = StudentTOutput() if distr_output is None else distr_output\n    self.args_proj = distr_output.get_args_proj(hidden_size)\n\n    self.tsmixer_encoder = TSMixerEncoder(\n        input_len=context_length,\n        output_len=prediction_length,\n        past_feat_size=self.num_feat_dynamic_real + 1,  # target\n        future_feat_size=max(1, self.num_future_feat),\n        static_feat_size=(sum(self.embedding_dimension) + num_feat_static_real + 1),\n        activation=\"relu\",\n        dropout=dropout_rate,\n        n_block=n_block,\n        hidden_size=hidden_size,\n    )\n</code></pre>"},{"location":"api/tpk/TSMixerModel/#tpk.TSMixerModel.args_proj","title":"args_proj  <code>instance-attribute</code>","text":"<pre><code>args_proj = distr_output.get_args_proj(hidden_size)\n</code></pre>"},{"location":"api/tpk/TSMixerModel/#tpk.TSMixerModel.context_length","title":"context_length  <code>instance-attribute</code>","text":"<pre><code>context_length = context_length\n</code></pre>"},{"location":"api/tpk/TSMixerModel/#tpk.TSMixerModel.distr_output","title":"distr_output  <code>instance-attribute</code>","text":"<pre><code>distr_output = StudentTOutput() if distr_output is None else distr_output\n</code></pre>"},{"location":"api/tpk/TSMixerModel/#tpk.TSMixerModel.embedder","title":"embedder  <code>instance-attribute</code>","text":"<pre><code>embedder = FeatureEmbedder(cardinalities=cardinality, embedding_dims=self.embedding_dimension)\n</code></pre>"},{"location":"api/tpk/TSMixerModel/#tpk.TSMixerModel.embedding_dimension","title":"embedding_dimension  <code>instance-attribute</code>","text":"<pre><code>embedding_dimension = embedding_dimension if embedding_dimension is not None or cardinality is None else [min(32, cat + 1 // 2) for cat in cardinality]\n</code></pre>"},{"location":"api/tpk/TSMixerModel/#tpk.TSMixerModel.num_feat_dynamic_real","title":"num_feat_dynamic_real  <code>instance-attribute</code>","text":"<pre><code>num_feat_dynamic_real = num_feat_dynamic_real\n</code></pre>"},{"location":"api/tpk/TSMixerModel/#tpk.TSMixerModel.num_feat_static_cat","title":"num_feat_static_cat  <code>instance-attribute</code>","text":"<pre><code>num_feat_static_cat = num_feat_static_cat\n</code></pre>"},{"location":"api/tpk/TSMixerModel/#tpk.TSMixerModel.num_feat_static_real","title":"num_feat_static_real  <code>instance-attribute</code>","text":"<pre><code>num_feat_static_real = num_feat_static_real\n</code></pre>"},{"location":"api/tpk/TSMixerModel/#tpk.TSMixerModel.num_future_feat","title":"num_future_feat  <code>instance-attribute</code>","text":"<pre><code>num_future_feat = num_future_feat\n</code></pre>"},{"location":"api/tpk/TSMixerModel/#tpk.TSMixerModel.past_length","title":"past_length  <code>instance-attribute</code>","text":"<pre><code>past_length = self.context_length\n</code></pre>"},{"location":"api/tpk/TSMixerModel/#tpk.TSMixerModel.prediction_length","title":"prediction_length  <code>instance-attribute</code>","text":"<pre><code>prediction_length = prediction_length\n</code></pre>"},{"location":"api/tpk/TSMixerModel/#tpk.TSMixerModel.scaler","title":"scaler  <code>instance-attribute</code>","text":"<pre><code>scaler = MeanScaler(dim=-1, keepdim=True)\n</code></pre>"},{"location":"api/tpk/TSMixerModel/#tpk.TSMixerModel.tsmixer_encoder","title":"tsmixer_encoder  <code>instance-attribute</code>","text":"<pre><code>tsmixer_encoder = TSMixerEncoder(input_len=context_length, output_len=prediction_length, past_feat_size=self.num_feat_dynamic_real + 1, future_feat_size=max(1, self.num_future_feat), static_feat_size=sum(self.embedding_dimension) + num_feat_static_real + 1, activation='relu', dropout=dropout_rate, n_block=n_block, hidden_size=hidden_size)\n</code></pre>"},{"location":"api/tpk/TSMixerModel/#tpk.TSMixerModel.forward","title":"forward","text":"<pre><code>forward(feat_static_cat: torch.Tensor, feat_static_real: torch.Tensor, past_time_feat: torch.Tensor, past_target: torch.Tensor, past_observed_values: torch.Tensor, future_time_feat: torch.Tensor) -&gt; Tuple[Any, torch.Tensor, Any]\n</code></pre> <p>Invokes the model on input data, and produce outputs future samples.</p>"},{"location":"api/tpk/TSMixerModel/#tpk.TSMixerModel.forward--parameters","title":"Parameters","text":"<p>feat_static_cat     Tensor of static categorical features,     shape: <code>(batch_size, num_feat_static_cat)</code>. feat_static_real     Tensor of static real features,     shape: <code>(batch_size, num_feat_static_real)</code>. past_time_feat     Tensor of dynamic real features in the past,     shape: <code>(batch_size, past_length, num_feat_dynamic_real)</code>. past_target     Tensor of past target values,     shape: <code>(batch_size, past_length)</code>. past_observed_values     Tensor of observed values indicators,     shape: <code>(batch_size, past_length)</code>. future_time_feat     (Optional) tensor of dynamic real features in the past,     shape: <code>(batch_size, prediction_length, num_feat_dynamic_real)</code>.</p> Source code in <code>tpk/torch/tsmixer/module.py</code> <pre><code>def forward(\n    self,\n    feat_static_cat: torch.Tensor,\n    feat_static_real: torch.Tensor,\n    past_time_feat: torch.Tensor,\n    past_target: torch.Tensor,\n    past_observed_values: torch.Tensor,\n    future_time_feat: torch.Tensor,\n) -&gt; Tuple[Any, torch.Tensor, Any]:\n    \"\"\"\n    Invokes the model on input data, and produce outputs future samples.\n\n    Parameters\n    ----------\n    feat_static_cat\n        Tensor of static categorical features,\n        shape: ``(batch_size, num_feat_static_cat)``.\n    feat_static_real\n        Tensor of static real features,\n        shape: ``(batch_size, num_feat_static_real)``.\n    past_time_feat\n        Tensor of dynamic real features in the past,\n        shape: ``(batch_size, past_length, num_feat_dynamic_real)``.\n    past_target\n        Tensor of past target values,\n        shape: ``(batch_size, past_length)``.\n    past_observed_values\n        Tensor of observed values indicators,\n        shape: ``(batch_size, past_length)``.\n    future_time_feat\n        (Optional) tensor of dynamic real features in the past,\n        shape: ``(batch_size, prediction_length, num_feat_dynamic_real)``.\n    \"\"\"\n    if self.num_future_feat == 0:\n        future_time_feat = torch.zeros_like(future_time_feat)[:, :, [0]]\n    else:\n        future_time_feat = future_time_feat[:, :, : self.num_future_feat]\n    _, _, scale = self.scaler(past_target, past_observed_values)\n\n    scaled_past_target = past_target / scale\n\n    embedded_cat = self.embedder(feat_static_cat)\n    static_feat = torch.cat(\n        (embedded_cat, feat_static_real, scale.log()),\n        dim=-1,\n    )\n    past_feature = torch.cat(\n        (scaled_past_target.unsqueeze(-1), past_time_feat), dim=-1\n    )\n    output = self.tsmixer_encoder(past_feature, future_time_feat, static_feat)\n    distr_args = self.args_proj(output)\n    return distr_args, torch.zeros_like(scale), scale\n</code></pre>"},{"location":"api/tpk/TSMixerModel/#tpk.TSMixerModel.input_shapes","title":"input_shapes","text":"<pre><code>input_shapes(batch_size: int = 1) -&gt; Dict[str, Tuple[int, ...]]\n</code></pre> Source code in <code>tpk/torch/tsmixer/module.py</code> <pre><code>def input_shapes(self, batch_size: int = 1) -&gt; Dict[str, Tuple[int, ...]]:\n    return {\n        \"feat_static_cat\": (batch_size, self.num_feat_static_cat),\n        \"feat_static_real\": (batch_size, self.num_feat_static_real),\n        \"past_time_feat\": (\n            batch_size,\n            self._past_length,\n            self.num_feat_dynamic_real,\n        ),\n        \"past_target\": (batch_size, self._past_length),\n        \"past_observed_values\": (batch_size, self._past_length),\n        \"future_time_feat\": (\n            batch_size,\n            self.prediction_length,\n            self.num_feat_dynamic_real,\n        ),\n    }\n</code></pre>"},{"location":"api/tpk/TSMixerModel/#tpk.TSMixerModel.input_types","title":"input_types","text":"<pre><code>input_types() -&gt; Dict[str, torch.dtype]\n</code></pre> Source code in <code>tpk/torch/tsmixer/module.py</code> <pre><code>def input_types(self) -&gt; Dict[str, torch.dtype]:\n    return {\n        \"feat_static_cat\": torch.long,\n        \"feat_static_real\": torch.float,\n        \"past_time_feat\": torch.float,\n        \"past_target\": torch.float,\n        \"past_observed_values\": torch.float,\n        \"future_time_feat\": torch.float,\n    }\n</code></pre>"},{"location":"api/tpk/cli/get_model_cls/","title":"Get model cls","text":""},{"location":"api/tpk/cli/get_model_cls/#tpk.cli.get_model_cls","title":"tpk.cli.get_model_cls","text":"<pre><code>get_model_cls(model_str: Literal['tpk', 'tsmixer']) -&gt; Type[Union[TPKModel, TSMixerModel]]\n</code></pre> Source code in <code>tpk/cli.py</code> <pre><code>def get_model_cls(\n    model_str: Literal[\"tpk\", \"tsmixer\"]\n) -&gt; Type[Union[TPKModel, TSMixerModel]]:\n    if model_str == \"tpk\":\n        return TPKModel  # type: ignore[no-any-return]\n    elif model_str == \"tsmixer\":\n        return TSMixerModel  # type: ignore[no-any-return]\n    else:\n        raise ValueError(f\"Unknown model: {model_str}\")\n</code></pre>"},{"location":"api/tpk/cli/hello/","title":"Hello","text":""},{"location":"api/tpk/cli/hello/#tpk.cli.hello","title":"tpk.cli.hello","text":"<pre><code>hello() -&gt; None\n</code></pre> Source code in <code>tpk/cli.py</code> <pre><code>@app.command()\ndef hello() -&gt; None:\n    print(\"Hi from temporal predictions kit\")\n</code></pre>"},{"location":"api/tpk/cli/run_study/","title":"Run study","text":""},{"location":"api/tpk/cli/run_study/#tpk.cli.run_study","title":"tpk.cli.run_study","text":"<pre><code>run_study(model_cls: Literal['tpk', 'tsmixer'], study_name: str, n_trials: int, tests_per_trial: int = 5, study_journal_path: str = 'data/journal', data_path: str = 'data/m5') -&gt; None\n</code></pre> Source code in <code>tpk/cli.py</code> <pre><code>@app.command()\ndef run_study(\n    model_cls: Literal[\"tpk\", \"tsmixer\"],\n    study_name: str,\n    n_trials: int,\n    tests_per_trial: int = 5,\n    study_journal_path: str = \"data/journal\",\n    data_path: str = \"data/m5\",\n) -&gt; None:\n    from tpk.hypervalidation import run_study as concrete_run_study\n\n    concrete_run_study(\n        model_cls=model_cls,\n        study_journal_path=Path(study_journal_path),\n        data_path=Path(data_path),\n        study_name=study_name,\n        n_trials=n_trials,\n        tests_per_trial=tests_per_trial,\n    )\n</code></pre>"},{"location":"api/tpk/cli/train_model/","title":"Train model","text":""},{"location":"api/tpk/cli/train_model/#tpk.cli.train_model","title":"tpk.cli.train_model","text":"<pre><code>train_model(model_cls: Literal['tpk', 'tsmixer'], data_path: str = 'data/m5', batch_size: int = 64, epochs: int = 300, context_length: int = 30, n_block: int = 2, hidden_size: int = 256, weight_decay: float = 0.0001, dropout_rate: float = 0.0001, disable_future_feat: bool = False, use_static_feat: bool = True) -&gt; None\n</code></pre> Source code in <code>tpk/cli.py</code> <pre><code>@app.command()\ndef train_model(\n    model_cls: Literal[\"tpk\", \"tsmixer\"],\n    data_path: str = \"data/m5\",\n    batch_size: int = 64,\n    epochs: int = 300,\n    context_length: int = 30,\n    n_block: int = 2,\n    hidden_size: int = 256,\n    weight_decay: float = 0.0001,\n    dropout_rate: float = 0.0001,\n    disable_future_feat: bool = False,\n    use_static_feat: bool = True,\n) -&gt; None:\n    from tpk.hypervalidation import train_model as concrete_train_model\n\n    validation_wrmsse = concrete_train_model(\n        model_cls=get_model_cls(model_cls),\n        data_path=data_path,\n        batch_size=batch_size,\n        epochs=epochs,\n        context_length=context_length,\n        n_block=n_block,\n        hidden_size=hidden_size,\n        weight_decay=weight_decay,\n        dropout_rate=dropout_rate,\n        disable_future_feature=disable_future_feat,\n        use_static_feat=use_static_feat,\n    )\n\n    typer.echo(validation_wrmsse)\n</code></pre>"},{"location":"api/tpk/hypervalidation/run_study/","title":"Run study","text":""},{"location":"api/tpk/hypervalidation/run_study/#tpk.hypervalidation.run_study","title":"tpk.hypervalidation.run_study","text":"<pre><code>run_study(*, model_cls: Literal['tpk', 'tsmixer'], study_journal_path: Path, study_name: str, data_path: Path, n_trials: int, tests_per_trial: int) -&gt; None\n</code></pre> Source code in <code>tpk/hypervalidation/hyperparameter_search.py</code> <pre><code>def run_study(\n    *,\n    model_cls: Literal[\"tpk\", \"tsmixer\"],\n    study_journal_path: Path,\n    study_name: str,\n    data_path: Path,\n    n_trials: int,\n    tests_per_trial: int,\n) -&gt; None:\n    if not study_journal_path.exists():\n        study_journal_path.mkdir(exist_ok=True)\n\n    storage = optuna.storages.JournalStorage(\n        optuna.storages.JournalFileStorage(str(study_journal_path / \"journal.log\")),\n    )\n\n    study = optuna.create_study(\n        storage=storage,\n        directions=[\"minimize\"],\n        study_name=study_name,\n    )\n    study.optimize(\n        objective(\n            model_cls=model_cls,\n            data_path=str(data_path),\n            tests_per_trial=tests_per_trial,\n        ),\n        n_trials=n_trials,\n        catch=(ValueError,),\n    )  # Model diverging with ValueError, catch and go to next trial\n</code></pre>"},{"location":"api/tpk/hypervalidation/train_model/","title":"Train model","text":""},{"location":"api/tpk/hypervalidation/train_model/#tpk.hypervalidation.train_model","title":"tpk.hypervalidation.train_model","text":"<pre><code>train_model(*, model_cls: Type[Union[TPKModel, TSMixerModel]], data_path: str, batch_size: int, epochs: int, context_length: int, n_block: int, hidden_size: int, weight_decay: float, dropout_rate: float, disable_future_feature: bool, use_static_feat: bool) -&gt; float\n</code></pre> Source code in <code>tpk/hypervalidation/model_train.py</code> <pre><code>def train_model(\n    *,\n    model_cls: Type[Union[TPKModel, TSMixerModel]],\n    data_path: str,\n    batch_size: int,\n    epochs: int,\n    context_length: int,\n    n_block: int,\n    hidden_size: int,\n    weight_decay: float,\n    dropout_rate: float,\n    disable_future_feature: bool,\n    use_static_feat: bool,\n) -&gt; float:\n    train_ds, val_ds, _, stat_cat_cardinalities = load_datasets(data_path)\n    estimator = MyEstimator(\n        model_cls=model_cls,\n        prediction_length=PREDICTION_LENGTH,\n        context_length=context_length,\n        epochs=epochs,\n        n_block=n_block,\n        hidden_size=hidden_size,\n        weight_decay=weight_decay,\n        dropout_rate=dropout_rate,\n        num_feat_dynamic_real=7,\n        disable_future_feature=disable_future_feature,\n        num_feat_static_cat=5 if use_static_feat else 0,\n        cardinality=stat_cat_cardinalities,\n        batch_size=batch_size,\n        freq=\"D\",\n        distr_output=NegativeBinomialOutput(),\n        num_batches_per_epoch=(N_TS // batch_size + 1),\n        trainer_kwargs={\n            \"accelerator\": \"gpu\",\n            \"devices\": 1,\n            \"max_epochs\": epochs,\n            \"callbacks\": [],\n        },\n    )\n\n    predictor = estimator.train(train_ds, validation_data=val_ds, num_workers=32)\n\n    val_wrmsse = evaluate(data_path, val_ds, predictor, VAL_START)\n    return val_wrmsse  # type: ignore\n</code></pre>"},{"location":"api/tpk/hypervalidation/hyperparameter_search/objective/","title":"Objective","text":""},{"location":"api/tpk/hypervalidation/hyperparameter_search/objective/#tpk.hypervalidation.hyperparameter_search.objective","title":"tpk.hypervalidation.hyperparameter_search.objective","text":"<pre><code>objective(*, model_cls: Literal['tpk', 'tsmixer'], data_path: str, tests_per_trial: int) -&gt; Callable[[optuna.Trial], Union[float, Sequence[float]]]\n</code></pre> Source code in <code>tpk/hypervalidation/hyperparameter_search.py</code> <pre><code>def objective(\n    *,\n    model_cls: Literal[\"tpk\", \"tsmixer\"],\n    data_path: str,\n    tests_per_trial: int,\n) -&gt; Callable[[optuna.Trial], Union[float, Sequence[float]]]:\n    def _inner(\n        trial: Any,\n        *,\n        model_cls: Literal[\"tpk\", \"tsmixer\"] = model_cls,\n        data_path: str = data_path,\n        tests_per_trial: int = tests_per_trial,\n        batch_size: int = 64,\n        epochs: int = 1,\n    ) -&gt; float:\n        trial_values = {\n            \"model_cls\": model_cls,\n            \"data-path\": data_path,\n            \"context-length\": trial.suggest_categorical(\"context_length\", [20, 35, 50]),\n            \"n-block\": trial.suggest_int(\"n_block\", 1, 5),\n            \"hidden-size\": trial.suggest_categorical(\n                \"hidden_size\", [64, 128, 256, 512]\n            ),\n            \"lr\": trial.suggest_float(\"learning_rate\", 0.0001, 0.5, log=True),\n            \"weight-decay\": trial.suggest_float(\"weight_decay\", 0.0001, 0.5, log=True),\n            \"dropout-rate\": trial.suggest_float(\"dropout_rate\", 0.0001, 0.5, log=True),\n            \"batch-size\": batch_size,\n            \"epochs\": trial.suggest_int(\"num_epochs\", 1, 150),\n        }\n\n        cmd = \"tpk train-model\"\n\n        for key, value in trial_values.items():\n            cmd += f\" --{key} {value}\"\n\n        typer.echo(f\"Running trial with cmd: {cmd}\")\n\n        values = asyncio.run(\n            run_model_cmd_parallel(\n                model_cmd=cmd,\n                num_executions=tests_per_trial,\n            )\n        )\n\n        return float(np.mean(values))\n\n    return _inner\n</code></pre>"},{"location":"api/tpk/hypervalidation/hyperparameter_search/run_model_cmd_parallel/","title":"Run model cmd parallel","text":""},{"location":"api/tpk/hypervalidation/hyperparameter_search/run_model_cmd_parallel/#tpk.hypervalidation.hyperparameter_search.run_model_cmd_parallel","title":"tpk.hypervalidation.hyperparameter_search.run_model_cmd_parallel  <code>async</code>","text":"<pre><code>run_model_cmd_parallel(model_cmd: str, num_executions: int) -&gt; List[float]\n</code></pre> Source code in <code>tpk/hypervalidation/hyperparameter_search.py</code> <pre><code>async def run_model_cmd_parallel(model_cmd: str, num_executions: int) -&gt; List[float]:\n    async with asyncer.create_task_group() as tg:\n        tasks = []\n        for _ in range(num_executions):\n            tasks.append(\n                tg.soonify(asyncio.create_subprocess_exec)(\n                    *shlex.split(model_cmd),\n                    stdout=asyncio.subprocess.PIPE,\n                    stdin=asyncio.subprocess.PIPE,\n                )\n            )\n            await asyncio.sleep(0.001)\n\n    procs = [task.value for task in tasks]\n\n    async def log_output(\n        output: Optional[asyncio.StreamReader],\n        pid: int,\n    ) -&gt; str:\n        if output is None:\n            raise RuntimeError(\"Expected StreamReader, got None. Is stdout piped?\")\n        last_out = \"\"\n        while not output.at_eof():\n            outs = await output.readline()\n            if outs != b\"\":\n                typer.echo(f\"[{pid:03d}]: \" + outs.decode(\"utf-8\"), nl=False)\n                last_out = outs.decode(\"utf-8\").strip()\n        return last_out\n\n    async with asyncer.create_task_group() as tg:\n        soon_values = [tg.soonify(log_output)(proc.stdout, proc.pid) for proc in procs]\n\n    values = [soon_value.value for soon_value in soon_values]\n\n    try:\n        return [float(value) for value in values]\n    except ValueError:\n        raise ValueError(\"Model training process failed\") from None\n</code></pre>"},{"location":"api/tpk/hypervalidation/hyperparameter_search/run_study/","title":"Run study","text":""},{"location":"api/tpk/hypervalidation/hyperparameter_search/run_study/#tpk.hypervalidation.hyperparameter_search.run_study","title":"tpk.hypervalidation.hyperparameter_search.run_study","text":"<pre><code>run_study(*, model_cls: Literal['tpk', 'tsmixer'], study_journal_path: Path, study_name: str, data_path: Path, n_trials: int, tests_per_trial: int) -&gt; None\n</code></pre> Source code in <code>tpk/hypervalidation/hyperparameter_search.py</code> <pre><code>def run_study(\n    *,\n    model_cls: Literal[\"tpk\", \"tsmixer\"],\n    study_journal_path: Path,\n    study_name: str,\n    data_path: Path,\n    n_trials: int,\n    tests_per_trial: int,\n) -&gt; None:\n    if not study_journal_path.exists():\n        study_journal_path.mkdir(exist_ok=True)\n\n    storage = optuna.storages.JournalStorage(\n        optuna.storages.JournalFileStorage(str(study_journal_path / \"journal.log\")),\n    )\n\n    study = optuna.create_study(\n        storage=storage,\n        directions=[\"minimize\"],\n        study_name=study_name,\n    )\n    study.optimize(\n        objective(\n            model_cls=model_cls,\n            data_path=str(data_path),\n            tests_per_trial=tests_per_trial,\n        ),\n        n_trials=n_trials,\n        catch=(ValueError,),\n    )  # Model diverging with ValueError, catch and go to next trial\n</code></pre>"},{"location":"api/tpk/hypervalidation/model_train/evaluate/","title":"Evaluate","text":""},{"location":"api/tpk/hypervalidation/model_train/evaluate/#tpk.hypervalidation.model_train.evaluate","title":"tpk.hypervalidation.model_train.evaluate","text":"<pre><code>evaluate(data_dir: str, dataset: Any, predictor: Any, prediction_start: int) -&gt; Any\n</code></pre> Source code in <code>tpk/hypervalidation/model_train.py</code> <pre><code>def evaluate(\n    data_dir: str,\n    dataset: Any,\n    predictor: Any,\n    prediction_start: int,\n) -&gt; Any:\n    forecast_it, _ = make_evaluation_predictions(\n        dataset=dataset, predictor=predictor, num_samples=100\n    )\n\n    forecasts = list(tqdm(forecast_it, total=len(dataset)))\n\n    forecasts_acc = np.zeros((len(forecasts), PREDICTION_LENGTH))\n    if isinstance(forecasts[0], (PTDistributionForecast, QuantileForecast)):\n        for i in range(len(forecasts)):\n            forecasts_acc[i] = forecasts[i].mean\n    else:\n        for i in range(len(forecasts)):\n            forecasts_acc[i] = np.mean(forecasts[i].samples, axis=0)\n    wrmsse = evaluate_wrmsse(data_dir, forecasts_acc, prediction_start, score_only=True)\n    return wrmsse\n</code></pre>"},{"location":"api/tpk/hypervalidation/model_train/train_model/","title":"Train model","text":""},{"location":"api/tpk/hypervalidation/model_train/train_model/#tpk.hypervalidation.model_train.train_model","title":"tpk.hypervalidation.model_train.train_model","text":"<pre><code>train_model(*, model_cls: Type[Union[TPKModel, TSMixerModel]], data_path: str, batch_size: int, epochs: int, context_length: int, n_block: int, hidden_size: int, weight_decay: float, dropout_rate: float, disable_future_feature: bool, use_static_feat: bool) -&gt; float\n</code></pre> Source code in <code>tpk/hypervalidation/model_train.py</code> <pre><code>def train_model(\n    *,\n    model_cls: Type[Union[TPKModel, TSMixerModel]],\n    data_path: str,\n    batch_size: int,\n    epochs: int,\n    context_length: int,\n    n_block: int,\n    hidden_size: int,\n    weight_decay: float,\n    dropout_rate: float,\n    disable_future_feature: bool,\n    use_static_feat: bool,\n) -&gt; float:\n    train_ds, val_ds, _, stat_cat_cardinalities = load_datasets(data_path)\n    estimator = MyEstimator(\n        model_cls=model_cls,\n        prediction_length=PREDICTION_LENGTH,\n        context_length=context_length,\n        epochs=epochs,\n        n_block=n_block,\n        hidden_size=hidden_size,\n        weight_decay=weight_decay,\n        dropout_rate=dropout_rate,\n        num_feat_dynamic_real=7,\n        disable_future_feature=disable_future_feature,\n        num_feat_static_cat=5 if use_static_feat else 0,\n        cardinality=stat_cat_cardinalities,\n        batch_size=batch_size,\n        freq=\"D\",\n        distr_output=NegativeBinomialOutput(),\n        num_batches_per_epoch=(N_TS // batch_size + 1),\n        trainer_kwargs={\n            \"accelerator\": \"gpu\",\n            \"devices\": 1,\n            \"max_epochs\": epochs,\n            \"callbacks\": [],\n        },\n    )\n\n    predictor = estimator.train(train_ds, validation_data=val_ds, num_workers=32)\n\n    val_wrmsse = evaluate(data_path, val_ds, predictor, VAL_START)\n    return val_wrmsse  # type: ignore\n</code></pre>"},{"location":"api/tpk/testing/datasets/m5/evaluate_wrmsse/","title":"Evaluate wrmsse","text":""},{"location":"api/tpk/testing/datasets/m5/evaluate_wrmsse/#tpk.testing.datasets.m5.evaluate_wrmsse","title":"tpk.testing.datasets.m5.evaluate_wrmsse","text":"<pre><code>evaluate_wrmsse(data_path: str, prediction: Any, prediction_start: int, score_only: bool = True) -&gt; Any\n</code></pre> Source code in <code>tpk/testing/datasets/m5/accuracy_evaluator.py</code> <pre><code>def evaluate_wrmsse(\n    data_path: str, prediction: Any, prediction_start: int, score_only: bool = True\n) -&gt; Any:\n    # Loading data in two ways:\n    # if S, W, SW are calculated in advance, load from pickle files\n    # otherwise, calculate from scratch\n    if os.path.isfile(\n        data_path + f\"/ordered_sw_df_p{prediction_start}.pkl\"\n    ) and os.path.isfile(data_path + \"/ordered_roll_mat_df.pkl\"):\n        print(\"load precalculated data\")\n        # Sales quantities:\n        sales = pd.read_csv(data_path + \"/sales_train_evaluation.csv\")\n        S, W, SW, roll_mat_csr = load_precalculated_data(data_path, prediction_start)\n    else:\n        print(\"load data from scratch\")\n        sales, S, W, SW, roll_mat_csr = calculate_and_save_data(\n            data_path, prediction_start\n        )\n\n    # Ground truth:\n    dayCols = [\n        f\"d_{i}\" for i in range(prediction_start, prediction_start + prediction_length)\n    ]\n    y_true = sales[dayCols]\n\n    error = prediction - y_true.values\n    results = wrmsse(error, score_only, roll_mat_csr, S, W, SW)\n\n    return results\n</code></pre>"},{"location":"api/tpk/testing/datasets/m5/load_datasets/","title":"Load datasets","text":""},{"location":"api/tpk/testing/datasets/m5/load_datasets/#tpk.testing.datasets.m5.load_datasets","title":"tpk.testing.datasets.m5.load_datasets","text":"<pre><code>load_datasets(data_dir: str) -&gt; Tuple[ListDataset, ListDataset, ListDataset, List[int]]\n</code></pre> Source code in <code>tpk/testing/datasets/m5/load_dataset.py</code> <pre><code>def load_datasets(\n    data_dir: str,\n) -&gt; Tuple[ListDataset, ListDataset, ListDataset, List[int]]:\n    calendar = pd.read_csv(f\"{data_dir}/calendar.csv\")\n    sales_train_evaluation = pd.read_csv(f\"{data_dir}/sales_train_evaluation.csv\")\n\n    cal_features = calendar.drop(\n        [\n            \"date\",\n            \"wm_yr_wk\",\n            \"weekday\",\n            \"wday\",\n            \"month\",\n            \"year\",\n            \"event_name_1\",\n            \"event_name_2\",\n            \"d\",\n        ],\n        axis=1,\n    )\n    cal_features[\"event_type_1\"] = cal_features[\"event_type_1\"].apply(\n        lambda x: 0 if str(x) == \"nan\" else 1\n    )\n    cal_features[\"event_type_2\"] = cal_features[\"event_type_2\"].apply(\n        lambda x: 0 if str(x) == \"nan\" else 1\n    )\n\n    event_features = cal_features.values.T\n    event_features_expand = np.tile(event_features, (len(sales_train_evaluation), 1, 1))\n\n    state_ids = sales_train_evaluation[\"state_id\"].astype(\"category\").cat.codes.values\n    state_ids_un, state_ids_counts = np.unique(state_ids, return_counts=True)\n\n    store_ids = sales_train_evaluation[\"store_id\"].astype(\"category\").cat.codes.values\n    store_ids_un, store_ids_counts = np.unique(store_ids, return_counts=True)\n\n    cat_ids = sales_train_evaluation[\"cat_id\"].astype(\"category\").cat.codes.values\n    cat_ids_un, cat_ids_counts = np.unique(cat_ids, return_counts=True)\n\n    dept_ids = sales_train_evaluation[\"dept_id\"].astype(\"category\").cat.codes.values\n    dept_ids_un, dept_ids_counts = np.unique(dept_ids, return_counts=True)\n\n    item_ids = sales_train_evaluation[\"item_id\"].astype(\"category\").cat.codes.values\n    item_ids_un, item_ids_counts = np.unique(item_ids, return_counts=True)\n\n    stat_cat_list = [item_ids, dept_ids, cat_ids, store_ids, state_ids]\n    stat_cat = np.concatenate(stat_cat_list)\n    stat_cat = stat_cat.reshape(len(stat_cat_list), len(item_ids)).T  # type: ignore\n    stat_cat_cardinalities = [\n        len(item_ids_un),\n        len(dept_ids_un),\n        len(cat_ids_un),\n        len(store_ids_un),\n        len(state_ids_un),\n    ]  # type: ignore\n\n    train_df = sales_train_evaluation.drop(\n        [\"id\", \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"], axis=1\n    )\n    train_target_values = train_df.values\n\n    test_target_values = train_target_values.copy()\n    train_target_values = [ts[: -(2 * PREDICTION_LENGTH)] for ts in train_df.values]\n    val_target_values = [ts[:-PREDICTION_LENGTH] for ts in train_df.values]\n\n    # snap features\n    # snap_features = calendar[['snap_CA', 'snap_TX', 'snap_WI']]\n    # snap_features = snap_features.values.T\n    # snap_features_expand = np.array([snap_features] * len(sales_train_evaluation))    # 30490 * 3 * T\n\n    # sell_prices\n    converted_price_file = Path(f\"{data_dir}/converted_price_evaluation.csv\")\n    if not converted_price_file.exists():\n        convert_price_file(data_dir)\n    converted_price = pd.read_csv(converted_price_file)\n\n    price_feature = converted_price.drop(\n        [\"id\", \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"], axis=1\n    ).values\n\n    # normalized sell prices\n    normalized_price_file = Path(f\"{data_dir}/normalized_price_evaluation.npz\")\n    if not normalized_price_file.exists():\n        # normalized sell prices per each item\n        price_mean_per_item = np.nanmean(price_feature, axis=1, keepdims=True)\n        price_std_per_item = np.nanstd(price_feature, axis=1, keepdims=True)\n        normalized_price_per_item = (price_feature - price_mean_per_item) / (\n            price_std_per_item + 1e-6\n        )\n\n        # normalized sell prices per day within the same dept\n        dept_groups = converted_price.drop(\n            [\"id\", \"item_id\", \"cat_id\", \"store_id\", \"state_id\"], axis=1\n        ).groupby(\"dept_id\")\n        price_mean_per_dept = dept_groups.transform(np.nanmean)\n        price_std_per_dept = dept_groups.transform(np.nanstd)\n        normalized_price_per_group_pd = (\n            converted_price[price_mean_per_dept.columns] - price_mean_per_dept\n        ) / (price_std_per_dept + 1e-6)\n\n        normalized_price_per_group = normalized_price_per_group_pd.values\n        np.savez(\n            normalized_price_file,\n            per_item=normalized_price_per_item,\n            per_group=normalized_price_per_group,\n        )\n    else:\n        normalized_price = np.load(normalized_price_file)\n        normalized_price_per_item = normalized_price[\"per_item\"]\n        normalized_price_per_group = normalized_price[\"per_group\"]\n\n    price_feature = np.nan_to_num(price_feature)\n    normalized_price_per_item = np.nan_to_num(normalized_price_per_item)\n    normalized_price_per_group = np.nan_to_num(normalized_price_per_group)\n\n    all_price_features = np.stack(\n        [normalized_price_per_item, normalized_price_per_group], axis=1\n    )  # 30490 * 2 * T\n    # dynamic_real = np.concatenate([snap_features_expand, all_price_features, event_features_expand], axis=1)    # 30490 * 6 * T\n    dynamic_real = np.concatenate(\n        [all_price_features, event_features_expand], axis=1\n    )  # 30490 * 6 * T\n\n    train_dynamic_real = dynamic_real[..., : VAL_START - 1]\n    val_dynamic_real = dynamic_real[..., : TEST_START - 1]\n    test_dynamic_real = dynamic_real[..., :-PREDICTION_LENGTH]\n\n    m5_dates = [pd.Timestamp(\"2011-01-29\") for _ in range(len(sales_train_evaluation))]\n\n    train_ds = ListDataset(\n        [\n            {\n                FieldName.TARGET: target,\n                FieldName.START: start,\n                FieldName.FEAT_DYNAMIC_REAL: fdr,\n                FieldName.FEAT_STATIC_CAT: fsc,\n            }\n            for (target, start, fdr, fsc) in zip(\n                train_target_values, m5_dates, train_dynamic_real, stat_cat\n            )\n        ],\n        freq=\"D\",\n    )\n\n    val_ds = ListDataset(\n        [\n            {\n                FieldName.TARGET: target,\n                FieldName.START: start,\n                FieldName.FEAT_DYNAMIC_REAL: fdr,\n                FieldName.FEAT_STATIC_CAT: fsc,\n            }\n            for (target, start, fdr, fsc) in zip(\n                val_target_values, m5_dates, val_dynamic_real, stat_cat\n            )\n        ],\n        freq=\"D\",\n    )\n\n    test_ds = ListDataset(\n        [\n            {\n                FieldName.TARGET: target,\n                FieldName.START: start,\n                FieldName.FEAT_DYNAMIC_REAL: fdr,\n                FieldName.FEAT_STATIC_CAT: fsc,\n            }\n            for (target, start, fdr, fsc) in zip(\n                test_target_values, m5_dates, test_dynamic_real, stat_cat\n            )\n        ],\n        freq=\"D\",\n    )\n\n    return train_ds, val_ds, test_ds, stat_cat_cardinalities\n</code></pre>"},{"location":"api/tpk/testing/datasets/m5/accuracy_evaluator/calculate_and_save_data/","title":"Calculate and save data","text":""},{"location":"api/tpk/testing/datasets/m5/accuracy_evaluator/calculate_and_save_data/#tpk.testing.datasets.m5.accuracy_evaluator.calculate_and_save_data","title":"tpk.testing.datasets.m5.accuracy_evaluator.calculate_and_save_data","text":"<pre><code>calculate_and_save_data(data_path: str, prediction_start: int) -&gt; Tuple[Any, Any, Any, Any, Any]\n</code></pre> Source code in <code>tpk/testing/datasets/m5/accuracy_evaluator.py</code> <pre><code>def calculate_and_save_data(\n    data_path: str, prediction_start: int\n) -&gt; Tuple[Any, Any, Any, Any, Any]:\n    # Sales quantities:\n    sales = pd.read_csv(data_path + \"/sales_train_evaluation.csv\")\n\n    # Calendar to get week number to join sell prices:\n    calendar = pd.read_csv(data_path + \"/calendar.csv\")\n    calendar = reduce_mem_usage(calendar)\n\n    # Sell prices to calculate sales in USD:\n    sell_prices = pd.read_csv(data_path + \"/sell_prices.csv\")\n    sell_prices = reduce_mem_usage(sell_prices)\n\n    # Dataframe with only last 28 days:\n    cols = [f\"d_{i}\" for i in range(prediction_start - 28, prediction_start)]\n    data = sales[[\"id\", \"store_id\", \"item_id\"] + cols]\n\n    # To long form:\n    data = data.melt(\n        id_vars=[\"id\", \"store_id\", \"item_id\"], var_name=\"d\", value_name=\"sale\"\n    )\n\n    # Add week of year column from 'calendar':\n    data = pd.merge(data, calendar, how=\"left\", left_on=[\"d\"], right_on=[\"d\"])\n\n    data = data[[\"id\", \"store_id\", \"item_id\", \"sale\", \"d\", \"wm_yr_wk\"]]\n\n    # Add weekly price from 'sell_prices':\n    data = data.merge(sell_prices, on=[\"store_id\", \"item_id\", \"wm_yr_wk\"], how=\"left\")\n    data.drop(columns=[\"wm_yr_wk\"], inplace=True)\n\n    # Calculate daily sales in USD:\n    data[\"sale_usd\"] = data[\"sale\"] * data[\"sell_price\"]\n\n    # List of categories combinations for aggregations as defined in docs:\n    dummies_list = [\n        sales.state_id,\n        sales.store_id,\n        sales.cat_id,\n        sales.dept_id,\n        sales.state_id + \"_\" + sales.cat_id,\n        sales.state_id + \"_\" + sales.dept_id,\n        sales.store_id + \"_\" + sales.cat_id,\n        sales.store_id + \"_\" + sales.dept_id,\n        sales.item_id,\n        sales.state_id + \"_\" + sales.item_id,\n        sales.id,\n    ]\n\n    ## First element Level_0 aggregation 'all_sales':\n    dummies_df_list = [\n        pd.DataFrame(\n            np.ones(sales.shape[0]).astype(np.int8),\n            index=sales.index,\n            columns=[\"all\"],\n        ).T\n    ]\n\n    # List of dummy dataframes:\n    for _, cats in enumerate(dummies_list):\n        cat_dtype = pd.api.types.CategoricalDtype(\n            categories=pd.unique(cats.values), ordered=True\n        )\n        ordered_cat = cats.astype(cat_dtype)\n        dummies_df_list += [\n            pd.get_dummies(ordered_cat, drop_first=False, dtype=np.int8).T\n        ]\n\n    # [1, 3, 10, 3, 7, 9, 21, 30, 70, 3049, 9147, 30490]\n    # Concat dummy dataframes in one go:\n    ## Level is constructed for free.\n    roll_mat_df = pd.concat(\n        dummies_df_list, keys=list(range(12)), names=[\"level\", \"id\"]\n    )  # .astype(np.int8, copy=False)\n\n    # Save values as sparse matrix &amp; save index for future reference:\n    roll_index = roll_mat_df.index\n    roll_mat_csr = csr_matrix(roll_mat_df.values)\n\n    # nosemgrep\n    roll_mat_df.to_pickle(data_path + \"/ordered_roll_mat_df.pkl\")\n\n    del dummies_df_list, roll_mat_df\n    gc.collect()\n\n    S = get_s(roll_mat_csr, sales, prediction_start)\n    W = get_w(roll_mat_csr, data[[\"id\", \"sale_usd\"]])\n    SW = W / np.sqrt(S)\n\n    sw_df = pd.DataFrame(\n        np.stack((S, W, SW), axis=-1),\n        index=roll_index,\n        columns=[\"s\", \"w\", \"sw\"],\n    )\n    # nosemgrep\n    sw_df.to_pickle(data_path + f\"/ordered_sw_df_p{prediction_start}.pkl\")\n\n    return sales, S, W, SW, roll_mat_csr\n</code></pre>"},{"location":"api/tpk/testing/datasets/m5/accuracy_evaluator/evaluate_wrmsse/","title":"Evaluate wrmsse","text":""},{"location":"api/tpk/testing/datasets/m5/accuracy_evaluator/evaluate_wrmsse/#tpk.testing.datasets.m5.accuracy_evaluator.evaluate_wrmsse","title":"tpk.testing.datasets.m5.accuracy_evaluator.evaluate_wrmsse","text":"<pre><code>evaluate_wrmsse(data_path: str, prediction: Any, prediction_start: int, score_only: bool = True) -&gt; Any\n</code></pre> Source code in <code>tpk/testing/datasets/m5/accuracy_evaluator.py</code> <pre><code>def evaluate_wrmsse(\n    data_path: str, prediction: Any, prediction_start: int, score_only: bool = True\n) -&gt; Any:\n    # Loading data in two ways:\n    # if S, W, SW are calculated in advance, load from pickle files\n    # otherwise, calculate from scratch\n    if os.path.isfile(\n        data_path + f\"/ordered_sw_df_p{prediction_start}.pkl\"\n    ) and os.path.isfile(data_path + \"/ordered_roll_mat_df.pkl\"):\n        print(\"load precalculated data\")\n        # Sales quantities:\n        sales = pd.read_csv(data_path + \"/sales_train_evaluation.csv\")\n        S, W, SW, roll_mat_csr = load_precalculated_data(data_path, prediction_start)\n    else:\n        print(\"load data from scratch\")\n        sales, S, W, SW, roll_mat_csr = calculate_and_save_data(\n            data_path, prediction_start\n        )\n\n    # Ground truth:\n    dayCols = [\n        f\"d_{i}\" for i in range(prediction_start, prediction_start + prediction_length)\n    ]\n    y_true = sales[dayCols]\n\n    error = prediction - y_true.values\n    results = wrmsse(error, score_only, roll_mat_csr, S, W, SW)\n\n    return results\n</code></pre>"},{"location":"api/tpk/testing/datasets/m5/accuracy_evaluator/get_s/","title":"Get s","text":""},{"location":"api/tpk/testing/datasets/m5/accuracy_evaluator/get_s/#tpk.testing.datasets.m5.accuracy_evaluator.get_s","title":"tpk.testing.datasets.m5.accuracy_evaluator.get_s","text":"<pre><code>get_s(roll_mat_csr: csr_matrix, sales: pd.DataFrame, prediction_start: int) -&gt; Any\n</code></pre> Source code in <code>tpk/testing/datasets/m5/accuracy_evaluator.py</code> <pre><code>def get_s(roll_mat_csr: csr_matrix, sales: pd.DataFrame, prediction_start: int) -&gt; Any:\n    # Rollup sales:\n    d_name = [\"d_\" + str(i) for i in range(1, prediction_start)]\n    sales_train_val = roll_mat_csr * sales[d_name].values\n\n    no_sales = np.cumsum(sales_train_val, axis=1) == 0\n\n    # Denominator of RMSSE / RMSSE\n    diff = np.diff(sales_train_val, axis=1)\n    diff = np.where(no_sales[:, 1:], np.nan, diff)\n\n    weight1 = np.nanmean(diff**2, axis=1)\n    weight1[np.isnan(weight1)] = 1e-9\n\n    return weight1\n</code></pre>"},{"location":"api/tpk/testing/datasets/m5/accuracy_evaluator/get_w/","title":"Get w","text":""},{"location":"api/tpk/testing/datasets/m5/accuracy_evaluator/get_w/#tpk.testing.datasets.m5.accuracy_evaluator.get_w","title":"tpk.testing.datasets.m5.accuracy_evaluator.get_w","text":"<pre><code>get_w(roll_mat_csr: csr_matrix, sale_usd: pd.DataFrame) -&gt; Any\n</code></pre> Source code in <code>tpk/testing/datasets/m5/accuracy_evaluator.py</code> <pre><code>def get_w(roll_mat_csr: csr_matrix, sale_usd: pd.DataFrame) -&gt; Any:\n    \"\"\" \"\"\"\n    # Calculate the total sales in USD for each item id:\n    total_sales_usd = (\n        sale_usd.groupby([\"id\"], sort=False)[\"sale_usd\"].apply(np.sum).values\n    )\n\n    # Roll up total sales by ids to higher levels:\n    weight2 = roll_mat_csr * total_sales_usd\n\n    return (\n        12 * weight2 / np.sum(weight2)\n    )  # weight2/(np.sum(weight2) / 12) : np.sum(weight2)\uc740 \ubaa8\ub4e0 \ud569\uc758 12\ubc30\uc784\n</code></pre>"},{"location":"api/tpk/testing/datasets/m5/accuracy_evaluator/load_precalculated_data/","title":"Load precalculated data","text":""},{"location":"api/tpk/testing/datasets/m5/accuracy_evaluator/load_precalculated_data/#tpk.testing.datasets.m5.accuracy_evaluator.load_precalculated_data","title":"tpk.testing.datasets.m5.accuracy_evaluator.load_precalculated_data","text":"<pre><code>load_precalculated_data(data_path: str, prediction_start: int) -&gt; Tuple[Any, Any, Any, csr_matrix]\n</code></pre> Source code in <code>tpk/testing/datasets/m5/accuracy_evaluator.py</code> <pre><code>def load_precalculated_data(\n    data_path: str, prediction_start: int\n) -&gt; Tuple[Any, Any, Any, csr_matrix]:\n    # Load S and W weights for WRMSSE calcualtions:\n    if not os.path.exists(data_path + f\"/ordered_sw_df_p{prediction_start}.pkl\"):\n        calculate_and_save_data(data_path, prediction_start)\n    # nosemgrep\n    sw_df = pd.read_pickle(\n        data_path + f\"/ordered_sw_df_p{prediction_start}.pkl\"\n    )  # nosec: [B301:blacklist]\n    S = sw_df.s.values\n    W = sw_df.w.values\n    SW = sw_df.sw.values\n\n    # Load roll up matrix to calcualte aggreagates:\n    # nosemgrep\n    roll_mat_df = pd.read_pickle(\n        data_path + \"/ordered_roll_mat_df.pkl\"\n    )  # nosec: [B301:blacklist]\n    roll_mat_csr = csr_matrix(roll_mat_df.values)\n    del roll_mat_df\n\n    return S, W, SW, roll_mat_csr\n</code></pre>"},{"location":"api/tpk/testing/datasets/m5/accuracy_evaluator/reduce_mem_usage/","title":"Reduce mem usage","text":""},{"location":"api/tpk/testing/datasets/m5/accuracy_evaluator/reduce_mem_usage/#tpk.testing.datasets.m5.accuracy_evaluator.reduce_mem_usage","title":"tpk.testing.datasets.m5.accuracy_evaluator.reduce_mem_usage","text":"<pre><code>reduce_mem_usage(df: pd.DataFrame, verbose: bool = True) -&gt; pd.DataFrame\n</code></pre> Source code in <code>tpk/testing/datasets/m5/accuracy_evaluator.py</code> <pre><code>def reduce_mem_usage(df: pd.DataFrame, verbose: bool = True) -&gt; pd.DataFrame:\n    numerics = [\"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n    start_mem = df.memory_usage().sum() / 1024**2\n    for col in df.columns:  # columns\n        col_type = df[col].dtypes\n        if col_type in numerics:  # numerics\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == \"int\":\n                if c_min &gt; np.iinfo(np.int8).min and c_max &lt; np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min &gt; np.iinfo(np.int16).min and c_max &lt; np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min &gt; np.iinfo(np.int32).min and c_max &lt; np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min &gt; np.iinfo(np.int64).min and c_max &lt; np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if (\n                    c_min &gt; np.finfo(np.float16).min\n                    and c_max &lt; np.finfo(np.float16).max\n                ):\n                    df[col] = df[col].astype(np.float16)\n                elif (\n                    c_min &gt; np.finfo(np.float32).min\n                    and c_max &lt; np.finfo(np.float32).max\n                ):\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose:\n        print(\n            \"Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)\".format(\n                end_mem, 100 * (start_mem - end_mem) / start_mem\n            )\n        )\n    return df\n</code></pre>"},{"location":"api/tpk/testing/datasets/m5/accuracy_evaluator/rollup/","title":"Rollup","text":""},{"location":"api/tpk/testing/datasets/m5/accuracy_evaluator/rollup/#tpk.testing.datasets.m5.accuracy_evaluator.rollup","title":"tpk.testing.datasets.m5.accuracy_evaluator.rollup","text":"<pre><code>rollup(roll_mat_csr: csr_matrix, v: Any) -&gt; Any\n</code></pre> <p>v - np.array of size (30490 rows, n day columns) v_rolledup - array of size (n, 42840)</p> Source code in <code>tpk/testing/datasets/m5/accuracy_evaluator.py</code> <pre><code>def rollup(roll_mat_csr: csr_matrix, v: Any) -&gt; Any:\n    \"\"\"\n    v - np.array of size (30490 rows, n day columns)\n    v_rolledup - array of size (n, 42840)\n    \"\"\"\n    return roll_mat_csr * v  # (v.T*roll_mat_csr.T).T\n</code></pre>"},{"location":"api/tpk/testing/datasets/m5/accuracy_evaluator/wrmsse/","title":"Wrmsse","text":""},{"location":"api/tpk/testing/datasets/m5/accuracy_evaluator/wrmsse/#tpk.testing.datasets.m5.accuracy_evaluator.wrmsse","title":"tpk.testing.datasets.m5.accuracy_evaluator.wrmsse","text":"<pre><code>wrmsse(error: float, score_only: bool, roll_mat_csr: csr_matrix, s: Any, w: Any, sw: Any) -&gt; Any\n</code></pre> <p>preds - Predictions: pd.DataFrame of size (30490 rows, N day columns) y_true - True values: pd.DataFrame of size (30490 rows, N day columns) sequence_length - np.array of size (42840,) sales_weight - sales weights based on last 28 days: np.array (42840,)</p> Source code in <code>tpk/testing/datasets/m5/accuracy_evaluator.py</code> <pre><code>def wrmsse(\n    error: float, score_only: bool, roll_mat_csr: csr_matrix, s: Any, w: Any, sw: Any\n) -&gt; Any:\n    \"\"\"\n    preds - Predictions: pd.DataFrame of size (30490 rows, N day columns)\n    y_true - True values: pd.DataFrame of size (30490 rows, N day columns)\n    sequence_length - np.array of size (42840,)\n    sales_weight - sales weights based on last 28 days: np.array (42840,)\n    \"\"\"\n\n    if score_only:\n        return (\n            np.sum(\n                np.sqrt(np.mean(np.square(rollup(roll_mat_csr, error)), axis=1)) * sw\n            )\n            / 12\n        )  # &lt;-used to be mistake here\n    else:\n        score_matrix = (\n            np.square(rollup(roll_mat_csr, error)) * np.square(w)[:, None]\n        ) / s[:, None]\n        wrmsse_i = np.sqrt(np.mean(score_matrix, axis=1))\n        wrmsse_raw = np.sqrt(score_matrix)\n\n        aggregation_count = [1, 3, 10, 3, 7, 9, 21, 30, 70, 3049, 9147, 30490]\n\n        idx = 0\n        aggregated_wrmsse = np.zeros(12)\n        aggregated_wrmsse_per_day = np.zeros([12, prediction_length])\n        for i, count in enumerate(aggregation_count):\n            endIdx = idx + count\n            aggregated_wrmsse[i] = wrmsse_i[idx:endIdx].sum()\n            aggregated_wrmsse_per_day[i] = wrmsse_raw[idx:endIdx, :].sum(axis=0)\n            idx = endIdx\n\n        # score == aggregated_wrmsse.mean()\n        wrmsse = np.sum(wrmsse_i) / 12  # &lt;-used to be mistake here\n\n        return (\n            wrmsse,\n            aggregated_wrmsse,\n            aggregated_wrmsse_per_day,\n            score_matrix,\n        )\n</code></pre>"},{"location":"api/tpk/testing/datasets/m5/load_dataset/convert_price_file/","title":"Convert price file","text":""},{"location":"api/tpk/testing/datasets/m5/load_dataset/convert_price_file/#tpk.testing.datasets.m5.load_dataset.convert_price_file","title":"tpk.testing.datasets.m5.load_dataset.convert_price_file","text":"<pre><code>convert_price_file(m5_input_path: str) -&gt; None\n</code></pre> Source code in <code>tpk/testing/datasets/m5/load_dataset.py</code> <pre><code>def convert_price_file(m5_input_path: str) -&gt; None:\n    # load data\n    calendar = pd.read_csv(f\"{m5_input_path}/calendar.csv\")\n    sales_train_evaluation = pd.read_csv(f\"{m5_input_path}/sales_train_evaluation.csv\")\n    sell_prices = pd.read_csv(f\"{m5_input_path}/sell_prices.csv\")\n\n    # assign price for all days\n    week_and_day = calendar[[\"wm_yr_wk\", \"d\"]]\n\n    price_all_days_items = pd.merge(\n        week_and_day, sell_prices, on=[\"wm_yr_wk\"], how=\"left\"\n    )  # join on week number\n    price_all_days_items = price_all_days_items.drop([\"wm_yr_wk\"], axis=1)\n\n    # convert days to column\n    price_all_items = price_all_days_items.pivot_table(\n        values=\"sell_price\", index=[\"store_id\", \"item_id\"], columns=\"d\"\n    )\n    price_all_items.reset_index(drop=False, inplace=True)\n\n    # reorder column\n    price_all_items = price_all_items.reindex(\n        [\"store_id\", \"item_id\"] + [\"d_%d\" % x for x in range(1, 1969 + 1)], axis=1\n    )\n\n    sales_keys = [\"id\", \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"]\n    sales_keys_pd = sales_train_evaluation[sales_keys]\n\n    # join with sales data\n    price_converted = pd.merge(\n        sales_keys_pd, price_all_items, on=[\"store_id\", \"item_id\"], how=\"left\"\n    )\n\n    # save file\n    price_converted.to_csv(\n        f\"{m5_input_path}/converted_price_evaluation.csv\", index=False\n    )\n</code></pre>"},{"location":"api/tpk/testing/datasets/m5/load_dataset/load_datasets/","title":"Load datasets","text":""},{"location":"api/tpk/testing/datasets/m5/load_dataset/load_datasets/#tpk.testing.datasets.m5.load_dataset.load_datasets","title":"tpk.testing.datasets.m5.load_dataset.load_datasets","text":"<pre><code>load_datasets(data_dir: str) -&gt; Tuple[ListDataset, ListDataset, ListDataset, List[int]]\n</code></pre> Source code in <code>tpk/testing/datasets/m5/load_dataset.py</code> <pre><code>def load_datasets(\n    data_dir: str,\n) -&gt; Tuple[ListDataset, ListDataset, ListDataset, List[int]]:\n    calendar = pd.read_csv(f\"{data_dir}/calendar.csv\")\n    sales_train_evaluation = pd.read_csv(f\"{data_dir}/sales_train_evaluation.csv\")\n\n    cal_features = calendar.drop(\n        [\n            \"date\",\n            \"wm_yr_wk\",\n            \"weekday\",\n            \"wday\",\n            \"month\",\n            \"year\",\n            \"event_name_1\",\n            \"event_name_2\",\n            \"d\",\n        ],\n        axis=1,\n    )\n    cal_features[\"event_type_1\"] = cal_features[\"event_type_1\"].apply(\n        lambda x: 0 if str(x) == \"nan\" else 1\n    )\n    cal_features[\"event_type_2\"] = cal_features[\"event_type_2\"].apply(\n        lambda x: 0 if str(x) == \"nan\" else 1\n    )\n\n    event_features = cal_features.values.T\n    event_features_expand = np.tile(event_features, (len(sales_train_evaluation), 1, 1))\n\n    state_ids = sales_train_evaluation[\"state_id\"].astype(\"category\").cat.codes.values\n    state_ids_un, state_ids_counts = np.unique(state_ids, return_counts=True)\n\n    store_ids = sales_train_evaluation[\"store_id\"].astype(\"category\").cat.codes.values\n    store_ids_un, store_ids_counts = np.unique(store_ids, return_counts=True)\n\n    cat_ids = sales_train_evaluation[\"cat_id\"].astype(\"category\").cat.codes.values\n    cat_ids_un, cat_ids_counts = np.unique(cat_ids, return_counts=True)\n\n    dept_ids = sales_train_evaluation[\"dept_id\"].astype(\"category\").cat.codes.values\n    dept_ids_un, dept_ids_counts = np.unique(dept_ids, return_counts=True)\n\n    item_ids = sales_train_evaluation[\"item_id\"].astype(\"category\").cat.codes.values\n    item_ids_un, item_ids_counts = np.unique(item_ids, return_counts=True)\n\n    stat_cat_list = [item_ids, dept_ids, cat_ids, store_ids, state_ids]\n    stat_cat = np.concatenate(stat_cat_list)\n    stat_cat = stat_cat.reshape(len(stat_cat_list), len(item_ids)).T  # type: ignore\n    stat_cat_cardinalities = [\n        len(item_ids_un),\n        len(dept_ids_un),\n        len(cat_ids_un),\n        len(store_ids_un),\n        len(state_ids_un),\n    ]  # type: ignore\n\n    train_df = sales_train_evaluation.drop(\n        [\"id\", \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"], axis=1\n    )\n    train_target_values = train_df.values\n\n    test_target_values = train_target_values.copy()\n    train_target_values = [ts[: -(2 * PREDICTION_LENGTH)] for ts in train_df.values]\n    val_target_values = [ts[:-PREDICTION_LENGTH] for ts in train_df.values]\n\n    # snap features\n    # snap_features = calendar[['snap_CA', 'snap_TX', 'snap_WI']]\n    # snap_features = snap_features.values.T\n    # snap_features_expand = np.array([snap_features] * len(sales_train_evaluation))    # 30490 * 3 * T\n\n    # sell_prices\n    converted_price_file = Path(f\"{data_dir}/converted_price_evaluation.csv\")\n    if not converted_price_file.exists():\n        convert_price_file(data_dir)\n    converted_price = pd.read_csv(converted_price_file)\n\n    price_feature = converted_price.drop(\n        [\"id\", \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"], axis=1\n    ).values\n\n    # normalized sell prices\n    normalized_price_file = Path(f\"{data_dir}/normalized_price_evaluation.npz\")\n    if not normalized_price_file.exists():\n        # normalized sell prices per each item\n        price_mean_per_item = np.nanmean(price_feature, axis=1, keepdims=True)\n        price_std_per_item = np.nanstd(price_feature, axis=1, keepdims=True)\n        normalized_price_per_item = (price_feature - price_mean_per_item) / (\n            price_std_per_item + 1e-6\n        )\n\n        # normalized sell prices per day within the same dept\n        dept_groups = converted_price.drop(\n            [\"id\", \"item_id\", \"cat_id\", \"store_id\", \"state_id\"], axis=1\n        ).groupby(\"dept_id\")\n        price_mean_per_dept = dept_groups.transform(np.nanmean)\n        price_std_per_dept = dept_groups.transform(np.nanstd)\n        normalized_price_per_group_pd = (\n            converted_price[price_mean_per_dept.columns] - price_mean_per_dept\n        ) / (price_std_per_dept + 1e-6)\n\n        normalized_price_per_group = normalized_price_per_group_pd.values\n        np.savez(\n            normalized_price_file,\n            per_item=normalized_price_per_item,\n            per_group=normalized_price_per_group,\n        )\n    else:\n        normalized_price = np.load(normalized_price_file)\n        normalized_price_per_item = normalized_price[\"per_item\"]\n        normalized_price_per_group = normalized_price[\"per_group\"]\n\n    price_feature = np.nan_to_num(price_feature)\n    normalized_price_per_item = np.nan_to_num(normalized_price_per_item)\n    normalized_price_per_group = np.nan_to_num(normalized_price_per_group)\n\n    all_price_features = np.stack(\n        [normalized_price_per_item, normalized_price_per_group], axis=1\n    )  # 30490 * 2 * T\n    # dynamic_real = np.concatenate([snap_features_expand, all_price_features, event_features_expand], axis=1)    # 30490 * 6 * T\n    dynamic_real = np.concatenate(\n        [all_price_features, event_features_expand], axis=1\n    )  # 30490 * 6 * T\n\n    train_dynamic_real = dynamic_real[..., : VAL_START - 1]\n    val_dynamic_real = dynamic_real[..., : TEST_START - 1]\n    test_dynamic_real = dynamic_real[..., :-PREDICTION_LENGTH]\n\n    m5_dates = [pd.Timestamp(\"2011-01-29\") for _ in range(len(sales_train_evaluation))]\n\n    train_ds = ListDataset(\n        [\n            {\n                FieldName.TARGET: target,\n                FieldName.START: start,\n                FieldName.FEAT_DYNAMIC_REAL: fdr,\n                FieldName.FEAT_STATIC_CAT: fsc,\n            }\n            for (target, start, fdr, fsc) in zip(\n                train_target_values, m5_dates, train_dynamic_real, stat_cat\n            )\n        ],\n        freq=\"D\",\n    )\n\n    val_ds = ListDataset(\n        [\n            {\n                FieldName.TARGET: target,\n                FieldName.START: start,\n                FieldName.FEAT_DYNAMIC_REAL: fdr,\n                FieldName.FEAT_STATIC_CAT: fsc,\n            }\n            for (target, start, fdr, fsc) in zip(\n                val_target_values, m5_dates, val_dynamic_real, stat_cat\n            )\n        ],\n        freq=\"D\",\n    )\n\n    test_ds = ListDataset(\n        [\n            {\n                FieldName.TARGET: target,\n                FieldName.START: start,\n                FieldName.FEAT_DYNAMIC_REAL: fdr,\n                FieldName.FEAT_STATIC_CAT: fsc,\n            }\n            for (target, start, fdr, fsc) in zip(\n                test_target_values, m5_dates, test_dynamic_real, stat_cat\n            )\n        ],\n        freq=\"D\",\n    )\n\n    return train_ds, val_ds, test_ds, stat_cat_cardinalities\n</code></pre>"},{"location":"api/tpk/torch/MyEstimator/","title":"MyEstimator","text":""},{"location":"api/tpk/torch/MyEstimator/#tpk.torch.MyEstimator","title":"tpk.torch.MyEstimator","text":"<pre><code>MyEstimator(*, model_cls: Type[LightningModule], freq: str, prediction_length: int, epochs: int, context_length: Optional[int] = None, n_block: int = 2, hidden_size: int = 128, weight_decay: float = 1e-08, dropout_rate: float = 0.1, patience: int = 10, num_feat_dynamic_real: int = 0, disable_future_feature: bool = False, num_feat_static_cat: int = 0, num_feat_static_real: int = 0, cardinality: Optional[List[int]] = None, embedding_dimension: Optional[List[int]] = None, distr_output: Optional[DistributionOutput] = None, loss: Optional[DistributionLoss] = None, scaling: bool = True, time_features: Optional[List[TimeFeature]] = None, batch_size: int = 32, num_batches_per_epoch: int = 50, trainer_kwargs: Optional[Dict[str, Any]] = None, train_sampler: Optional[InstanceSampler] = None, validation_sampler: Optional[InstanceSampler] = None)\n</code></pre> <p>             Bases: <code>PyTorchLightningEstimator</code></p> <p>Estimator class to train a TPK model.</p> <p>This class is uses the model defined in <code>TPKModel</code>, and wraps it into a <code>MyLightningModule</code> for training purposes: training is performed using PyTorch Lightning's <code>pl.Trainer</code> class.</p>"},{"location":"api/tpk/torch/MyEstimator/#tpk.torch.MyEstimator--parameters","title":"Parameters","text":"<p>freq     Frequency of the data to train on and predict. prediction_length     Length of the prediction horizon. context_length     Number of steps to unroll the RNN for before computing predictions     (default: None, in which case context_length = prediction_length). n_block     Number of TPK blocks (default: 2). hidden_size     Number of hidden size for each layer (default: 128). weight_decay     Weight decay regularization parameter (default: <code>1e-8</code>). dropout_rate     Dropout regularization parameter (default: 0.1). patience     Patience parameter for learning rate scheduler. num_feat_dynamic_real     Number of dynamic real features in the data (default: 0). num_feat_static_real     Number of static real features in the data (default: 0). num_feat_static_cat     Number of static categorical features in the data (default: 0). cardinality     Number of values of each categorical feature.     This must be set if <code>num_feat_static_cat &gt; 0</code> (default: None). embedding_dimension     Dimension of the embeddings for categorical features     (default: <code>[min(50, (cat+1)//2) for cat in cardinality]</code>). distr_output     Distribution to use to evaluate observations and sample predictions     (default: StudentTOutput()). loss     Loss to be optimized during training     (default: <code>NegativeLogLikelihood()</code>). scaling     Whether to automatically scale the target values (default: true). time_features     List of time features, from :py:mod:<code>gluonts.time_feature</code>, to use as     inputs of the RNN in addition to the provided data (default: None,     in which case these are automatically determined based on freq). batch_size     The size of the batches to be used for training (default: 32). num_batches_per_epoch     Number of batches to be processed in each training epoch     (default: 50). trainer_kwargs     Additional arguments to provide to <code>pl.Trainer</code> for construction. train_sampler     Controls the sampling of windows during training. validation_sampler     Controls the sampling of windows during validation.</p> Source code in <code>tpk/torch/estimator.py</code> <pre><code>@validated()  # type: ignore\ndef __init__(\n    self,\n    *,\n    model_cls: Type[LightningModule],\n    freq: str,\n    prediction_length: int,\n    epochs: int,\n    context_length: Optional[int] = None,\n    n_block: int = 2,\n    hidden_size: int = 128,\n    weight_decay: float = 1e-8,\n    dropout_rate: float = 0.1,\n    patience: int = 10,\n    num_feat_dynamic_real: int = 0,\n    disable_future_feature: bool = False,\n    num_feat_static_cat: int = 0,\n    num_feat_static_real: int = 0,\n    cardinality: Optional[List[int]] = None,\n    embedding_dimension: Optional[List[int]] = None,\n    distr_output: Optional[DistributionOutput] = None,\n    loss: Optional[DistributionLoss] = None,\n    scaling: bool = True,\n    time_features: Optional[List[TimeFeature]] = None,\n    batch_size: int = 32,\n    num_batches_per_epoch: int = 50,\n    trainer_kwargs: Optional[Dict[str, Any]] = None,\n    train_sampler: Optional[InstanceSampler] = None,\n    validation_sampler: Optional[InstanceSampler] = None,\n) -&gt; None:\n    default_trainer_kwargs = {\n        \"max_epochs\": 100,\n        \"gradient_clip_val\": 10.0,\n    }\n    if trainer_kwargs is not None:\n        default_trainer_kwargs.update(trainer_kwargs)\n    super().__init__(trainer_kwargs=default_trainer_kwargs)\n\n    self.model_cls = model_cls\n    self.epochs = epochs\n    self.freq = freq\n    self.context_length = (\n        context_length if context_length is not None else prediction_length\n    )\n    self.prediction_length = prediction_length\n    self.patience = patience\n    self.distr_output = StudentTOutput() if distr_output is None else distr_output\n    self.loss = NegativeLogLikelihood() if loss is None else loss\n    self.n_block = n_block\n    self.hidden_size = hidden_size\n    self.weight_decay = weight_decay\n    self.dropout_rate = dropout_rate\n    self.num_feat_dynamic_real = num_feat_dynamic_real\n    self.disable_future_feature = disable_future_feature\n    self.num_feat_static_cat = num_feat_static_cat\n    self.num_feat_static_real = num_feat_static_real\n    self.cardinality = (\n        cardinality if cardinality and num_feat_static_cat &gt; 0 else [1]\n    )\n    self.embedding_dimension = embedding_dimension\n    self.scaling = scaling\n    self.time_features = (\n        time_features\n        if time_features is not None\n        else time_features_from_frequency_str(self.freq)\n    )\n\n    self.batch_size = batch_size\n    self.num_batches_per_epoch = num_batches_per_epoch\n\n    self.train_sampler = train_sampler or ExpectedNumInstanceSampler(\n        num_instances=1.0, min_future=prediction_length\n    )\n    self.validation_sampler = validation_sampler or ValidationSplitSampler(\n        min_future=prediction_length\n    )\n</code></pre>"},{"location":"api/tpk/torch/MyEstimator/#tpk.torch.MyEstimator.batch_size","title":"batch_size  <code>instance-attribute</code>","text":"<pre><code>batch_size = batch_size\n</code></pre>"},{"location":"api/tpk/torch/MyEstimator/#tpk.torch.MyEstimator.cardinality","title":"cardinality  <code>instance-attribute</code>","text":"<pre><code>cardinality = cardinality if cardinality and num_feat_static_cat &gt; 0 else [1]\n</code></pre>"},{"location":"api/tpk/torch/MyEstimator/#tpk.torch.MyEstimator.context_length","title":"context_length  <code>instance-attribute</code>","text":"<pre><code>context_length = context_length if context_length is not None else prediction_length\n</code></pre>"},{"location":"api/tpk/torch/MyEstimator/#tpk.torch.MyEstimator.disable_future_feature","title":"disable_future_feature  <code>instance-attribute</code>","text":"<pre><code>disable_future_feature = disable_future_feature\n</code></pre>"},{"location":"api/tpk/torch/MyEstimator/#tpk.torch.MyEstimator.distr_output","title":"distr_output  <code>instance-attribute</code>","text":"<pre><code>distr_output = StudentTOutput() if distr_output is None else distr_output\n</code></pre>"},{"location":"api/tpk/torch/MyEstimator/#tpk.torch.MyEstimator.dropout_rate","title":"dropout_rate  <code>instance-attribute</code>","text":"<pre><code>dropout_rate = dropout_rate\n</code></pre>"},{"location":"api/tpk/torch/MyEstimator/#tpk.torch.MyEstimator.embedding_dimension","title":"embedding_dimension  <code>instance-attribute</code>","text":"<pre><code>embedding_dimension = embedding_dimension\n</code></pre>"},{"location":"api/tpk/torch/MyEstimator/#tpk.torch.MyEstimator.epochs","title":"epochs  <code>instance-attribute</code>","text":"<pre><code>epochs = epochs\n</code></pre>"},{"location":"api/tpk/torch/MyEstimator/#tpk.torch.MyEstimator.freq","title":"freq  <code>instance-attribute</code>","text":"<pre><code>freq = freq\n</code></pre>"},{"location":"api/tpk/torch/MyEstimator/#tpk.torch.MyEstimator.hidden_size","title":"hidden_size  <code>instance-attribute</code>","text":"<pre><code>hidden_size = hidden_size\n</code></pre>"},{"location":"api/tpk/torch/MyEstimator/#tpk.torch.MyEstimator.loss","title":"loss  <code>instance-attribute</code>","text":"<pre><code>loss = NegativeLogLikelihood() if loss is None else loss\n</code></pre>"},{"location":"api/tpk/torch/MyEstimator/#tpk.torch.MyEstimator.model_cls","title":"model_cls  <code>instance-attribute</code>","text":"<pre><code>model_cls = model_cls\n</code></pre>"},{"location":"api/tpk/torch/MyEstimator/#tpk.torch.MyEstimator.n_block","title":"n_block  <code>instance-attribute</code>","text":"<pre><code>n_block = n_block\n</code></pre>"},{"location":"api/tpk/torch/MyEstimator/#tpk.torch.MyEstimator.num_batches_per_epoch","title":"num_batches_per_epoch  <code>instance-attribute</code>","text":"<pre><code>num_batches_per_epoch = num_batches_per_epoch\n</code></pre>"},{"location":"api/tpk/torch/MyEstimator/#tpk.torch.MyEstimator.num_feat_dynamic_real","title":"num_feat_dynamic_real  <code>instance-attribute</code>","text":"<pre><code>num_feat_dynamic_real = num_feat_dynamic_real\n</code></pre>"},{"location":"api/tpk/torch/MyEstimator/#tpk.torch.MyEstimator.num_feat_static_cat","title":"num_feat_static_cat  <code>instance-attribute</code>","text":"<pre><code>num_feat_static_cat = num_feat_static_cat\n</code></pre>"},{"location":"api/tpk/torch/MyEstimator/#tpk.torch.MyEstimator.num_feat_static_real","title":"num_feat_static_real  <code>instance-attribute</code>","text":"<pre><code>num_feat_static_real = num_feat_static_real\n</code></pre>"},{"location":"api/tpk/torch/MyEstimator/#tpk.torch.MyEstimator.patience","title":"patience  <code>instance-attribute</code>","text":"<pre><code>patience = patience\n</code></pre>"},{"location":"api/tpk/torch/MyEstimator/#tpk.torch.MyEstimator.prediction_length","title":"prediction_length  <code>instance-attribute</code>","text":"<pre><code>prediction_length = prediction_length\n</code></pre>"},{"location":"api/tpk/torch/MyEstimator/#tpk.torch.MyEstimator.scaling","title":"scaling  <code>instance-attribute</code>","text":"<pre><code>scaling = scaling\n</code></pre>"},{"location":"api/tpk/torch/MyEstimator/#tpk.torch.MyEstimator.time_features","title":"time_features  <code>instance-attribute</code>","text":"<pre><code>time_features = time_features if time_features is not None else time_features_from_frequency_str(self.freq)\n</code></pre>"},{"location":"api/tpk/torch/MyEstimator/#tpk.torch.MyEstimator.train_sampler","title":"train_sampler  <code>instance-attribute</code>","text":"<pre><code>train_sampler = train_sampler or ExpectedNumInstanceSampler(num_instances=1.0, min_future=prediction_length)\n</code></pre>"},{"location":"api/tpk/torch/MyEstimator/#tpk.torch.MyEstimator.validation_sampler","title":"validation_sampler  <code>instance-attribute</code>","text":"<pre><code>validation_sampler = validation_sampler or ValidationSplitSampler(min_future=prediction_length)\n</code></pre>"},{"location":"api/tpk/torch/MyEstimator/#tpk.torch.MyEstimator.weight_decay","title":"weight_decay  <code>instance-attribute</code>","text":"<pre><code>weight_decay = weight_decay\n</code></pre>"},{"location":"api/tpk/torch/MyEstimator/#tpk.torch.MyEstimator.create_lightning_module","title":"create_lightning_module","text":"<pre><code>create_lightning_module() -&gt; LightningModule\n</code></pre> Source code in <code>tpk/torch/estimator.py</code> <pre><code>def create_lightning_module(self) -&gt; LightningModule:\n    model = self.model_cls(\n        freq=self.freq,\n        context_length=self.context_length,\n        prediction_length=self.prediction_length,\n        num_feat_dynamic_real=(\n            self.num_feat_dynamic_real + len(self.time_features)\n        ),\n        num_future_feat=(\n            # len(self.time_features)\n            0\n            if self.disable_future_feature\n            else self.num_feat_dynamic_real + len(self.time_features)\n        ),\n        num_feat_static_real=max(1, self.num_feat_static_real),\n        num_feat_static_cat=max(1, self.num_feat_static_cat),\n        cardinality=self.cardinality,\n        embedding_dimension=self.embedding_dimension,\n        n_block=self.n_block,\n        hidden_size=self.hidden_size,\n        distr_output=self.distr_output,\n        dropout_rate=self.dropout_rate,\n        scaling=self.scaling,\n    )\n\n    return MyLightningModule(  # type: ignore\n        model=model,\n        loss=self.loss,\n        weight_decay=self.weight_decay,\n        patience=self.patience,\n        epochs=self.epochs,\n        steps_per_epoch=self.num_batches_per_epoch,\n    )\n</code></pre>"},{"location":"api/tpk/torch/MyEstimator/#tpk.torch.MyEstimator.create_predictor","title":"create_predictor","text":"<pre><code>create_predictor(transformation: Transformation, module: LightningModule) -&gt; PyTorchPredictor\n</code></pre> Source code in <code>tpk/torch/estimator.py</code> <pre><code>def create_predictor(\n    self,\n    transformation: Transformation,\n    module: LightningModule,\n) -&gt; PyTorchPredictor:\n    prediction_splitter = self._create_instance_splitter(module, \"test\")\n\n    return PyTorchPredictor(\n        input_transform=transformation + prediction_splitter,\n        input_names=PREDICTION_INPUT_NAMES,\n        prediction_net=module,\n        forecast_generator=DistributionForecastGenerator(self.distr_output),\n        batch_size=self.batch_size,\n        prediction_length=self.prediction_length,\n        device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n    )\n</code></pre>"},{"location":"api/tpk/torch/MyEstimator/#tpk.torch.MyEstimator.create_training_data_loader","title":"create_training_data_loader","text":"<pre><code>create_training_data_loader(data: Dataset, module: LightningModule, shuffle_buffer_length: Optional[int] = None, **kwargs: Any) -&gt; Any\n</code></pre> Source code in <code>tpk/torch/estimator.py</code> <pre><code>def create_training_data_loader(\n    self,\n    data: Dataset,\n    module: LightningModule,\n    shuffle_buffer_length: Optional[int] = None,\n    **kwargs: Any,\n) -&gt; Any:\n    transformation = self._create_instance_splitter(\n        module, \"training\"\n    ) + SelectFields(TRAINING_INPUT_NAMES)\n\n    training_instances = transformation.apply(\n        Cyclic(data)\n        if shuffle_buffer_length is None\n        else PseudoShuffled(\n            Cyclic(data), shuffle_buffer_length=shuffle_buffer_length\n        )\n    )\n\n    return IterableSlice(\n        iter(\n            # nosemgrep\n            DataLoader(\n                IterableDataset(training_instances),\n                batch_size=self.batch_size,\n                num_workers=2,\n                persistent_workers=True,\n                **kwargs,\n            )\n        ),\n        self.num_batches_per_epoch,\n    )\n</code></pre>"},{"location":"api/tpk/torch/MyEstimator/#tpk.torch.MyEstimator.create_transformation","title":"create_transformation","text":"<pre><code>create_transformation() -&gt; Transformation\n</code></pre> Source code in <code>tpk/torch/estimator.py</code> <pre><code>def create_transformation(self) -&gt; Transformation:\n    remove_field_names = []\n    if self.num_feat_static_real == 0:\n        remove_field_names.append(FieldName.FEAT_STATIC_REAL)\n    if self.num_feat_dynamic_real == 0:\n        remove_field_names.append(FieldName.FEAT_DYNAMIC_REAL)\n\n    return Chain(\n        [RemoveFields(field_names=remove_field_names)]\n        + (\n            [SetField(output_field=FieldName.FEAT_STATIC_CAT, value=[0])]\n            if not self.num_feat_static_cat &gt; 0\n            else []\n        )\n        + (\n            [SetField(output_field=FieldName.FEAT_STATIC_REAL, value=[0.0])]\n            if not self.num_feat_static_real &gt; 0\n            else []\n        )\n        + [\n            AsNumpyArray(\n                field=FieldName.FEAT_STATIC_CAT,\n                expected_ndim=1,\n                dtype=int,\n            ),\n            AsNumpyArray(\n                field=FieldName.FEAT_STATIC_REAL,\n                expected_ndim=1,\n            ),\n            AsNumpyArray(\n                field=FieldName.TARGET,\n                # in the following line, we add 1 for the time dimension\n                expected_ndim=1 + len(self.distr_output.event_shape),\n            ),\n            AddObservedValuesIndicator(\n                target_field=FieldName.TARGET,\n                output_field=FieldName.OBSERVED_VALUES,\n            ),\n            AddTimeFeatures(\n                start_field=FieldName.START,\n                target_field=FieldName.TARGET,\n                output_field=FieldName.FEAT_TIME,\n                time_features=self.time_features,\n                pred_length=self.prediction_length,\n            ),\n            VstackFeatures(\n                output_field=FieldName.FEAT_TIME,\n                input_fields=[FieldName.FEAT_TIME]\n                + (\n                    [FieldName.FEAT_DYNAMIC_REAL]\n                    if self.num_feat_dynamic_real &gt; 0\n                    else []\n                ),\n            ),\n        ]\n    )\n</code></pre>"},{"location":"api/tpk/torch/MyEstimator/#tpk.torch.MyEstimator.create_validation_data_loader","title":"create_validation_data_loader","text":"<pre><code>create_validation_data_loader(data: Dataset, module: LightningModule, **kwargs: Any) -&gt; DataLoader\n</code></pre> Source code in <code>tpk/torch/estimator.py</code> <pre><code>def create_validation_data_loader(\n    self,\n    data: Dataset,\n    module: LightningModule,\n    **kwargs: Any,\n) -&gt; DataLoader:  # type: ignore\n    transformation = self._create_instance_splitter(\n        module, \"validation\"\n    ) + SelectFields(TRAINING_INPUT_NAMES)\n\n    validation_instances = transformation.apply(data)\n\n    # nosemgrep\n    return DataLoader(\n        IterableDataset(validation_instances),\n        batch_size=self.batch_size,\n        num_workers=2,\n        persistent_workers=True,\n        **kwargs,\n    )\n</code></pre>"},{"location":"api/tpk/torch/MyEstimator/#tpk.torch.MyEstimator.train_model","title":"train_model","text":"<pre><code>train_model(training_data: Dataset, validation_data: Optional[Dataset] = None, from_predictor: Optional[PyTorchPredictor] = None, shuffle_buffer_length: Optional[int] = None, cache_data: bool = False, ckpt_path: Optional[str] = None, **kwargs: Any) -&gt; TrainOutput\n</code></pre> Source code in <code>tpk/torch/estimator.py</code> <pre><code>def train_model(\n    self,\n    training_data: Dataset,\n    validation_data: Optional[Dataset] = None,\n    from_predictor: Optional[PyTorchPredictor] = None,\n    shuffle_buffer_length: Optional[int] = None,\n    cache_data: bool = False,\n    ckpt_path: Optional[str] = None,\n    **kwargs: Any,\n) -&gt; TrainOutput:\n    transformation = self.create_transformation()\n\n    with env._let(max_idle_transforms=max(len(training_data), 100)):\n        transformed_training_data: Dataset = transformation.apply(\n            training_data, is_train=True\n        )\n        if cache_data:\n            transformed_training_data = Cached(transformed_training_data)\n\n        training_network = self.create_lightning_module()\n\n        training_data_loader = self.create_training_data_loader(\n            transformed_training_data,\n            training_network,\n            shuffle_buffer_length=shuffle_buffer_length,\n        )\n\n    validation_data_loader = None\n\n    if validation_data is not None:\n        with env._let(max_idle_transforms=max(len(validation_data), 100)):\n            transformed_validation_data: Dataset = transformation.apply(\n                validation_data, is_train=True\n            )\n            if cache_data:\n                transformed_validation_data = Cached(transformed_validation_data)\n\n            validation_data_loader = self.create_validation_data_loader(\n                transformed_validation_data,\n                training_network,\n            )\n\n    if from_predictor is not None:\n        training_network.load_state_dict(from_predictor.network.state_dict())\n\n    monitor = \"train_loss\" if validation_data is None else \"val_loss\"\n    checkpoint = pl.callbacks.ModelCheckpoint(\n        monitor=monitor, mode=\"min\", verbose=True\n    )\n\n    custom_callbacks = self.trainer_kwargs.pop(\"callbacks\", [])\n    trainer = pl.Trainer(\n        **{\n            \"accelerator\": \"auto\",\n            \"callbacks\": [checkpoint] + custom_callbacks,\n            **self.trainer_kwargs,\n        }\n    )\n\n    tuner = Tuner(trainer)\n\n    tuner.lr_find(\n        model=training_network,\n        train_dataloaders=training_data_loader,\n        val_dataloaders=validation_data_loader,\n        early_stop_threshold=50.0,\n    )\n\n    trainer.fit(\n        model=training_network,\n        train_dataloaders=training_data_loader,\n        val_dataloaders=validation_data_loader,\n        ckpt_path=ckpt_path,\n    )\n\n    if checkpoint.best_model_path != \"\":\n        logger.info(f\"Loading best model from {checkpoint.best_model_path}\")\n        best_model = training_network.__class__.load_from_checkpoint(\n            checkpoint.best_model_path\n        )\n    else:\n        best_model = training_network\n\n    return TrainOutput(\n        transformation=transformation,\n        trained_net=best_model,\n        trainer=trainer,\n        predictor=self.create_predictor(transformation, best_model),\n    )\n</code></pre>"},{"location":"api/tpk/torch/TPKModel/","title":"TPKModel","text":""},{"location":"api/tpk/torch/TPKModel/#tpk.torch.TPKModel","title":"tpk.torch.TPKModel","text":"<pre><code>TPKModel(freq: str, context_length: int, prediction_length: int, num_feat_dynamic_real: int, num_future_feat: int, num_feat_static_real: int, num_feat_static_cat: int, cardinality: List[int], distr_output: DistributionOutput, embedding_dimension: Optional[List[int]] = None, n_block: int = 2, hidden_size: int = 128, dropout_rate: float = 0.1, scaling: bool = True)\n</code></pre> <p>             Bases: <code>Module</code></p> <p>Module implementing the TPK model, see [SFG17]_.</p> <p>Note: the code of this model is unrelated to the implementation behind <code>SageMaker's TPK Forecasting Algorithm &lt;https://docs.aws.amazon.com/sagemaker/latest/dg/deepar.html&gt;</code>_.</p>"},{"location":"api/tpk/torch/TPKModel/#tpk.torch.TPKModel--parameters","title":"Parameters","text":"<p>freq     String indicating the sampling frequency of the data to be processed. context_length     Length of the RNN unrolling prior to the forecast date. prediction_length     Number of time points to predict. num_feat_dynamic_real     Number of dynamic real features that will be provided to <code>forward</code>. num_feat_static_real     Number of static real features that will be provided to <code>forward</code>. num_feat_static_cat     Number of static categorical features that will be provided to     <code>forward</code>. cardinality     List of cardinalities, one for each static categorical feature. embedding_dimension     Dimension of the embedding space, one for each static categorical     feature. n_block     Number of layers in the RNN. hidden_size     Size of the hidden layers in the RNN. dropout_rate     Dropout rate to be applied at training time. distr_output     Type of distribution to be output by the model at each time step scaling     Whether to apply mean scaling to the observations (target).</p> Source code in <code>tpk/torch/tpk/module.py</code> <pre><code>@validated()  # type: ignore\ndef __init__(\n    self,\n    freq: str,\n    context_length: int,\n    prediction_length: int,\n    num_feat_dynamic_real: int,\n    num_future_feat: int,\n    num_feat_static_real: int,\n    num_feat_static_cat: int,\n    cardinality: List[int],\n    distr_output: DistributionOutput,\n    embedding_dimension: Optional[List[int]] = None,\n    n_block: int = 2,\n    hidden_size: int = 128,\n    dropout_rate: float = 0.1,\n    scaling: bool = True,\n) -&gt; None:\n    super().__init__()\n\n    # assert distr_output.event_shape == ()\n\n    self.context_length = context_length\n    self.prediction_length = prediction_length\n    self.num_feat_dynamic_real = num_feat_dynamic_real\n    self.num_future_feat = num_future_feat\n    self.num_feat_static_cat = num_feat_static_cat\n    self.num_feat_static_real = num_feat_static_real\n    self.embedding_dimension = (\n        embedding_dimension\n        if embedding_dimension is not None or cardinality is None\n        else [min(32, (cat + 1) // 2) for cat in cardinality]\n    )\n    self.past_length = self.context_length\n    self.embedder = FeatureEmbedder(\n        cardinalities=cardinality,\n        embedding_dims=self.embedding_dimension,\n    )\n\n    if scaling:\n        self.scaler = MeanScaler(dim=-1, keepdim=True)\n    else:\n        self.scaler = NOPScaler(dim=-1, keepdim=True)\n\n    self.distr_output = StudentTOutput() if distr_output is None else distr_output\n    self.args_proj = distr_output.get_args_proj(hidden_size)\n\n    self.tsmixer_encoder = TPKEncoder(\n        input_len=context_length,\n        output_len=prediction_length,\n        past_feat_size=self.num_feat_dynamic_real + 1,  # target\n        future_feat_size=max(1, self.num_future_feat),\n        static_feat_size=(sum(self.embedding_dimension) + num_feat_static_real + 1),\n        activation=\"relu\",\n        dropout=dropout_rate,\n        n_block=n_block,\n        hidden_size=hidden_size,\n    )\n</code></pre>"},{"location":"api/tpk/torch/TPKModel/#tpk.torch.TPKModel.args_proj","title":"args_proj  <code>instance-attribute</code>","text":"<pre><code>args_proj = distr_output.get_args_proj(hidden_size)\n</code></pre>"},{"location":"api/tpk/torch/TPKModel/#tpk.torch.TPKModel.context_length","title":"context_length  <code>instance-attribute</code>","text":"<pre><code>context_length = context_length\n</code></pre>"},{"location":"api/tpk/torch/TPKModel/#tpk.torch.TPKModel.distr_output","title":"distr_output  <code>instance-attribute</code>","text":"<pre><code>distr_output = StudentTOutput() if distr_output is None else distr_output\n</code></pre>"},{"location":"api/tpk/torch/TPKModel/#tpk.torch.TPKModel.embedder","title":"embedder  <code>instance-attribute</code>","text":"<pre><code>embedder = FeatureEmbedder(cardinalities=cardinality, embedding_dims=self.embedding_dimension)\n</code></pre>"},{"location":"api/tpk/torch/TPKModel/#tpk.torch.TPKModel.embedding_dimension","title":"embedding_dimension  <code>instance-attribute</code>","text":"<pre><code>embedding_dimension = embedding_dimension if embedding_dimension is not None or cardinality is None else [min(32, cat + 1 // 2) for cat in cardinality]\n</code></pre>"},{"location":"api/tpk/torch/TPKModel/#tpk.torch.TPKModel.num_feat_dynamic_real","title":"num_feat_dynamic_real  <code>instance-attribute</code>","text":"<pre><code>num_feat_dynamic_real = num_feat_dynamic_real\n</code></pre>"},{"location":"api/tpk/torch/TPKModel/#tpk.torch.TPKModel.num_feat_static_cat","title":"num_feat_static_cat  <code>instance-attribute</code>","text":"<pre><code>num_feat_static_cat = num_feat_static_cat\n</code></pre>"},{"location":"api/tpk/torch/TPKModel/#tpk.torch.TPKModel.num_feat_static_real","title":"num_feat_static_real  <code>instance-attribute</code>","text":"<pre><code>num_feat_static_real = num_feat_static_real\n</code></pre>"},{"location":"api/tpk/torch/TPKModel/#tpk.torch.TPKModel.num_future_feat","title":"num_future_feat  <code>instance-attribute</code>","text":"<pre><code>num_future_feat = num_future_feat\n</code></pre>"},{"location":"api/tpk/torch/TPKModel/#tpk.torch.TPKModel.past_length","title":"past_length  <code>instance-attribute</code>","text":"<pre><code>past_length = self.context_length\n</code></pre>"},{"location":"api/tpk/torch/TPKModel/#tpk.torch.TPKModel.prediction_length","title":"prediction_length  <code>instance-attribute</code>","text":"<pre><code>prediction_length = prediction_length\n</code></pre>"},{"location":"api/tpk/torch/TPKModel/#tpk.torch.TPKModel.scaler","title":"scaler  <code>instance-attribute</code>","text":"<pre><code>scaler = MeanScaler(dim=-1, keepdim=True)\n</code></pre>"},{"location":"api/tpk/torch/TPKModel/#tpk.torch.TPKModel.tsmixer_encoder","title":"tsmixer_encoder  <code>instance-attribute</code>","text":"<pre><code>tsmixer_encoder = TPKEncoder(input_len=context_length, output_len=prediction_length, past_feat_size=self.num_feat_dynamic_real + 1, future_feat_size=max(1, self.num_future_feat), static_feat_size=sum(self.embedding_dimension) + num_feat_static_real + 1, activation='relu', dropout=dropout_rate, n_block=n_block, hidden_size=hidden_size)\n</code></pre>"},{"location":"api/tpk/torch/TPKModel/#tpk.torch.TPKModel.forward","title":"forward","text":"<pre><code>forward(feat_static_cat: torch.Tensor, feat_static_real: torch.Tensor, past_time_feat: torch.Tensor, past_target: torch.Tensor, past_observed_values: torch.Tensor, future_time_feat: torch.Tensor) -&gt; Tuple[Any, torch.Tensor, Any]\n</code></pre> <p>Invokes the model on input data, and produce outputs future samples.</p>"},{"location":"api/tpk/torch/TPKModel/#tpk.torch.TPKModel.forward--parameters","title":"Parameters","text":"<p>feat_static_cat     Tensor of static categorical features,     shape: <code>(batch_size, num_feat_static_cat)</code>. feat_static_real     Tensor of static real features,     shape: <code>(batch_size, num_feat_static_real)</code>. past_time_feat     Tensor of dynamic real features in the past,     shape: <code>(batch_size, past_length, num_feat_dynamic_real)</code>. past_target     Tensor of past target values,     shape: <code>(batch_size, past_length)</code>. past_observed_values     Tensor of observed values indicators,     shape: <code>(batch_size, past_length)</code>. future_time_feat     (Optional) tensor of dynamic real features in the past,     shape: <code>(batch_size, prediction_length, num_feat_dynamic_real)</code>.</p> Source code in <code>tpk/torch/tpk/module.py</code> <pre><code>def forward(\n    self,\n    feat_static_cat: torch.Tensor,\n    feat_static_real: torch.Tensor,\n    past_time_feat: torch.Tensor,\n    past_target: torch.Tensor,\n    past_observed_values: torch.Tensor,\n    future_time_feat: torch.Tensor,\n) -&gt; Tuple[Any, torch.Tensor, Any]:\n    \"\"\"\n    Invokes the model on input data, and produce outputs future samples.\n\n    Parameters\n    ----------\n    feat_static_cat\n        Tensor of static categorical features,\n        shape: ``(batch_size, num_feat_static_cat)``.\n    feat_static_real\n        Tensor of static real features,\n        shape: ``(batch_size, num_feat_static_real)``.\n    past_time_feat\n        Tensor of dynamic real features in the past,\n        shape: ``(batch_size, past_length, num_feat_dynamic_real)``.\n    past_target\n        Tensor of past target values,\n        shape: ``(batch_size, past_length)``.\n    past_observed_values\n        Tensor of observed values indicators,\n        shape: ``(batch_size, past_length)``.\n    future_time_feat\n        (Optional) tensor of dynamic real features in the past,\n        shape: ``(batch_size, prediction_length, num_feat_dynamic_real)``.\n    \"\"\"\n    if self.num_future_feat == 0:\n        future_time_feat = torch.zeros_like(future_time_feat)[:, :, [0]]\n    else:\n        future_time_feat = future_time_feat[:, :, : self.num_future_feat]\n    _, _, scale = self.scaler(past_target, past_observed_values)\n\n    scaled_past_target = past_target / scale\n\n    embedded_cat = self.embedder(feat_static_cat)\n    static_feat = torch.cat(\n        (embedded_cat, feat_static_real, scale.log()),\n        dim=-1,\n    )\n    past_feature = torch.cat(\n        (scaled_past_target.unsqueeze(-1), past_time_feat), dim=-1\n    )\n    output = self.tsmixer_encoder(past_feature, future_time_feat, static_feat)\n    distr_args = self.args_proj(output)\n    return distr_args, torch.zeros_like(scale), scale\n</code></pre>"},{"location":"api/tpk/torch/TPKModel/#tpk.torch.TPKModel.input_shapes","title":"input_shapes","text":"<pre><code>input_shapes(batch_size: int = 1) -&gt; Dict[str, Tuple[int, ...]]\n</code></pre> Source code in <code>tpk/torch/tpk/module.py</code> <pre><code>def input_shapes(self, batch_size: int = 1) -&gt; Dict[str, Tuple[int, ...]]:\n    return {\n        \"feat_static_cat\": (batch_size, self.num_feat_static_cat),\n        \"feat_static_real\": (batch_size, self.num_feat_static_real),\n        \"past_time_feat\": (\n            batch_size,\n            self._past_length,\n            self.num_feat_dynamic_real,\n        ),\n        \"past_target\": (batch_size, self._past_length),\n        \"past_observed_values\": (batch_size, self._past_length),\n        \"future_time_feat\": (\n            batch_size,\n            self.prediction_length,\n            self.num_feat_dynamic_real,\n        ),\n    }\n</code></pre>"},{"location":"api/tpk/torch/TPKModel/#tpk.torch.TPKModel.input_types","title":"input_types","text":"<pre><code>input_types() -&gt; Dict[str, torch.dtype]\n</code></pre> Source code in <code>tpk/torch/tpk/module.py</code> <pre><code>def input_types(self) -&gt; Dict[str, torch.dtype]:\n    return {\n        \"feat_static_cat\": torch.long,\n        \"feat_static_real\": torch.float,\n        \"past_time_feat\": torch.float,\n        \"past_target\": torch.float,\n        \"past_observed_values\": torch.float,\n        \"future_time_feat\": torch.float,\n    }\n</code></pre>"},{"location":"api/tpk/torch/TSMixerModel/","title":"TSMixerModel","text":""},{"location":"api/tpk/torch/TSMixerModel/#tpk.torch.TSMixerModel","title":"tpk.torch.TSMixerModel","text":"<pre><code>TSMixerModel(freq: str, context_length: int, prediction_length: int, num_feat_dynamic_real: int, num_future_feat: int, num_feat_static_real: int, num_feat_static_cat: int, cardinality: List[int], distr_output: DistributionOutput, embedding_dimension: Optional[List[int]] = None, n_block: int = 2, hidden_size: int = 128, dropout_rate: float = 0.1, scaling: bool = True)\n</code></pre> <p>             Bases: <code>Module</code></p> <p>Module implementing the TSMixer model, see [SFG17]_.</p> <p>Note: the code of this model is unrelated to the implementation behind <code>SageMaker's TSMixer Forecasting Algorithm &lt;https://docs.aws.amazon.com/sagemaker/latest/dg/deepar.html&gt;</code>_.</p>"},{"location":"api/tpk/torch/TSMixerModel/#tpk.torch.TSMixerModel--parameters","title":"Parameters","text":"<p>freq     String indicating the sampling frequency of the data to be processed. context_length     Length of the RNN unrolling prior to the forecast date. prediction_length     Number of time points to predict. num_feat_dynamic_real     Number of dynamic real features that will be provided to <code>forward</code>. num_feat_static_real     Number of static real features that will be provided to <code>forward</code>. num_feat_static_cat     Number of static categorical features that will be provided to     <code>forward</code>. cardinality     List of cardinalities, one for each static categorical feature. embedding_dimension     Dimension of the embedding space, one for each static categorical     feature. n_block     Number of layers in the RNN. hidden_size     Size of the hidden layers in the RNN. dropout_rate     Dropout rate to be applied at training time. distr_output     Type of distribution to be output by the model at each time step scaling     Whether to apply mean scaling to the observations (target).</p> Source code in <code>tpk/torch/tsmixer/module.py</code> <pre><code>@validated()  # type: ignore\ndef __init__(\n    self,\n    freq: str,\n    context_length: int,\n    prediction_length: int,\n    num_feat_dynamic_real: int,\n    num_future_feat: int,\n    num_feat_static_real: int,\n    num_feat_static_cat: int,\n    cardinality: List[int],\n    distr_output: DistributionOutput,\n    embedding_dimension: Optional[List[int]] = None,\n    n_block: int = 2,\n    hidden_size: int = 128,\n    dropout_rate: float = 0.1,\n    scaling: bool = True,\n) -&gt; None:\n    super().__init__()\n\n    # assert distr_output.event_shape == ()\n\n    self.context_length = context_length\n    self.prediction_length = prediction_length\n    self.num_feat_dynamic_real = num_feat_dynamic_real\n    self.num_future_feat = num_future_feat\n    self.num_feat_static_cat = num_feat_static_cat\n    self.num_feat_static_real = num_feat_static_real\n    self.embedding_dimension = (\n        embedding_dimension\n        if embedding_dimension is not None or cardinality is None\n        else [min(32, (cat + 1) // 2) for cat in cardinality]\n    )\n    self.past_length = self.context_length\n    self.embedder = FeatureEmbedder(\n        cardinalities=cardinality,\n        embedding_dims=self.embedding_dimension,\n    )\n\n    if scaling:\n        self.scaler = MeanScaler(dim=-1, keepdim=True)\n    else:\n        self.scaler = NOPScaler(dim=-1, keepdim=True)\n\n    self.distr_output = StudentTOutput() if distr_output is None else distr_output\n    self.args_proj = distr_output.get_args_proj(hidden_size)\n\n    self.tsmixer_encoder = TSMixerEncoder(\n        input_len=context_length,\n        output_len=prediction_length,\n        past_feat_size=self.num_feat_dynamic_real + 1,  # target\n        future_feat_size=max(1, self.num_future_feat),\n        static_feat_size=(sum(self.embedding_dimension) + num_feat_static_real + 1),\n        activation=\"relu\",\n        dropout=dropout_rate,\n        n_block=n_block,\n        hidden_size=hidden_size,\n    )\n</code></pre>"},{"location":"api/tpk/torch/TSMixerModel/#tpk.torch.TSMixerModel.args_proj","title":"args_proj  <code>instance-attribute</code>","text":"<pre><code>args_proj = distr_output.get_args_proj(hidden_size)\n</code></pre>"},{"location":"api/tpk/torch/TSMixerModel/#tpk.torch.TSMixerModel.context_length","title":"context_length  <code>instance-attribute</code>","text":"<pre><code>context_length = context_length\n</code></pre>"},{"location":"api/tpk/torch/TSMixerModel/#tpk.torch.TSMixerModel.distr_output","title":"distr_output  <code>instance-attribute</code>","text":"<pre><code>distr_output = StudentTOutput() if distr_output is None else distr_output\n</code></pre>"},{"location":"api/tpk/torch/TSMixerModel/#tpk.torch.TSMixerModel.embedder","title":"embedder  <code>instance-attribute</code>","text":"<pre><code>embedder = FeatureEmbedder(cardinalities=cardinality, embedding_dims=self.embedding_dimension)\n</code></pre>"},{"location":"api/tpk/torch/TSMixerModel/#tpk.torch.TSMixerModel.embedding_dimension","title":"embedding_dimension  <code>instance-attribute</code>","text":"<pre><code>embedding_dimension = embedding_dimension if embedding_dimension is not None or cardinality is None else [min(32, cat + 1 // 2) for cat in cardinality]\n</code></pre>"},{"location":"api/tpk/torch/TSMixerModel/#tpk.torch.TSMixerModel.num_feat_dynamic_real","title":"num_feat_dynamic_real  <code>instance-attribute</code>","text":"<pre><code>num_feat_dynamic_real = num_feat_dynamic_real\n</code></pre>"},{"location":"api/tpk/torch/TSMixerModel/#tpk.torch.TSMixerModel.num_feat_static_cat","title":"num_feat_static_cat  <code>instance-attribute</code>","text":"<pre><code>num_feat_static_cat = num_feat_static_cat\n</code></pre>"},{"location":"api/tpk/torch/TSMixerModel/#tpk.torch.TSMixerModel.num_feat_static_real","title":"num_feat_static_real  <code>instance-attribute</code>","text":"<pre><code>num_feat_static_real = num_feat_static_real\n</code></pre>"},{"location":"api/tpk/torch/TSMixerModel/#tpk.torch.TSMixerModel.num_future_feat","title":"num_future_feat  <code>instance-attribute</code>","text":"<pre><code>num_future_feat = num_future_feat\n</code></pre>"},{"location":"api/tpk/torch/TSMixerModel/#tpk.torch.TSMixerModel.past_length","title":"past_length  <code>instance-attribute</code>","text":"<pre><code>past_length = self.context_length\n</code></pre>"},{"location":"api/tpk/torch/TSMixerModel/#tpk.torch.TSMixerModel.prediction_length","title":"prediction_length  <code>instance-attribute</code>","text":"<pre><code>prediction_length = prediction_length\n</code></pre>"},{"location":"api/tpk/torch/TSMixerModel/#tpk.torch.TSMixerModel.scaler","title":"scaler  <code>instance-attribute</code>","text":"<pre><code>scaler = MeanScaler(dim=-1, keepdim=True)\n</code></pre>"},{"location":"api/tpk/torch/TSMixerModel/#tpk.torch.TSMixerModel.tsmixer_encoder","title":"tsmixer_encoder  <code>instance-attribute</code>","text":"<pre><code>tsmixer_encoder = TSMixerEncoder(input_len=context_length, output_len=prediction_length, past_feat_size=self.num_feat_dynamic_real + 1, future_feat_size=max(1, self.num_future_feat), static_feat_size=sum(self.embedding_dimension) + num_feat_static_real + 1, activation='relu', dropout=dropout_rate, n_block=n_block, hidden_size=hidden_size)\n</code></pre>"},{"location":"api/tpk/torch/TSMixerModel/#tpk.torch.TSMixerModel.forward","title":"forward","text":"<pre><code>forward(feat_static_cat: torch.Tensor, feat_static_real: torch.Tensor, past_time_feat: torch.Tensor, past_target: torch.Tensor, past_observed_values: torch.Tensor, future_time_feat: torch.Tensor) -&gt; Tuple[Any, torch.Tensor, Any]\n</code></pre> <p>Invokes the model on input data, and produce outputs future samples.</p>"},{"location":"api/tpk/torch/TSMixerModel/#tpk.torch.TSMixerModel.forward--parameters","title":"Parameters","text":"<p>feat_static_cat     Tensor of static categorical features,     shape: <code>(batch_size, num_feat_static_cat)</code>. feat_static_real     Tensor of static real features,     shape: <code>(batch_size, num_feat_static_real)</code>. past_time_feat     Tensor of dynamic real features in the past,     shape: <code>(batch_size, past_length, num_feat_dynamic_real)</code>. past_target     Tensor of past target values,     shape: <code>(batch_size, past_length)</code>. past_observed_values     Tensor of observed values indicators,     shape: <code>(batch_size, past_length)</code>. future_time_feat     (Optional) tensor of dynamic real features in the past,     shape: <code>(batch_size, prediction_length, num_feat_dynamic_real)</code>.</p> Source code in <code>tpk/torch/tsmixer/module.py</code> <pre><code>def forward(\n    self,\n    feat_static_cat: torch.Tensor,\n    feat_static_real: torch.Tensor,\n    past_time_feat: torch.Tensor,\n    past_target: torch.Tensor,\n    past_observed_values: torch.Tensor,\n    future_time_feat: torch.Tensor,\n) -&gt; Tuple[Any, torch.Tensor, Any]:\n    \"\"\"\n    Invokes the model on input data, and produce outputs future samples.\n\n    Parameters\n    ----------\n    feat_static_cat\n        Tensor of static categorical features,\n        shape: ``(batch_size, num_feat_static_cat)``.\n    feat_static_real\n        Tensor of static real features,\n        shape: ``(batch_size, num_feat_static_real)``.\n    past_time_feat\n        Tensor of dynamic real features in the past,\n        shape: ``(batch_size, past_length, num_feat_dynamic_real)``.\n    past_target\n        Tensor of past target values,\n        shape: ``(batch_size, past_length)``.\n    past_observed_values\n        Tensor of observed values indicators,\n        shape: ``(batch_size, past_length)``.\n    future_time_feat\n        (Optional) tensor of dynamic real features in the past,\n        shape: ``(batch_size, prediction_length, num_feat_dynamic_real)``.\n    \"\"\"\n    if self.num_future_feat == 0:\n        future_time_feat = torch.zeros_like(future_time_feat)[:, :, [0]]\n    else:\n        future_time_feat = future_time_feat[:, :, : self.num_future_feat]\n    _, _, scale = self.scaler(past_target, past_observed_values)\n\n    scaled_past_target = past_target / scale\n\n    embedded_cat = self.embedder(feat_static_cat)\n    static_feat = torch.cat(\n        (embedded_cat, feat_static_real, scale.log()),\n        dim=-1,\n    )\n    past_feature = torch.cat(\n        (scaled_past_target.unsqueeze(-1), past_time_feat), dim=-1\n    )\n    output = self.tsmixer_encoder(past_feature, future_time_feat, static_feat)\n    distr_args = self.args_proj(output)\n    return distr_args, torch.zeros_like(scale), scale\n</code></pre>"},{"location":"api/tpk/torch/TSMixerModel/#tpk.torch.TSMixerModel.input_shapes","title":"input_shapes","text":"<pre><code>input_shapes(batch_size: int = 1) -&gt; Dict[str, Tuple[int, ...]]\n</code></pre> Source code in <code>tpk/torch/tsmixer/module.py</code> <pre><code>def input_shapes(self, batch_size: int = 1) -&gt; Dict[str, Tuple[int, ...]]:\n    return {\n        \"feat_static_cat\": (batch_size, self.num_feat_static_cat),\n        \"feat_static_real\": (batch_size, self.num_feat_static_real),\n        \"past_time_feat\": (\n            batch_size,\n            self._past_length,\n            self.num_feat_dynamic_real,\n        ),\n        \"past_target\": (batch_size, self._past_length),\n        \"past_observed_values\": (batch_size, self._past_length),\n        \"future_time_feat\": (\n            batch_size,\n            self.prediction_length,\n            self.num_feat_dynamic_real,\n        ),\n    }\n</code></pre>"},{"location":"api/tpk/torch/TSMixerModel/#tpk.torch.TSMixerModel.input_types","title":"input_types","text":"<pre><code>input_types() -&gt; Dict[str, torch.dtype]\n</code></pre> Source code in <code>tpk/torch/tsmixer/module.py</code> <pre><code>def input_types(self) -&gt; Dict[str, torch.dtype]:\n    return {\n        \"feat_static_cat\": torch.long,\n        \"feat_static_real\": torch.float,\n        \"past_time_feat\": torch.float,\n        \"past_target\": torch.float,\n        \"past_observed_values\": torch.float,\n        \"future_time_feat\": torch.float,\n    }\n</code></pre>"},{"location":"api/tpk/torch/estimator/IterableDataset/","title":"IterableDataset","text":""},{"location":"api/tpk/torch/estimator/IterableDataset/#tpk.torch.estimator.IterableDataset","title":"tpk.torch.estimator.IterableDataset","text":"<pre><code>IterableDataset(iterable: Iterator[Any])\n</code></pre> <p>             Bases: <code>IterableDataset</code></p> Source code in <code>tpk/torch/estimator.py</code> <pre><code>def __init__(self, iterable: Iterator[Any]):\n    self.iterable = iterable\n</code></pre>"},{"location":"api/tpk/torch/estimator/IterableDataset/#tpk.torch.estimator.IterableDataset.iterable","title":"iterable  <code>instance-attribute</code>","text":"<pre><code>iterable = iterable\n</code></pre>"},{"location":"api/tpk/torch/estimator/MyEstimator/","title":"MyEstimator","text":""},{"location":"api/tpk/torch/estimator/MyEstimator/#tpk.torch.estimator.MyEstimator","title":"tpk.torch.estimator.MyEstimator","text":"<pre><code>MyEstimator(*, model_cls: Type[LightningModule], freq: str, prediction_length: int, epochs: int, context_length: Optional[int] = None, n_block: int = 2, hidden_size: int = 128, weight_decay: float = 1e-08, dropout_rate: float = 0.1, patience: int = 10, num_feat_dynamic_real: int = 0, disable_future_feature: bool = False, num_feat_static_cat: int = 0, num_feat_static_real: int = 0, cardinality: Optional[List[int]] = None, embedding_dimension: Optional[List[int]] = None, distr_output: Optional[DistributionOutput] = None, loss: Optional[DistributionLoss] = None, scaling: bool = True, time_features: Optional[List[TimeFeature]] = None, batch_size: int = 32, num_batches_per_epoch: int = 50, trainer_kwargs: Optional[Dict[str, Any]] = None, train_sampler: Optional[InstanceSampler] = None, validation_sampler: Optional[InstanceSampler] = None)\n</code></pre> <p>             Bases: <code>PyTorchLightningEstimator</code></p> <p>Estimator class to train a TPK model.</p> <p>This class is uses the model defined in <code>TPKModel</code>, and wraps it into a <code>MyLightningModule</code> for training purposes: training is performed using PyTorch Lightning's <code>pl.Trainer</code> class.</p>"},{"location":"api/tpk/torch/estimator/MyEstimator/#tpk.torch.estimator.MyEstimator--parameters","title":"Parameters","text":"<p>freq     Frequency of the data to train on and predict. prediction_length     Length of the prediction horizon. context_length     Number of steps to unroll the RNN for before computing predictions     (default: None, in which case context_length = prediction_length). n_block     Number of TPK blocks (default: 2). hidden_size     Number of hidden size for each layer (default: 128). weight_decay     Weight decay regularization parameter (default: <code>1e-8</code>). dropout_rate     Dropout regularization parameter (default: 0.1). patience     Patience parameter for learning rate scheduler. num_feat_dynamic_real     Number of dynamic real features in the data (default: 0). num_feat_static_real     Number of static real features in the data (default: 0). num_feat_static_cat     Number of static categorical features in the data (default: 0). cardinality     Number of values of each categorical feature.     This must be set if <code>num_feat_static_cat &gt; 0</code> (default: None). embedding_dimension     Dimension of the embeddings for categorical features     (default: <code>[min(50, (cat+1)//2) for cat in cardinality]</code>). distr_output     Distribution to use to evaluate observations and sample predictions     (default: StudentTOutput()). loss     Loss to be optimized during training     (default: <code>NegativeLogLikelihood()</code>). scaling     Whether to automatically scale the target values (default: true). time_features     List of time features, from :py:mod:<code>gluonts.time_feature</code>, to use as     inputs of the RNN in addition to the provided data (default: None,     in which case these are automatically determined based on freq). batch_size     The size of the batches to be used for training (default: 32). num_batches_per_epoch     Number of batches to be processed in each training epoch     (default: 50). trainer_kwargs     Additional arguments to provide to <code>pl.Trainer</code> for construction. train_sampler     Controls the sampling of windows during training. validation_sampler     Controls the sampling of windows during validation.</p> Source code in <code>tpk/torch/estimator.py</code> <pre><code>@validated()  # type: ignore\ndef __init__(\n    self,\n    *,\n    model_cls: Type[LightningModule],\n    freq: str,\n    prediction_length: int,\n    epochs: int,\n    context_length: Optional[int] = None,\n    n_block: int = 2,\n    hidden_size: int = 128,\n    weight_decay: float = 1e-8,\n    dropout_rate: float = 0.1,\n    patience: int = 10,\n    num_feat_dynamic_real: int = 0,\n    disable_future_feature: bool = False,\n    num_feat_static_cat: int = 0,\n    num_feat_static_real: int = 0,\n    cardinality: Optional[List[int]] = None,\n    embedding_dimension: Optional[List[int]] = None,\n    distr_output: Optional[DistributionOutput] = None,\n    loss: Optional[DistributionLoss] = None,\n    scaling: bool = True,\n    time_features: Optional[List[TimeFeature]] = None,\n    batch_size: int = 32,\n    num_batches_per_epoch: int = 50,\n    trainer_kwargs: Optional[Dict[str, Any]] = None,\n    train_sampler: Optional[InstanceSampler] = None,\n    validation_sampler: Optional[InstanceSampler] = None,\n) -&gt; None:\n    default_trainer_kwargs = {\n        \"max_epochs\": 100,\n        \"gradient_clip_val\": 10.0,\n    }\n    if trainer_kwargs is not None:\n        default_trainer_kwargs.update(trainer_kwargs)\n    super().__init__(trainer_kwargs=default_trainer_kwargs)\n\n    self.model_cls = model_cls\n    self.epochs = epochs\n    self.freq = freq\n    self.context_length = (\n        context_length if context_length is not None else prediction_length\n    )\n    self.prediction_length = prediction_length\n    self.patience = patience\n    self.distr_output = StudentTOutput() if distr_output is None else distr_output\n    self.loss = NegativeLogLikelihood() if loss is None else loss\n    self.n_block = n_block\n    self.hidden_size = hidden_size\n    self.weight_decay = weight_decay\n    self.dropout_rate = dropout_rate\n    self.num_feat_dynamic_real = num_feat_dynamic_real\n    self.disable_future_feature = disable_future_feature\n    self.num_feat_static_cat = num_feat_static_cat\n    self.num_feat_static_real = num_feat_static_real\n    self.cardinality = (\n        cardinality if cardinality and num_feat_static_cat &gt; 0 else [1]\n    )\n    self.embedding_dimension = embedding_dimension\n    self.scaling = scaling\n    self.time_features = (\n        time_features\n        if time_features is not None\n        else time_features_from_frequency_str(self.freq)\n    )\n\n    self.batch_size = batch_size\n    self.num_batches_per_epoch = num_batches_per_epoch\n\n    self.train_sampler = train_sampler or ExpectedNumInstanceSampler(\n        num_instances=1.0, min_future=prediction_length\n    )\n    self.validation_sampler = validation_sampler or ValidationSplitSampler(\n        min_future=prediction_length\n    )\n</code></pre>"},{"location":"api/tpk/torch/estimator/MyEstimator/#tpk.torch.estimator.MyEstimator.batch_size","title":"batch_size  <code>instance-attribute</code>","text":"<pre><code>batch_size = batch_size\n</code></pre>"},{"location":"api/tpk/torch/estimator/MyEstimator/#tpk.torch.estimator.MyEstimator.cardinality","title":"cardinality  <code>instance-attribute</code>","text":"<pre><code>cardinality = cardinality if cardinality and num_feat_static_cat &gt; 0 else [1]\n</code></pre>"},{"location":"api/tpk/torch/estimator/MyEstimator/#tpk.torch.estimator.MyEstimator.context_length","title":"context_length  <code>instance-attribute</code>","text":"<pre><code>context_length = context_length if context_length is not None else prediction_length\n</code></pre>"},{"location":"api/tpk/torch/estimator/MyEstimator/#tpk.torch.estimator.MyEstimator.disable_future_feature","title":"disable_future_feature  <code>instance-attribute</code>","text":"<pre><code>disable_future_feature = disable_future_feature\n</code></pre>"},{"location":"api/tpk/torch/estimator/MyEstimator/#tpk.torch.estimator.MyEstimator.distr_output","title":"distr_output  <code>instance-attribute</code>","text":"<pre><code>distr_output = StudentTOutput() if distr_output is None else distr_output\n</code></pre>"},{"location":"api/tpk/torch/estimator/MyEstimator/#tpk.torch.estimator.MyEstimator.dropout_rate","title":"dropout_rate  <code>instance-attribute</code>","text":"<pre><code>dropout_rate = dropout_rate\n</code></pre>"},{"location":"api/tpk/torch/estimator/MyEstimator/#tpk.torch.estimator.MyEstimator.embedding_dimension","title":"embedding_dimension  <code>instance-attribute</code>","text":"<pre><code>embedding_dimension = embedding_dimension\n</code></pre>"},{"location":"api/tpk/torch/estimator/MyEstimator/#tpk.torch.estimator.MyEstimator.epochs","title":"epochs  <code>instance-attribute</code>","text":"<pre><code>epochs = epochs\n</code></pre>"},{"location":"api/tpk/torch/estimator/MyEstimator/#tpk.torch.estimator.MyEstimator.freq","title":"freq  <code>instance-attribute</code>","text":"<pre><code>freq = freq\n</code></pre>"},{"location":"api/tpk/torch/estimator/MyEstimator/#tpk.torch.estimator.MyEstimator.hidden_size","title":"hidden_size  <code>instance-attribute</code>","text":"<pre><code>hidden_size = hidden_size\n</code></pre>"},{"location":"api/tpk/torch/estimator/MyEstimator/#tpk.torch.estimator.MyEstimator.loss","title":"loss  <code>instance-attribute</code>","text":"<pre><code>loss = NegativeLogLikelihood() if loss is None else loss\n</code></pre>"},{"location":"api/tpk/torch/estimator/MyEstimator/#tpk.torch.estimator.MyEstimator.model_cls","title":"model_cls  <code>instance-attribute</code>","text":"<pre><code>model_cls = model_cls\n</code></pre>"},{"location":"api/tpk/torch/estimator/MyEstimator/#tpk.torch.estimator.MyEstimator.n_block","title":"n_block  <code>instance-attribute</code>","text":"<pre><code>n_block = n_block\n</code></pre>"},{"location":"api/tpk/torch/estimator/MyEstimator/#tpk.torch.estimator.MyEstimator.num_batches_per_epoch","title":"num_batches_per_epoch  <code>instance-attribute</code>","text":"<pre><code>num_batches_per_epoch = num_batches_per_epoch\n</code></pre>"},{"location":"api/tpk/torch/estimator/MyEstimator/#tpk.torch.estimator.MyEstimator.num_feat_dynamic_real","title":"num_feat_dynamic_real  <code>instance-attribute</code>","text":"<pre><code>num_feat_dynamic_real = num_feat_dynamic_real\n</code></pre>"},{"location":"api/tpk/torch/estimator/MyEstimator/#tpk.torch.estimator.MyEstimator.num_feat_static_cat","title":"num_feat_static_cat  <code>instance-attribute</code>","text":"<pre><code>num_feat_static_cat = num_feat_static_cat\n</code></pre>"},{"location":"api/tpk/torch/estimator/MyEstimator/#tpk.torch.estimator.MyEstimator.num_feat_static_real","title":"num_feat_static_real  <code>instance-attribute</code>","text":"<pre><code>num_feat_static_real = num_feat_static_real\n</code></pre>"},{"location":"api/tpk/torch/estimator/MyEstimator/#tpk.torch.estimator.MyEstimator.patience","title":"patience  <code>instance-attribute</code>","text":"<pre><code>patience = patience\n</code></pre>"},{"location":"api/tpk/torch/estimator/MyEstimator/#tpk.torch.estimator.MyEstimator.prediction_length","title":"prediction_length  <code>instance-attribute</code>","text":"<pre><code>prediction_length = prediction_length\n</code></pre>"},{"location":"api/tpk/torch/estimator/MyEstimator/#tpk.torch.estimator.MyEstimator.scaling","title":"scaling  <code>instance-attribute</code>","text":"<pre><code>scaling = scaling\n</code></pre>"},{"location":"api/tpk/torch/estimator/MyEstimator/#tpk.torch.estimator.MyEstimator.time_features","title":"time_features  <code>instance-attribute</code>","text":"<pre><code>time_features = time_features if time_features is not None else time_features_from_frequency_str(self.freq)\n</code></pre>"},{"location":"api/tpk/torch/estimator/MyEstimator/#tpk.torch.estimator.MyEstimator.train_sampler","title":"train_sampler  <code>instance-attribute</code>","text":"<pre><code>train_sampler = train_sampler or ExpectedNumInstanceSampler(num_instances=1.0, min_future=prediction_length)\n</code></pre>"},{"location":"api/tpk/torch/estimator/MyEstimator/#tpk.torch.estimator.MyEstimator.validation_sampler","title":"validation_sampler  <code>instance-attribute</code>","text":"<pre><code>validation_sampler = validation_sampler or ValidationSplitSampler(min_future=prediction_length)\n</code></pre>"},{"location":"api/tpk/torch/estimator/MyEstimator/#tpk.torch.estimator.MyEstimator.weight_decay","title":"weight_decay  <code>instance-attribute</code>","text":"<pre><code>weight_decay = weight_decay\n</code></pre>"},{"location":"api/tpk/torch/estimator/MyEstimator/#tpk.torch.estimator.MyEstimator.create_lightning_module","title":"create_lightning_module","text":"<pre><code>create_lightning_module() -&gt; LightningModule\n</code></pre> Source code in <code>tpk/torch/estimator.py</code> <pre><code>def create_lightning_module(self) -&gt; LightningModule:\n    model = self.model_cls(\n        freq=self.freq,\n        context_length=self.context_length,\n        prediction_length=self.prediction_length,\n        num_feat_dynamic_real=(\n            self.num_feat_dynamic_real + len(self.time_features)\n        ),\n        num_future_feat=(\n            # len(self.time_features)\n            0\n            if self.disable_future_feature\n            else self.num_feat_dynamic_real + len(self.time_features)\n        ),\n        num_feat_static_real=max(1, self.num_feat_static_real),\n        num_feat_static_cat=max(1, self.num_feat_static_cat),\n        cardinality=self.cardinality,\n        embedding_dimension=self.embedding_dimension,\n        n_block=self.n_block,\n        hidden_size=self.hidden_size,\n        distr_output=self.distr_output,\n        dropout_rate=self.dropout_rate,\n        scaling=self.scaling,\n    )\n\n    return MyLightningModule(  # type: ignore\n        model=model,\n        loss=self.loss,\n        weight_decay=self.weight_decay,\n        patience=self.patience,\n        epochs=self.epochs,\n        steps_per_epoch=self.num_batches_per_epoch,\n    )\n</code></pre>"},{"location":"api/tpk/torch/estimator/MyEstimator/#tpk.torch.estimator.MyEstimator.create_predictor","title":"create_predictor","text":"<pre><code>create_predictor(transformation: Transformation, module: LightningModule) -&gt; PyTorchPredictor\n</code></pre> Source code in <code>tpk/torch/estimator.py</code> <pre><code>def create_predictor(\n    self,\n    transformation: Transformation,\n    module: LightningModule,\n) -&gt; PyTorchPredictor:\n    prediction_splitter = self._create_instance_splitter(module, \"test\")\n\n    return PyTorchPredictor(\n        input_transform=transformation + prediction_splitter,\n        input_names=PREDICTION_INPUT_NAMES,\n        prediction_net=module,\n        forecast_generator=DistributionForecastGenerator(self.distr_output),\n        batch_size=self.batch_size,\n        prediction_length=self.prediction_length,\n        device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n    )\n</code></pre>"},{"location":"api/tpk/torch/estimator/MyEstimator/#tpk.torch.estimator.MyEstimator.create_training_data_loader","title":"create_training_data_loader","text":"<pre><code>create_training_data_loader(data: Dataset, module: LightningModule, shuffle_buffer_length: Optional[int] = None, **kwargs: Any) -&gt; Any\n</code></pre> Source code in <code>tpk/torch/estimator.py</code> <pre><code>def create_training_data_loader(\n    self,\n    data: Dataset,\n    module: LightningModule,\n    shuffle_buffer_length: Optional[int] = None,\n    **kwargs: Any,\n) -&gt; Any:\n    transformation = self._create_instance_splitter(\n        module, \"training\"\n    ) + SelectFields(TRAINING_INPUT_NAMES)\n\n    training_instances = transformation.apply(\n        Cyclic(data)\n        if shuffle_buffer_length is None\n        else PseudoShuffled(\n            Cyclic(data), shuffle_buffer_length=shuffle_buffer_length\n        )\n    )\n\n    return IterableSlice(\n        iter(\n            # nosemgrep\n            DataLoader(\n                IterableDataset(training_instances),\n                batch_size=self.batch_size,\n                num_workers=2,\n                persistent_workers=True,\n                **kwargs,\n            )\n        ),\n        self.num_batches_per_epoch,\n    )\n</code></pre>"},{"location":"api/tpk/torch/estimator/MyEstimator/#tpk.torch.estimator.MyEstimator.create_transformation","title":"create_transformation","text":"<pre><code>create_transformation() -&gt; Transformation\n</code></pre> Source code in <code>tpk/torch/estimator.py</code> <pre><code>def create_transformation(self) -&gt; Transformation:\n    remove_field_names = []\n    if self.num_feat_static_real == 0:\n        remove_field_names.append(FieldName.FEAT_STATIC_REAL)\n    if self.num_feat_dynamic_real == 0:\n        remove_field_names.append(FieldName.FEAT_DYNAMIC_REAL)\n\n    return Chain(\n        [RemoveFields(field_names=remove_field_names)]\n        + (\n            [SetField(output_field=FieldName.FEAT_STATIC_CAT, value=[0])]\n            if not self.num_feat_static_cat &gt; 0\n            else []\n        )\n        + (\n            [SetField(output_field=FieldName.FEAT_STATIC_REAL, value=[0.0])]\n            if not self.num_feat_static_real &gt; 0\n            else []\n        )\n        + [\n            AsNumpyArray(\n                field=FieldName.FEAT_STATIC_CAT,\n                expected_ndim=1,\n                dtype=int,\n            ),\n            AsNumpyArray(\n                field=FieldName.FEAT_STATIC_REAL,\n                expected_ndim=1,\n            ),\n            AsNumpyArray(\n                field=FieldName.TARGET,\n                # in the following line, we add 1 for the time dimension\n                expected_ndim=1 + len(self.distr_output.event_shape),\n            ),\n            AddObservedValuesIndicator(\n                target_field=FieldName.TARGET,\n                output_field=FieldName.OBSERVED_VALUES,\n            ),\n            AddTimeFeatures(\n                start_field=FieldName.START,\n                target_field=FieldName.TARGET,\n                output_field=FieldName.FEAT_TIME,\n                time_features=self.time_features,\n                pred_length=self.prediction_length,\n            ),\n            VstackFeatures(\n                output_field=FieldName.FEAT_TIME,\n                input_fields=[FieldName.FEAT_TIME]\n                + (\n                    [FieldName.FEAT_DYNAMIC_REAL]\n                    if self.num_feat_dynamic_real &gt; 0\n                    else []\n                ),\n            ),\n        ]\n    )\n</code></pre>"},{"location":"api/tpk/torch/estimator/MyEstimator/#tpk.torch.estimator.MyEstimator.create_validation_data_loader","title":"create_validation_data_loader","text":"<pre><code>create_validation_data_loader(data: Dataset, module: LightningModule, **kwargs: Any) -&gt; DataLoader\n</code></pre> Source code in <code>tpk/torch/estimator.py</code> <pre><code>def create_validation_data_loader(\n    self,\n    data: Dataset,\n    module: LightningModule,\n    **kwargs: Any,\n) -&gt; DataLoader:  # type: ignore\n    transformation = self._create_instance_splitter(\n        module, \"validation\"\n    ) + SelectFields(TRAINING_INPUT_NAMES)\n\n    validation_instances = transformation.apply(data)\n\n    # nosemgrep\n    return DataLoader(\n        IterableDataset(validation_instances),\n        batch_size=self.batch_size,\n        num_workers=2,\n        persistent_workers=True,\n        **kwargs,\n    )\n</code></pre>"},{"location":"api/tpk/torch/estimator/MyEstimator/#tpk.torch.estimator.MyEstimator.train_model","title":"train_model","text":"<pre><code>train_model(training_data: Dataset, validation_data: Optional[Dataset] = None, from_predictor: Optional[PyTorchPredictor] = None, shuffle_buffer_length: Optional[int] = None, cache_data: bool = False, ckpt_path: Optional[str] = None, **kwargs: Any) -&gt; TrainOutput\n</code></pre> Source code in <code>tpk/torch/estimator.py</code> <pre><code>def train_model(\n    self,\n    training_data: Dataset,\n    validation_data: Optional[Dataset] = None,\n    from_predictor: Optional[PyTorchPredictor] = None,\n    shuffle_buffer_length: Optional[int] = None,\n    cache_data: bool = False,\n    ckpt_path: Optional[str] = None,\n    **kwargs: Any,\n) -&gt; TrainOutput:\n    transformation = self.create_transformation()\n\n    with env._let(max_idle_transforms=max(len(training_data), 100)):\n        transformed_training_data: Dataset = transformation.apply(\n            training_data, is_train=True\n        )\n        if cache_data:\n            transformed_training_data = Cached(transformed_training_data)\n\n        training_network = self.create_lightning_module()\n\n        training_data_loader = self.create_training_data_loader(\n            transformed_training_data,\n            training_network,\n            shuffle_buffer_length=shuffle_buffer_length,\n        )\n\n    validation_data_loader = None\n\n    if validation_data is not None:\n        with env._let(max_idle_transforms=max(len(validation_data), 100)):\n            transformed_validation_data: Dataset = transformation.apply(\n                validation_data, is_train=True\n            )\n            if cache_data:\n                transformed_validation_data = Cached(transformed_validation_data)\n\n            validation_data_loader = self.create_validation_data_loader(\n                transformed_validation_data,\n                training_network,\n            )\n\n    if from_predictor is not None:\n        training_network.load_state_dict(from_predictor.network.state_dict())\n\n    monitor = \"train_loss\" if validation_data is None else \"val_loss\"\n    checkpoint = pl.callbacks.ModelCheckpoint(\n        monitor=monitor, mode=\"min\", verbose=True\n    )\n\n    custom_callbacks = self.trainer_kwargs.pop(\"callbacks\", [])\n    trainer = pl.Trainer(\n        **{\n            \"accelerator\": \"auto\",\n            \"callbacks\": [checkpoint] + custom_callbacks,\n            **self.trainer_kwargs,\n        }\n    )\n\n    tuner = Tuner(trainer)\n\n    tuner.lr_find(\n        model=training_network,\n        train_dataloaders=training_data_loader,\n        val_dataloaders=validation_data_loader,\n        early_stop_threshold=50.0,\n    )\n\n    trainer.fit(\n        model=training_network,\n        train_dataloaders=training_data_loader,\n        val_dataloaders=validation_data_loader,\n        ckpt_path=ckpt_path,\n    )\n\n    if checkpoint.best_model_path != \"\":\n        logger.info(f\"Loading best model from {checkpoint.best_model_path}\")\n        best_model = training_network.__class__.load_from_checkpoint(\n            checkpoint.best_model_path\n        )\n    else:\n        best_model = training_network\n\n    return TrainOutput(\n        transformation=transformation,\n        trained_net=best_model,\n        trainer=trainer,\n        predictor=self.create_predictor(transformation, best_model),\n    )\n</code></pre>"},{"location":"api/tpk/torch/lightning_module/MyLightningModule/","title":"MyLightningModule","text":""},{"location":"api/tpk/torch/lightning_module/MyLightningModule/#tpk.torch.lightning_module.MyLightningModule","title":"tpk.torch.lightning_module.MyLightningModule","text":"<pre><code>MyLightningModule(model: nn.Module, epochs: int, steps_per_epoch: int, loss: Optional[DistributionLoss] = None, weight_decay: float = 1e-08, patience: int = 10)\n</code></pre> <p>             Bases: <code>LightningModule</code></p> <p>A <code>pl.LightningModule</code> class that can be used to train a <code>nn.Module</code> with PyTorch Lightning.</p> <p>This is a thin layer around a (wrapped) <code>nn.Module</code> object, that exposes the methods to evaluate training and validation loss.</p>"},{"location":"api/tpk/torch/lightning_module/MyLightningModule/#tpk.torch.lightning_module.MyLightningModule--parameters","title":"Parameters","text":"<p>model     <code>nn.Module</code> to be trained. loss     Loss function to be used for training,     default: <code>NegativeLogLikelihood()</code>. weight_decay     Weight decay regularization parameter, default: <code>1e-8</code>. patience     Patience parameter for learning rate scheduler, default: <code>10</code>.</p> Source code in <code>tpk/torch/lightning_module.py</code> <pre><code>@validated()  # type: ignore\ndef __init__(\n    self,\n    model: nn.Module,\n    epochs: int,\n    steps_per_epoch: int,\n    loss: Optional[DistributionLoss] = None,\n    weight_decay: float = 1e-8,\n    patience: int = 10,\n) -&gt; None:\n    super().__init__()\n    self.loss = NegativeLogLikelihood() if loss is None else loss\n    self.save_hyperparameters()\n    self.model = model\n    self.weight_decay = weight_decay\n    self.patience = patience\n    self.epochs = epochs\n    self.steps_per_epoch = steps_per_epoch\n    self.lr = 0.0\n    self.example_input_array = tuple(\n        [\n            torch.zeros(shape, dtype=self.model.input_types()[name])\n            for (name, shape) in self.model.input_shapes().items()\n        ]\n    )\n</code></pre>"},{"location":"api/tpk/torch/lightning_module/MyLightningModule/#tpk.torch.lightning_module.MyLightningModule.epochs","title":"epochs  <code>instance-attribute</code>","text":"<pre><code>epochs = epochs\n</code></pre>"},{"location":"api/tpk/torch/lightning_module/MyLightningModule/#tpk.torch.lightning_module.MyLightningModule.example_input_array","title":"example_input_array  <code>instance-attribute</code>","text":"<pre><code>example_input_array = tuple([torch.zeros(shape, dtype=self.model.input_types()[name]) for (name, shape) in self.model.input_shapes().items()])\n</code></pre>"},{"location":"api/tpk/torch/lightning_module/MyLightningModule/#tpk.torch.lightning_module.MyLightningModule.loss","title":"loss  <code>instance-attribute</code>","text":"<pre><code>loss = NegativeLogLikelihood() if loss is None else loss\n</code></pre>"},{"location":"api/tpk/torch/lightning_module/MyLightningModule/#tpk.torch.lightning_module.MyLightningModule.lr","title":"lr  <code>instance-attribute</code>","text":"<pre><code>lr = 0.0\n</code></pre>"},{"location":"api/tpk/torch/lightning_module/MyLightningModule/#tpk.torch.lightning_module.MyLightningModule.model","title":"model  <code>instance-attribute</code>","text":"<pre><code>model = model\n</code></pre>"},{"location":"api/tpk/torch/lightning_module/MyLightningModule/#tpk.torch.lightning_module.MyLightningModule.patience","title":"patience  <code>instance-attribute</code>","text":"<pre><code>patience = patience\n</code></pre>"},{"location":"api/tpk/torch/lightning_module/MyLightningModule/#tpk.torch.lightning_module.MyLightningModule.steps_per_epoch","title":"steps_per_epoch  <code>instance-attribute</code>","text":"<pre><code>steps_per_epoch = steps_per_epoch\n</code></pre>"},{"location":"api/tpk/torch/lightning_module/MyLightningModule/#tpk.torch.lightning_module.MyLightningModule.weight_decay","title":"weight_decay  <code>instance-attribute</code>","text":"<pre><code>weight_decay = weight_decay\n</code></pre>"},{"location":"api/tpk/torch/lightning_module/MyLightningModule/#tpk.torch.lightning_module.MyLightningModule.configure_optimizers","title":"configure_optimizers","text":"<pre><code>configure_optimizers() -&gt; Any\n</code></pre> <p>Returns the optimizer to use.</p> Source code in <code>tpk/torch/lightning_module.py</code> <pre><code>def configure_optimizers(self) -&gt; Any:\n    \"\"\"\n    Returns the optimizer to use.\n    \"\"\"\n    optimizer = torch.optim.Adam(\n        self.model.parameters(),\n        lr=self.lr,\n        weight_decay=self.weight_decay,\n    )\n\n    optimizer_config: Dict[str, Any] = {\n        \"optimizer\": optimizer,\n    }\n\n    if self.lr != 0.0:\n        optimizer_config[\"lr_scheduler\"] = {\n            \"scheduler\": OneCycleLR(\n                optimizer=optimizer,\n                max_lr=self.lr,\n                epochs=self.epochs,\n                steps_per_epoch=self.steps_per_epoch,\n            ),\n        }\n\n    return optimizer_config\n</code></pre>"},{"location":"api/tpk/torch/lightning_module/MyLightningModule/#tpk.torch.lightning_module.MyLightningModule.forward","title":"forward","text":"<pre><code>forward(*args: List[Any], **kwargs: Dict[str, Any]) -&gt; Any\n</code></pre> Source code in <code>tpk/torch/lightning_module.py</code> <pre><code>def forward(self, *args: List[Any], **kwargs: Dict[str, Any]) -&gt; Any:\n    return self.model(*args, **kwargs)\n</code></pre>"},{"location":"api/tpk/torch/lightning_module/MyLightningModule/#tpk.torch.lightning_module.MyLightningModule.training_step","title":"training_step","text":"<pre><code>training_step(batch, batch_idx: int)\n</code></pre> <p>Execute training step.</p> Source code in <code>tpk/torch/lightning_module.py</code> <pre><code>def training_step(self, batch, batch_idx: int):  # type: ignore\n    \"\"\"\n    Execute training step.\n    \"\"\"\n    train_loss = self._compute_loss(batch)\n    self.log(\n        \"train_loss\",\n        train_loss,\n        on_epoch=True,\n        on_step=False,\n        prog_bar=True,\n    )\n    return train_loss\n</code></pre>"},{"location":"api/tpk/torch/lightning_module/MyLightningModule/#tpk.torch.lightning_module.MyLightningModule.validation_step","title":"validation_step","text":"<pre><code>validation_step(batch, batch_idx: int)\n</code></pre> <p>Execute validation step.</p> Source code in <code>tpk/torch/lightning_module.py</code> <pre><code>def validation_step(self, batch, batch_idx: int):  # type: ignore\n    \"\"\"\n    Execute validation step.\n    \"\"\"\n    val_loss = self._compute_loss(batch)\n    self.log(\"val_loss\", val_loss, on_epoch=True, on_step=False, prog_bar=True)\n    return val_loss\n</code></pre>"},{"location":"api/tpk/torch/tpk/TPKModel/","title":"TPKModel","text":""},{"location":"api/tpk/torch/tpk/TPKModel/#tpk.torch.tpk.TPKModel","title":"tpk.torch.tpk.TPKModel","text":"<pre><code>TPKModel(freq: str, context_length: int, prediction_length: int, num_feat_dynamic_real: int, num_future_feat: int, num_feat_static_real: int, num_feat_static_cat: int, cardinality: List[int], distr_output: DistributionOutput, embedding_dimension: Optional[List[int]] = None, n_block: int = 2, hidden_size: int = 128, dropout_rate: float = 0.1, scaling: bool = True)\n</code></pre> <p>             Bases: <code>Module</code></p> <p>Module implementing the TPK model, see [SFG17]_.</p> <p>Note: the code of this model is unrelated to the implementation behind <code>SageMaker's TPK Forecasting Algorithm &lt;https://docs.aws.amazon.com/sagemaker/latest/dg/deepar.html&gt;</code>_.</p>"},{"location":"api/tpk/torch/tpk/TPKModel/#tpk.torch.tpk.TPKModel--parameters","title":"Parameters","text":"<p>freq     String indicating the sampling frequency of the data to be processed. context_length     Length of the RNN unrolling prior to the forecast date. prediction_length     Number of time points to predict. num_feat_dynamic_real     Number of dynamic real features that will be provided to <code>forward</code>. num_feat_static_real     Number of static real features that will be provided to <code>forward</code>. num_feat_static_cat     Number of static categorical features that will be provided to     <code>forward</code>. cardinality     List of cardinalities, one for each static categorical feature. embedding_dimension     Dimension of the embedding space, one for each static categorical     feature. n_block     Number of layers in the RNN. hidden_size     Size of the hidden layers in the RNN. dropout_rate     Dropout rate to be applied at training time. distr_output     Type of distribution to be output by the model at each time step scaling     Whether to apply mean scaling to the observations (target).</p> Source code in <code>tpk/torch/tpk/module.py</code> <pre><code>@validated()  # type: ignore\ndef __init__(\n    self,\n    freq: str,\n    context_length: int,\n    prediction_length: int,\n    num_feat_dynamic_real: int,\n    num_future_feat: int,\n    num_feat_static_real: int,\n    num_feat_static_cat: int,\n    cardinality: List[int],\n    distr_output: DistributionOutput,\n    embedding_dimension: Optional[List[int]] = None,\n    n_block: int = 2,\n    hidden_size: int = 128,\n    dropout_rate: float = 0.1,\n    scaling: bool = True,\n) -&gt; None:\n    super().__init__()\n\n    # assert distr_output.event_shape == ()\n\n    self.context_length = context_length\n    self.prediction_length = prediction_length\n    self.num_feat_dynamic_real = num_feat_dynamic_real\n    self.num_future_feat = num_future_feat\n    self.num_feat_static_cat = num_feat_static_cat\n    self.num_feat_static_real = num_feat_static_real\n    self.embedding_dimension = (\n        embedding_dimension\n        if embedding_dimension is not None or cardinality is None\n        else [min(32, (cat + 1) // 2) for cat in cardinality]\n    )\n    self.past_length = self.context_length\n    self.embedder = FeatureEmbedder(\n        cardinalities=cardinality,\n        embedding_dims=self.embedding_dimension,\n    )\n\n    if scaling:\n        self.scaler = MeanScaler(dim=-1, keepdim=True)\n    else:\n        self.scaler = NOPScaler(dim=-1, keepdim=True)\n\n    self.distr_output = StudentTOutput() if distr_output is None else distr_output\n    self.args_proj = distr_output.get_args_proj(hidden_size)\n\n    self.tsmixer_encoder = TPKEncoder(\n        input_len=context_length,\n        output_len=prediction_length,\n        past_feat_size=self.num_feat_dynamic_real + 1,  # target\n        future_feat_size=max(1, self.num_future_feat),\n        static_feat_size=(sum(self.embedding_dimension) + num_feat_static_real + 1),\n        activation=\"relu\",\n        dropout=dropout_rate,\n        n_block=n_block,\n        hidden_size=hidden_size,\n    )\n</code></pre>"},{"location":"api/tpk/torch/tpk/TPKModel/#tpk.torch.tpk.TPKModel.args_proj","title":"args_proj  <code>instance-attribute</code>","text":"<pre><code>args_proj = distr_output.get_args_proj(hidden_size)\n</code></pre>"},{"location":"api/tpk/torch/tpk/TPKModel/#tpk.torch.tpk.TPKModel.context_length","title":"context_length  <code>instance-attribute</code>","text":"<pre><code>context_length = context_length\n</code></pre>"},{"location":"api/tpk/torch/tpk/TPKModel/#tpk.torch.tpk.TPKModel.distr_output","title":"distr_output  <code>instance-attribute</code>","text":"<pre><code>distr_output = StudentTOutput() if distr_output is None else distr_output\n</code></pre>"},{"location":"api/tpk/torch/tpk/TPKModel/#tpk.torch.tpk.TPKModel.embedder","title":"embedder  <code>instance-attribute</code>","text":"<pre><code>embedder = FeatureEmbedder(cardinalities=cardinality, embedding_dims=self.embedding_dimension)\n</code></pre>"},{"location":"api/tpk/torch/tpk/TPKModel/#tpk.torch.tpk.TPKModel.embedding_dimension","title":"embedding_dimension  <code>instance-attribute</code>","text":"<pre><code>embedding_dimension = embedding_dimension if embedding_dimension is not None or cardinality is None else [min(32, cat + 1 // 2) for cat in cardinality]\n</code></pre>"},{"location":"api/tpk/torch/tpk/TPKModel/#tpk.torch.tpk.TPKModel.num_feat_dynamic_real","title":"num_feat_dynamic_real  <code>instance-attribute</code>","text":"<pre><code>num_feat_dynamic_real = num_feat_dynamic_real\n</code></pre>"},{"location":"api/tpk/torch/tpk/TPKModel/#tpk.torch.tpk.TPKModel.num_feat_static_cat","title":"num_feat_static_cat  <code>instance-attribute</code>","text":"<pre><code>num_feat_static_cat = num_feat_static_cat\n</code></pre>"},{"location":"api/tpk/torch/tpk/TPKModel/#tpk.torch.tpk.TPKModel.num_feat_static_real","title":"num_feat_static_real  <code>instance-attribute</code>","text":"<pre><code>num_feat_static_real = num_feat_static_real\n</code></pre>"},{"location":"api/tpk/torch/tpk/TPKModel/#tpk.torch.tpk.TPKModel.num_future_feat","title":"num_future_feat  <code>instance-attribute</code>","text":"<pre><code>num_future_feat = num_future_feat\n</code></pre>"},{"location":"api/tpk/torch/tpk/TPKModel/#tpk.torch.tpk.TPKModel.past_length","title":"past_length  <code>instance-attribute</code>","text":"<pre><code>past_length = self.context_length\n</code></pre>"},{"location":"api/tpk/torch/tpk/TPKModel/#tpk.torch.tpk.TPKModel.prediction_length","title":"prediction_length  <code>instance-attribute</code>","text":"<pre><code>prediction_length = prediction_length\n</code></pre>"},{"location":"api/tpk/torch/tpk/TPKModel/#tpk.torch.tpk.TPKModel.scaler","title":"scaler  <code>instance-attribute</code>","text":"<pre><code>scaler = MeanScaler(dim=-1, keepdim=True)\n</code></pre>"},{"location":"api/tpk/torch/tpk/TPKModel/#tpk.torch.tpk.TPKModel.tsmixer_encoder","title":"tsmixer_encoder  <code>instance-attribute</code>","text":"<pre><code>tsmixer_encoder = TPKEncoder(input_len=context_length, output_len=prediction_length, past_feat_size=self.num_feat_dynamic_real + 1, future_feat_size=max(1, self.num_future_feat), static_feat_size=sum(self.embedding_dimension) + num_feat_static_real + 1, activation='relu', dropout=dropout_rate, n_block=n_block, hidden_size=hidden_size)\n</code></pre>"},{"location":"api/tpk/torch/tpk/TPKModel/#tpk.torch.tpk.TPKModel.forward","title":"forward","text":"<pre><code>forward(feat_static_cat: torch.Tensor, feat_static_real: torch.Tensor, past_time_feat: torch.Tensor, past_target: torch.Tensor, past_observed_values: torch.Tensor, future_time_feat: torch.Tensor) -&gt; Tuple[Any, torch.Tensor, Any]\n</code></pre> <p>Invokes the model on input data, and produce outputs future samples.</p>"},{"location":"api/tpk/torch/tpk/TPKModel/#tpk.torch.tpk.TPKModel.forward--parameters","title":"Parameters","text":"<p>feat_static_cat     Tensor of static categorical features,     shape: <code>(batch_size, num_feat_static_cat)</code>. feat_static_real     Tensor of static real features,     shape: <code>(batch_size, num_feat_static_real)</code>. past_time_feat     Tensor of dynamic real features in the past,     shape: <code>(batch_size, past_length, num_feat_dynamic_real)</code>. past_target     Tensor of past target values,     shape: <code>(batch_size, past_length)</code>. past_observed_values     Tensor of observed values indicators,     shape: <code>(batch_size, past_length)</code>. future_time_feat     (Optional) tensor of dynamic real features in the past,     shape: <code>(batch_size, prediction_length, num_feat_dynamic_real)</code>.</p> Source code in <code>tpk/torch/tpk/module.py</code> <pre><code>def forward(\n    self,\n    feat_static_cat: torch.Tensor,\n    feat_static_real: torch.Tensor,\n    past_time_feat: torch.Tensor,\n    past_target: torch.Tensor,\n    past_observed_values: torch.Tensor,\n    future_time_feat: torch.Tensor,\n) -&gt; Tuple[Any, torch.Tensor, Any]:\n    \"\"\"\n    Invokes the model on input data, and produce outputs future samples.\n\n    Parameters\n    ----------\n    feat_static_cat\n        Tensor of static categorical features,\n        shape: ``(batch_size, num_feat_static_cat)``.\n    feat_static_real\n        Tensor of static real features,\n        shape: ``(batch_size, num_feat_static_real)``.\n    past_time_feat\n        Tensor of dynamic real features in the past,\n        shape: ``(batch_size, past_length, num_feat_dynamic_real)``.\n    past_target\n        Tensor of past target values,\n        shape: ``(batch_size, past_length)``.\n    past_observed_values\n        Tensor of observed values indicators,\n        shape: ``(batch_size, past_length)``.\n    future_time_feat\n        (Optional) tensor of dynamic real features in the past,\n        shape: ``(batch_size, prediction_length, num_feat_dynamic_real)``.\n    \"\"\"\n    if self.num_future_feat == 0:\n        future_time_feat = torch.zeros_like(future_time_feat)[:, :, [0]]\n    else:\n        future_time_feat = future_time_feat[:, :, : self.num_future_feat]\n    _, _, scale = self.scaler(past_target, past_observed_values)\n\n    scaled_past_target = past_target / scale\n\n    embedded_cat = self.embedder(feat_static_cat)\n    static_feat = torch.cat(\n        (embedded_cat, feat_static_real, scale.log()),\n        dim=-1,\n    )\n    past_feature = torch.cat(\n        (scaled_past_target.unsqueeze(-1), past_time_feat), dim=-1\n    )\n    output = self.tsmixer_encoder(past_feature, future_time_feat, static_feat)\n    distr_args = self.args_proj(output)\n    return distr_args, torch.zeros_like(scale), scale\n</code></pre>"},{"location":"api/tpk/torch/tpk/TPKModel/#tpk.torch.tpk.TPKModel.input_shapes","title":"input_shapes","text":"<pre><code>input_shapes(batch_size: int = 1) -&gt; Dict[str, Tuple[int, ...]]\n</code></pre> Source code in <code>tpk/torch/tpk/module.py</code> <pre><code>def input_shapes(self, batch_size: int = 1) -&gt; Dict[str, Tuple[int, ...]]:\n    return {\n        \"feat_static_cat\": (batch_size, self.num_feat_static_cat),\n        \"feat_static_real\": (batch_size, self.num_feat_static_real),\n        \"past_time_feat\": (\n            batch_size,\n            self._past_length,\n            self.num_feat_dynamic_real,\n        ),\n        \"past_target\": (batch_size, self._past_length),\n        \"past_observed_values\": (batch_size, self._past_length),\n        \"future_time_feat\": (\n            batch_size,\n            self.prediction_length,\n            self.num_feat_dynamic_real,\n        ),\n    }\n</code></pre>"},{"location":"api/tpk/torch/tpk/TPKModel/#tpk.torch.tpk.TPKModel.input_types","title":"input_types","text":"<pre><code>input_types() -&gt; Dict[str, torch.dtype]\n</code></pre> Source code in <code>tpk/torch/tpk/module.py</code> <pre><code>def input_types(self) -&gt; Dict[str, torch.dtype]:\n    return {\n        \"feat_static_cat\": torch.long,\n        \"feat_static_real\": torch.float,\n        \"past_time_feat\": torch.float,\n        \"past_target\": torch.float,\n        \"past_observed_values\": torch.float,\n        \"future_time_feat\": torch.float,\n    }\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/ConditionalFeaturalResBlock/","title":"ConditionalFeaturalResBlock","text":""},{"location":"api/tpk/torch/tpk/module/ConditionalFeaturalResBlock/#tpk.torch.tpk.module.ConditionalFeaturalResBlock","title":"tpk.torch.tpk.module.ConditionalFeaturalResBlock","text":"<pre><code>ConditionalFeaturalResBlock(input_len: int, input_size: int, hidden_size: int, output_size: int, static_size: int, activation: str = 'relu', dropout: float = 0)\n</code></pre> <p>             Bases: <code>Module</code></p> Source code in <code>tpk/torch/tpk/module.py</code> <pre><code>def __init__(\n    self,\n    input_len: int,\n    input_size: int,\n    hidden_size: int,\n    output_size: int,\n    static_size: int,\n    activation: str = \"relu\",\n    dropout: float = 0,\n):\n    super().__init__()\n    self.input_len = input_len\n    self.static_block = FeaturalResBlock(\n        1, static_size, hidden_size, hidden_size, activation, dropout\n    )\n    self.block = FeaturalResBlock(\n        input_len,\n        input_size + hidden_size,\n        hidden_size,\n        output_size,\n        activation,\n        dropout,\n    )\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/ConditionalFeaturalResBlock/#tpk.torch.tpk.module.ConditionalFeaturalResBlock.block","title":"block  <code>instance-attribute</code>","text":"<pre><code>block = FeaturalResBlock(input_len, input_size + hidden_size, hidden_size, output_size, activation, dropout)\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/ConditionalFeaturalResBlock/#tpk.torch.tpk.module.ConditionalFeaturalResBlock.input_len","title":"input_len  <code>instance-attribute</code>","text":"<pre><code>input_len = input_len\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/ConditionalFeaturalResBlock/#tpk.torch.tpk.module.ConditionalFeaturalResBlock.static_block","title":"static_block  <code>instance-attribute</code>","text":"<pre><code>static_block = FeaturalResBlock(1, static_size, hidden_size, hidden_size, activation, dropout)\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/ConditionalFeaturalResBlock/#tpk.torch.tpk.module.ConditionalFeaturalResBlock.forward","title":"forward","text":"<pre><code>forward(x: torch.Tensor, static: torch.Tensor) -&gt; torch.Tensor\n</code></pre> Source code in <code>tpk/torch/tpk/module.py</code> <pre><code>def forward(self, x: torch.Tensor, static: torch.Tensor) -&gt; torch.Tensor:\n    static = self.static_block(static.unsqueeze(1))\n    static = torch.repeat_interleave(static, self.input_len, dim=1)\n    x = torch.concat([x, static], dim=2)\n    x = self.block(x)\n    return x\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/ConditionalMixerBlock/","title":"ConditionalMixerBlock","text":""},{"location":"api/tpk/torch/tpk/module/ConditionalMixerBlock/#tpk.torch.tpk.module.ConditionalMixerBlock","title":"tpk.torch.tpk.module.ConditionalMixerBlock","text":"<pre><code>ConditionalMixerBlock(input_len: int, input_size: int, hidden_size: int, output_size: int, static_size: int, activation: str, dropout: float)\n</code></pre> <p>             Bases: <code>Module</code></p> Source code in <code>tpk/torch/tpk/module.py</code> <pre><code>def __init__(\n    self,\n    input_len: int,\n    input_size: int,\n    hidden_size: int,\n    output_size: int,\n    static_size: int,\n    activation: str,\n    dropout: float,\n):\n    super().__init__()\n    self.temporal_res_block = TemporalResBlock(\n        input_len, input_size, activation, dropout\n    )\n    self.ffwd_res_block = ConditionalFeaturalResBlock(\n        input_len,\n        input_size,\n        hidden_size,\n        output_size,\n        static_size,\n        activation,\n        dropout,\n    )\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/ConditionalMixerBlock/#tpk.torch.tpk.module.ConditionalMixerBlock.ffwd_res_block","title":"ffwd_res_block  <code>instance-attribute</code>","text":"<pre><code>ffwd_res_block = ConditionalFeaturalResBlock(input_len, input_size, hidden_size, output_size, static_size, activation, dropout)\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/ConditionalMixerBlock/#tpk.torch.tpk.module.ConditionalMixerBlock.temporal_res_block","title":"temporal_res_block  <code>instance-attribute</code>","text":"<pre><code>temporal_res_block = TemporalResBlock(input_len, input_size, activation, dropout)\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/ConditionalMixerBlock/#tpk.torch.tpk.module.ConditionalMixerBlock.forward","title":"forward","text":"<pre><code>forward(x: torch.Tensor, static: torch.Tensor) -&gt; torch.Tensor\n</code></pre> Source code in <code>tpk/torch/tpk/module.py</code> <pre><code>def forward(self, x: torch.Tensor, static: torch.Tensor) -&gt; torch.Tensor:\n    x = self.temporal_res_block(x)\n    x = self.ffwd_res_block(x, static)\n    return x\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/FeaturalResBlock/","title":"FeaturalResBlock","text":""},{"location":"api/tpk/torch/tpk/module/FeaturalResBlock/#tpk.torch.tpk.module.FeaturalResBlock","title":"tpk.torch.tpk.module.FeaturalResBlock","text":"<pre><code>FeaturalResBlock(input_len: int, input_size: int, hidden_size: int, output_size: int, activation: str = 'relu', dropout: float = 0)\n</code></pre> <p>             Bases: <code>Module</code></p> Source code in <code>tpk/torch/tpk/module.py</code> <pre><code>def __init__(\n    self,\n    input_len: int,\n    input_size: int,\n    hidden_size: int,\n    output_size: int,\n    activation: str = \"relu\",\n    dropout: float = 0,\n):\n    super().__init__()\n    self.linear1 = nn.Linear(in_features=input_size, out_features=hidden_size)\n    self.linear2 = nn.Linear(in_features=hidden_size, out_features=output_size)\n    self.res_linear = None\n    if input_size != output_size:\n        self.res_linear = nn.Linear(\n            in_features=input_size, out_features=output_size\n        )\n    self.activation = getattr(F, activation)\n    self.dropout = nn.Dropout(p=dropout)\n    self.norm = nn.LayerNorm(normalized_shape=[input_len, output_size])\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/FeaturalResBlock/#tpk.torch.tpk.module.FeaturalResBlock.activation","title":"activation  <code>instance-attribute</code>","text":"<pre><code>activation = getattr(F, activation)\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/FeaturalResBlock/#tpk.torch.tpk.module.FeaturalResBlock.dropout","title":"dropout  <code>instance-attribute</code>","text":"<pre><code>dropout = nn.Dropout(p=dropout)\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/FeaturalResBlock/#tpk.torch.tpk.module.FeaturalResBlock.linear1","title":"linear1  <code>instance-attribute</code>","text":"<pre><code>linear1 = nn.Linear(in_features=input_size, out_features=hidden_size)\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/FeaturalResBlock/#tpk.torch.tpk.module.FeaturalResBlock.linear2","title":"linear2  <code>instance-attribute</code>","text":"<pre><code>linear2 = nn.Linear(in_features=hidden_size, out_features=output_size)\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/FeaturalResBlock/#tpk.torch.tpk.module.FeaturalResBlock.norm","title":"norm  <code>instance-attribute</code>","text":"<pre><code>norm = nn.LayerNorm(normalized_shape=[input_len, output_size])\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/FeaturalResBlock/#tpk.torch.tpk.module.FeaturalResBlock.res_linear","title":"res_linear  <code>instance-attribute</code>","text":"<pre><code>res_linear = None\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/FeaturalResBlock/#tpk.torch.tpk.module.FeaturalResBlock.forward","title":"forward","text":"<pre><code>forward(x: torch.Tensor) -&gt; Any\n</code></pre> Source code in <code>tpk/torch/tpk/module.py</code> <pre><code>def forward(self, x: torch.Tensor) -&gt; Any:\n    res = x if self.res_linear is None else self.res_linear(x)\n    x = self.linear1(x)\n    x = self.activation(x)\n    x = self.dropout(x)\n    x = self.linear2(x)\n    x = self.dropout(x)\n    return self.norm(res + x)\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/MixerBlock/","title":"MixerBlock","text":""},{"location":"api/tpk/torch/tpk/module/MixerBlock/#tpk.torch.tpk.module.MixerBlock","title":"tpk.torch.tpk.module.MixerBlock","text":"<pre><code>MixerBlock(input_len: int, input_size: int, hidden_size: int, output_size: int, activation: str, dropout: float)\n</code></pre> <p>             Bases: <code>Module</code></p> Source code in <code>tpk/torch/tpk/module.py</code> <pre><code>def __init__(\n    self,\n    input_len: int,\n    input_size: int,\n    hidden_size: int,\n    output_size: int,\n    activation: str,\n    dropout: float,\n):\n    super().__init__()\n    self.temporal_res_block = TemporalResBlock(\n        input_len, input_size, activation, dropout\n    )\n    self.ffwd_res_block = FeaturalResBlock(\n        input_len,\n        input_size,\n        hidden_size,\n        output_size,\n        activation,\n        dropout,\n    )\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/MixerBlock/#tpk.torch.tpk.module.MixerBlock.ffwd_res_block","title":"ffwd_res_block  <code>instance-attribute</code>","text":"<pre><code>ffwd_res_block = FeaturalResBlock(input_len, input_size, hidden_size, output_size, activation, dropout)\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/MixerBlock/#tpk.torch.tpk.module.MixerBlock.temporal_res_block","title":"temporal_res_block  <code>instance-attribute</code>","text":"<pre><code>temporal_res_block = TemporalResBlock(input_len, input_size, activation, dropout)\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/MixerBlock/#tpk.torch.tpk.module.MixerBlock.forward","title":"forward","text":"<pre><code>forward(x: torch.Tensor) -&gt; torch.Tensor\n</code></pre> Source code in <code>tpk/torch/tpk/module.py</code> <pre><code>def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n    x = self.temporal_res_block(x)\n    x = self.ffwd_res_block(x)\n    return x\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/TPKEncoder/","title":"TPKEncoder","text":""},{"location":"api/tpk/torch/tpk/module/TPKEncoder/#tpk.torch.tpk.module.TPKEncoder","title":"tpk.torch.tpk.module.TPKEncoder","text":"<pre><code>TPKEncoder(input_len: int, output_len: int, past_feat_size: int, future_feat_size: int, static_feat_size: int, hidden_size: int, activation: str, dropout: float, n_block: int = 1)\n</code></pre> <p>             Bases: <code>Module</code></p> Source code in <code>tpk/torch/tpk/module.py</code> <pre><code>def __init__(\n    self,\n    input_len: int,\n    output_len: int,\n    past_feat_size: int,\n    future_feat_size: int,\n    static_feat_size: int,\n    hidden_size: int,\n    activation: str,\n    dropout: float,\n    n_block: int = 1,\n):\n    super().__init__()\n    self.past_temporal_linear = TemporalLinear(input_len, output_len)\n    self.past_featural_block = ConditionalFeaturalResBlock(\n        input_len=output_len,\n        input_size=past_feat_size,\n        hidden_size=hidden_size,\n        output_size=hidden_size,\n        static_size=static_feat_size,\n        activation=activation,\n        dropout=dropout,\n    )\n    self.future_featural_block = ConditionalFeaturalResBlock(\n        input_len=output_len,\n        input_size=future_feat_size,\n        hidden_size=hidden_size,\n        output_size=hidden_size,\n        static_size=static_feat_size,\n        activation=activation,\n        dropout=dropout,\n    )\n    self.blocks = nn.ModuleList(\n        [\n            ConditionalMixerBlock(\n                input_len=output_len,\n                input_size=(2 * hidden_size) if i == 0 else hidden_size,\n                hidden_size=hidden_size,\n                output_size=hidden_size,\n                static_size=static_feat_size,\n                activation=activation,\n                dropout=dropout,\n            )\n            for i in range(n_block)\n        ]\n    )\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/TPKEncoder/#tpk.torch.tpk.module.TPKEncoder.blocks","title":"blocks  <code>instance-attribute</code>","text":"<pre><code>blocks = nn.ModuleList([ConditionalMixerBlock(input_len=output_len, input_size=2 * hidden_size if i == 0 else hidden_size, hidden_size=hidden_size, output_size=hidden_size, static_size=static_feat_size, activation=activation, dropout=dropout) for i in range(n_block)])\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/TPKEncoder/#tpk.torch.tpk.module.TPKEncoder.future_featural_block","title":"future_featural_block  <code>instance-attribute</code>","text":"<pre><code>future_featural_block = ConditionalFeaturalResBlock(input_len=output_len, input_size=future_feat_size, hidden_size=hidden_size, output_size=hidden_size, static_size=static_feat_size, activation=activation, dropout=dropout)\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/TPKEncoder/#tpk.torch.tpk.module.TPKEncoder.past_featural_block","title":"past_featural_block  <code>instance-attribute</code>","text":"<pre><code>past_featural_block = ConditionalFeaturalResBlock(input_len=output_len, input_size=past_feat_size, hidden_size=hidden_size, output_size=hidden_size, static_size=static_feat_size, activation=activation, dropout=dropout)\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/TPKEncoder/#tpk.torch.tpk.module.TPKEncoder.past_temporal_linear","title":"past_temporal_linear  <code>instance-attribute</code>","text":"<pre><code>past_temporal_linear = TemporalLinear(input_len, output_len)\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/TPKEncoder/#tpk.torch.tpk.module.TPKEncoder.forward","title":"forward","text":"<pre><code>forward(past_feature: torch.Tensor, future_feature: torch.Tensor, static_feature: torch.Tensor) -&gt; torch.Tensor\n</code></pre> Source code in <code>tpk/torch/tpk/module.py</code> <pre><code>def forward(\n    self,\n    past_feature: torch.Tensor,\n    future_feature: torch.Tensor,\n    static_feature: torch.Tensor,\n) -&gt; torch.Tensor:\n    past_feature = self.past_temporal_linear(past_feature)\n    past_feature = self.past_featural_block(past_feature, static_feature)\n    future_feature = self.future_featural_block(future_feature, static_feature)\n    x = torch.cat([past_feature, future_feature], dim=2)\n    for block in self.blocks:\n        x = block(x, static_feature)\n    return x\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/TPKModel/","title":"TPKModel","text":""},{"location":"api/tpk/torch/tpk/module/TPKModel/#tpk.torch.tpk.module.TPKModel","title":"tpk.torch.tpk.module.TPKModel","text":"<pre><code>TPKModel(freq: str, context_length: int, prediction_length: int, num_feat_dynamic_real: int, num_future_feat: int, num_feat_static_real: int, num_feat_static_cat: int, cardinality: List[int], distr_output: DistributionOutput, embedding_dimension: Optional[List[int]] = None, n_block: int = 2, hidden_size: int = 128, dropout_rate: float = 0.1, scaling: bool = True)\n</code></pre> <p>             Bases: <code>Module</code></p> <p>Module implementing the TPK model, see [SFG17]_.</p> <p>Note: the code of this model is unrelated to the implementation behind <code>SageMaker's TPK Forecasting Algorithm &lt;https://docs.aws.amazon.com/sagemaker/latest/dg/deepar.html&gt;</code>_.</p>"},{"location":"api/tpk/torch/tpk/module/TPKModel/#tpk.torch.tpk.module.TPKModel--parameters","title":"Parameters","text":"<p>freq     String indicating the sampling frequency of the data to be processed. context_length     Length of the RNN unrolling prior to the forecast date. prediction_length     Number of time points to predict. num_feat_dynamic_real     Number of dynamic real features that will be provided to <code>forward</code>. num_feat_static_real     Number of static real features that will be provided to <code>forward</code>. num_feat_static_cat     Number of static categorical features that will be provided to     <code>forward</code>. cardinality     List of cardinalities, one for each static categorical feature. embedding_dimension     Dimension of the embedding space, one for each static categorical     feature. n_block     Number of layers in the RNN. hidden_size     Size of the hidden layers in the RNN. dropout_rate     Dropout rate to be applied at training time. distr_output     Type of distribution to be output by the model at each time step scaling     Whether to apply mean scaling to the observations (target).</p> Source code in <code>tpk/torch/tpk/module.py</code> <pre><code>@validated()  # type: ignore\ndef __init__(\n    self,\n    freq: str,\n    context_length: int,\n    prediction_length: int,\n    num_feat_dynamic_real: int,\n    num_future_feat: int,\n    num_feat_static_real: int,\n    num_feat_static_cat: int,\n    cardinality: List[int],\n    distr_output: DistributionOutput,\n    embedding_dimension: Optional[List[int]] = None,\n    n_block: int = 2,\n    hidden_size: int = 128,\n    dropout_rate: float = 0.1,\n    scaling: bool = True,\n) -&gt; None:\n    super().__init__()\n\n    # assert distr_output.event_shape == ()\n\n    self.context_length = context_length\n    self.prediction_length = prediction_length\n    self.num_feat_dynamic_real = num_feat_dynamic_real\n    self.num_future_feat = num_future_feat\n    self.num_feat_static_cat = num_feat_static_cat\n    self.num_feat_static_real = num_feat_static_real\n    self.embedding_dimension = (\n        embedding_dimension\n        if embedding_dimension is not None or cardinality is None\n        else [min(32, (cat + 1) // 2) for cat in cardinality]\n    )\n    self.past_length = self.context_length\n    self.embedder = FeatureEmbedder(\n        cardinalities=cardinality,\n        embedding_dims=self.embedding_dimension,\n    )\n\n    if scaling:\n        self.scaler = MeanScaler(dim=-1, keepdim=True)\n    else:\n        self.scaler = NOPScaler(dim=-1, keepdim=True)\n\n    self.distr_output = StudentTOutput() if distr_output is None else distr_output\n    self.args_proj = distr_output.get_args_proj(hidden_size)\n\n    self.tsmixer_encoder = TPKEncoder(\n        input_len=context_length,\n        output_len=prediction_length,\n        past_feat_size=self.num_feat_dynamic_real + 1,  # target\n        future_feat_size=max(1, self.num_future_feat),\n        static_feat_size=(sum(self.embedding_dimension) + num_feat_static_real + 1),\n        activation=\"relu\",\n        dropout=dropout_rate,\n        n_block=n_block,\n        hidden_size=hidden_size,\n    )\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/TPKModel/#tpk.torch.tpk.module.TPKModel.args_proj","title":"args_proj  <code>instance-attribute</code>","text":"<pre><code>args_proj = distr_output.get_args_proj(hidden_size)\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/TPKModel/#tpk.torch.tpk.module.TPKModel.context_length","title":"context_length  <code>instance-attribute</code>","text":"<pre><code>context_length = context_length\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/TPKModel/#tpk.torch.tpk.module.TPKModel.distr_output","title":"distr_output  <code>instance-attribute</code>","text":"<pre><code>distr_output = StudentTOutput() if distr_output is None else distr_output\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/TPKModel/#tpk.torch.tpk.module.TPKModel.embedder","title":"embedder  <code>instance-attribute</code>","text":"<pre><code>embedder = FeatureEmbedder(cardinalities=cardinality, embedding_dims=self.embedding_dimension)\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/TPKModel/#tpk.torch.tpk.module.TPKModel.embedding_dimension","title":"embedding_dimension  <code>instance-attribute</code>","text":"<pre><code>embedding_dimension = embedding_dimension if embedding_dimension is not None or cardinality is None else [min(32, cat + 1 // 2) for cat in cardinality]\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/TPKModel/#tpk.torch.tpk.module.TPKModel.num_feat_dynamic_real","title":"num_feat_dynamic_real  <code>instance-attribute</code>","text":"<pre><code>num_feat_dynamic_real = num_feat_dynamic_real\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/TPKModel/#tpk.torch.tpk.module.TPKModel.num_feat_static_cat","title":"num_feat_static_cat  <code>instance-attribute</code>","text":"<pre><code>num_feat_static_cat = num_feat_static_cat\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/TPKModel/#tpk.torch.tpk.module.TPKModel.num_feat_static_real","title":"num_feat_static_real  <code>instance-attribute</code>","text":"<pre><code>num_feat_static_real = num_feat_static_real\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/TPKModel/#tpk.torch.tpk.module.TPKModel.num_future_feat","title":"num_future_feat  <code>instance-attribute</code>","text":"<pre><code>num_future_feat = num_future_feat\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/TPKModel/#tpk.torch.tpk.module.TPKModel.past_length","title":"past_length  <code>instance-attribute</code>","text":"<pre><code>past_length = self.context_length\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/TPKModel/#tpk.torch.tpk.module.TPKModel.prediction_length","title":"prediction_length  <code>instance-attribute</code>","text":"<pre><code>prediction_length = prediction_length\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/TPKModel/#tpk.torch.tpk.module.TPKModel.scaler","title":"scaler  <code>instance-attribute</code>","text":"<pre><code>scaler = MeanScaler(dim=-1, keepdim=True)\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/TPKModel/#tpk.torch.tpk.module.TPKModel.tsmixer_encoder","title":"tsmixer_encoder  <code>instance-attribute</code>","text":"<pre><code>tsmixer_encoder = TPKEncoder(input_len=context_length, output_len=prediction_length, past_feat_size=self.num_feat_dynamic_real + 1, future_feat_size=max(1, self.num_future_feat), static_feat_size=sum(self.embedding_dimension) + num_feat_static_real + 1, activation='relu', dropout=dropout_rate, n_block=n_block, hidden_size=hidden_size)\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/TPKModel/#tpk.torch.tpk.module.TPKModel.forward","title":"forward","text":"<pre><code>forward(feat_static_cat: torch.Tensor, feat_static_real: torch.Tensor, past_time_feat: torch.Tensor, past_target: torch.Tensor, past_observed_values: torch.Tensor, future_time_feat: torch.Tensor) -&gt; Tuple[Any, torch.Tensor, Any]\n</code></pre> <p>Invokes the model on input data, and produce outputs future samples.</p>"},{"location":"api/tpk/torch/tpk/module/TPKModel/#tpk.torch.tpk.module.TPKModel.forward--parameters","title":"Parameters","text":"<p>feat_static_cat     Tensor of static categorical features,     shape: <code>(batch_size, num_feat_static_cat)</code>. feat_static_real     Tensor of static real features,     shape: <code>(batch_size, num_feat_static_real)</code>. past_time_feat     Tensor of dynamic real features in the past,     shape: <code>(batch_size, past_length, num_feat_dynamic_real)</code>. past_target     Tensor of past target values,     shape: <code>(batch_size, past_length)</code>. past_observed_values     Tensor of observed values indicators,     shape: <code>(batch_size, past_length)</code>. future_time_feat     (Optional) tensor of dynamic real features in the past,     shape: <code>(batch_size, prediction_length, num_feat_dynamic_real)</code>.</p> Source code in <code>tpk/torch/tpk/module.py</code> <pre><code>def forward(\n    self,\n    feat_static_cat: torch.Tensor,\n    feat_static_real: torch.Tensor,\n    past_time_feat: torch.Tensor,\n    past_target: torch.Tensor,\n    past_observed_values: torch.Tensor,\n    future_time_feat: torch.Tensor,\n) -&gt; Tuple[Any, torch.Tensor, Any]:\n    \"\"\"\n    Invokes the model on input data, and produce outputs future samples.\n\n    Parameters\n    ----------\n    feat_static_cat\n        Tensor of static categorical features,\n        shape: ``(batch_size, num_feat_static_cat)``.\n    feat_static_real\n        Tensor of static real features,\n        shape: ``(batch_size, num_feat_static_real)``.\n    past_time_feat\n        Tensor of dynamic real features in the past,\n        shape: ``(batch_size, past_length, num_feat_dynamic_real)``.\n    past_target\n        Tensor of past target values,\n        shape: ``(batch_size, past_length)``.\n    past_observed_values\n        Tensor of observed values indicators,\n        shape: ``(batch_size, past_length)``.\n    future_time_feat\n        (Optional) tensor of dynamic real features in the past,\n        shape: ``(batch_size, prediction_length, num_feat_dynamic_real)``.\n    \"\"\"\n    if self.num_future_feat == 0:\n        future_time_feat = torch.zeros_like(future_time_feat)[:, :, [0]]\n    else:\n        future_time_feat = future_time_feat[:, :, : self.num_future_feat]\n    _, _, scale = self.scaler(past_target, past_observed_values)\n\n    scaled_past_target = past_target / scale\n\n    embedded_cat = self.embedder(feat_static_cat)\n    static_feat = torch.cat(\n        (embedded_cat, feat_static_real, scale.log()),\n        dim=-1,\n    )\n    past_feature = torch.cat(\n        (scaled_past_target.unsqueeze(-1), past_time_feat), dim=-1\n    )\n    output = self.tsmixer_encoder(past_feature, future_time_feat, static_feat)\n    distr_args = self.args_proj(output)\n    return distr_args, torch.zeros_like(scale), scale\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/TPKModel/#tpk.torch.tpk.module.TPKModel.input_shapes","title":"input_shapes","text":"<pre><code>input_shapes(batch_size: int = 1) -&gt; Dict[str, Tuple[int, ...]]\n</code></pre> Source code in <code>tpk/torch/tpk/module.py</code> <pre><code>def input_shapes(self, batch_size: int = 1) -&gt; Dict[str, Tuple[int, ...]]:\n    return {\n        \"feat_static_cat\": (batch_size, self.num_feat_static_cat),\n        \"feat_static_real\": (batch_size, self.num_feat_static_real),\n        \"past_time_feat\": (\n            batch_size,\n            self._past_length,\n            self.num_feat_dynamic_real,\n        ),\n        \"past_target\": (batch_size, self._past_length),\n        \"past_observed_values\": (batch_size, self._past_length),\n        \"future_time_feat\": (\n            batch_size,\n            self.prediction_length,\n            self.num_feat_dynamic_real,\n        ),\n    }\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/TPKModel/#tpk.torch.tpk.module.TPKModel.input_types","title":"input_types","text":"<pre><code>input_types() -&gt; Dict[str, torch.dtype]\n</code></pre> Source code in <code>tpk/torch/tpk/module.py</code> <pre><code>def input_types(self) -&gt; Dict[str, torch.dtype]:\n    return {\n        \"feat_static_cat\": torch.long,\n        \"feat_static_real\": torch.float,\n        \"past_time_feat\": torch.float,\n        \"past_target\": torch.float,\n        \"past_observed_values\": torch.float,\n        \"future_time_feat\": torch.float,\n    }\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/TemporalLinear/","title":"TemporalLinear","text":""},{"location":"api/tpk/torch/tpk/module/TemporalLinear/#tpk.torch.tpk.module.TemporalLinear","title":"tpk.torch.tpk.module.TemporalLinear","text":"<pre><code>TemporalLinear(input_len: int, output_len: int, activation: Optional[str] = None, dropout: float = 0)\n</code></pre> <p>             Bases: <code>Module</code></p> Source code in <code>tpk/torch/tpk/module.py</code> <pre><code>def __init__(\n    self,\n    input_len: int,\n    output_len: int,\n    activation: Optional[str] = None,\n    dropout: float = 0,\n):\n    super().__init__()\n    self.linear = nn.Linear(in_features=input_len, out_features=output_len)\n    self.activation = None if activation is None else getattr(F, activation)\n    self.dropout = nn.Dropout(p=dropout)\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/TemporalLinear/#tpk.torch.tpk.module.TemporalLinear.activation","title":"activation  <code>instance-attribute</code>","text":"<pre><code>activation = None if activation is None else getattr(F, activation)\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/TemporalLinear/#tpk.torch.tpk.module.TemporalLinear.dropout","title":"dropout  <code>instance-attribute</code>","text":"<pre><code>dropout = nn.Dropout(p=dropout)\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/TemporalLinear/#tpk.torch.tpk.module.TemporalLinear.linear","title":"linear  <code>instance-attribute</code>","text":"<pre><code>linear = nn.Linear(in_features=input_len, out_features=output_len)\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/TemporalLinear/#tpk.torch.tpk.module.TemporalLinear.forward","title":"forward","text":"<pre><code>forward(x: torch.Tensor) -&gt; torch.Tensor\n</code></pre> Source code in <code>tpk/torch/tpk/module.py</code> <pre><code>def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n    x = self.linear(x.permute(0, 2, 1)).permute(0, 2, 1)\n    x = x if self.activation is None else self.activation(x)\n    x = self.dropout(x)\n    return x\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/TemporalResBlock/","title":"TemporalResBlock","text":""},{"location":"api/tpk/torch/tpk/module/TemporalResBlock/#tpk.torch.tpk.module.TemporalResBlock","title":"tpk.torch.tpk.module.TemporalResBlock","text":"<pre><code>TemporalResBlock(input_len: int, input_size: int, activation: Optional[str] = None, dropout: float = 0)\n</code></pre> <p>             Bases: <code>Module</code></p> Source code in <code>tpk/torch/tpk/module.py</code> <pre><code>def __init__(\n    self,\n    input_len: int,\n    input_size: int,\n    activation: Optional[str] = None,\n    dropout: float = 0,\n):\n    super().__init__()\n    self.temporal_linear = TemporalLinear(input_len, input_len, activation, dropout)\n    self.norm = nn.LayerNorm(normalized_shape=[input_len, input_size])\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/TemporalResBlock/#tpk.torch.tpk.module.TemporalResBlock.norm","title":"norm  <code>instance-attribute</code>","text":"<pre><code>norm = nn.LayerNorm(normalized_shape=[input_len, input_size])\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/TemporalResBlock/#tpk.torch.tpk.module.TemporalResBlock.temporal_linear","title":"temporal_linear  <code>instance-attribute</code>","text":"<pre><code>temporal_linear = TemporalLinear(input_len, input_len, activation, dropout)\n</code></pre>"},{"location":"api/tpk/torch/tpk/module/TemporalResBlock/#tpk.torch.tpk.module.TemporalResBlock.forward","title":"forward","text":"<pre><code>forward(x: torch.Tensor) -&gt; torch.Tensor\n</code></pre> Source code in <code>tpk/torch/tpk/module.py</code> <pre><code>def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n    res = x\n    x = self.temporal_linear(x)\n    return self.norm(res + x)  # type: ignore\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/TSMixerModel/","title":"TSMixerModel","text":""},{"location":"api/tpk/torch/tsmixer/TSMixerModel/#tpk.torch.tsmixer.TSMixerModel","title":"tpk.torch.tsmixer.TSMixerModel","text":"<pre><code>TSMixerModel(freq: str, context_length: int, prediction_length: int, num_feat_dynamic_real: int, num_future_feat: int, num_feat_static_real: int, num_feat_static_cat: int, cardinality: List[int], distr_output: DistributionOutput, embedding_dimension: Optional[List[int]] = None, n_block: int = 2, hidden_size: int = 128, dropout_rate: float = 0.1, scaling: bool = True)\n</code></pre> <p>             Bases: <code>Module</code></p> <p>Module implementing the TSMixer model, see [SFG17]_.</p> <p>Note: the code of this model is unrelated to the implementation behind <code>SageMaker's TSMixer Forecasting Algorithm &lt;https://docs.aws.amazon.com/sagemaker/latest/dg/deepar.html&gt;</code>_.</p>"},{"location":"api/tpk/torch/tsmixer/TSMixerModel/#tpk.torch.tsmixer.TSMixerModel--parameters","title":"Parameters","text":"<p>freq     String indicating the sampling frequency of the data to be processed. context_length     Length of the RNN unrolling prior to the forecast date. prediction_length     Number of time points to predict. num_feat_dynamic_real     Number of dynamic real features that will be provided to <code>forward</code>. num_feat_static_real     Number of static real features that will be provided to <code>forward</code>. num_feat_static_cat     Number of static categorical features that will be provided to     <code>forward</code>. cardinality     List of cardinalities, one for each static categorical feature. embedding_dimension     Dimension of the embedding space, one for each static categorical     feature. n_block     Number of layers in the RNN. hidden_size     Size of the hidden layers in the RNN. dropout_rate     Dropout rate to be applied at training time. distr_output     Type of distribution to be output by the model at each time step scaling     Whether to apply mean scaling to the observations (target).</p> Source code in <code>tpk/torch/tsmixer/module.py</code> <pre><code>@validated()  # type: ignore\ndef __init__(\n    self,\n    freq: str,\n    context_length: int,\n    prediction_length: int,\n    num_feat_dynamic_real: int,\n    num_future_feat: int,\n    num_feat_static_real: int,\n    num_feat_static_cat: int,\n    cardinality: List[int],\n    distr_output: DistributionOutput,\n    embedding_dimension: Optional[List[int]] = None,\n    n_block: int = 2,\n    hidden_size: int = 128,\n    dropout_rate: float = 0.1,\n    scaling: bool = True,\n) -&gt; None:\n    super().__init__()\n\n    # assert distr_output.event_shape == ()\n\n    self.context_length = context_length\n    self.prediction_length = prediction_length\n    self.num_feat_dynamic_real = num_feat_dynamic_real\n    self.num_future_feat = num_future_feat\n    self.num_feat_static_cat = num_feat_static_cat\n    self.num_feat_static_real = num_feat_static_real\n    self.embedding_dimension = (\n        embedding_dimension\n        if embedding_dimension is not None or cardinality is None\n        else [min(32, (cat + 1) // 2) for cat in cardinality]\n    )\n    self.past_length = self.context_length\n    self.embedder = FeatureEmbedder(\n        cardinalities=cardinality,\n        embedding_dims=self.embedding_dimension,\n    )\n\n    if scaling:\n        self.scaler = MeanScaler(dim=-1, keepdim=True)\n    else:\n        self.scaler = NOPScaler(dim=-1, keepdim=True)\n\n    self.distr_output = StudentTOutput() if distr_output is None else distr_output\n    self.args_proj = distr_output.get_args_proj(hidden_size)\n\n    self.tsmixer_encoder = TSMixerEncoder(\n        input_len=context_length,\n        output_len=prediction_length,\n        past_feat_size=self.num_feat_dynamic_real + 1,  # target\n        future_feat_size=max(1, self.num_future_feat),\n        static_feat_size=(sum(self.embedding_dimension) + num_feat_static_real + 1),\n        activation=\"relu\",\n        dropout=dropout_rate,\n        n_block=n_block,\n        hidden_size=hidden_size,\n    )\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/TSMixerModel/#tpk.torch.tsmixer.TSMixerModel.args_proj","title":"args_proj  <code>instance-attribute</code>","text":"<pre><code>args_proj = distr_output.get_args_proj(hidden_size)\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/TSMixerModel/#tpk.torch.tsmixer.TSMixerModel.context_length","title":"context_length  <code>instance-attribute</code>","text":"<pre><code>context_length = context_length\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/TSMixerModel/#tpk.torch.tsmixer.TSMixerModel.distr_output","title":"distr_output  <code>instance-attribute</code>","text":"<pre><code>distr_output = StudentTOutput() if distr_output is None else distr_output\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/TSMixerModel/#tpk.torch.tsmixer.TSMixerModel.embedder","title":"embedder  <code>instance-attribute</code>","text":"<pre><code>embedder = FeatureEmbedder(cardinalities=cardinality, embedding_dims=self.embedding_dimension)\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/TSMixerModel/#tpk.torch.tsmixer.TSMixerModel.embedding_dimension","title":"embedding_dimension  <code>instance-attribute</code>","text":"<pre><code>embedding_dimension = embedding_dimension if embedding_dimension is not None or cardinality is None else [min(32, cat + 1 // 2) for cat in cardinality]\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/TSMixerModel/#tpk.torch.tsmixer.TSMixerModel.num_feat_dynamic_real","title":"num_feat_dynamic_real  <code>instance-attribute</code>","text":"<pre><code>num_feat_dynamic_real = num_feat_dynamic_real\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/TSMixerModel/#tpk.torch.tsmixer.TSMixerModel.num_feat_static_cat","title":"num_feat_static_cat  <code>instance-attribute</code>","text":"<pre><code>num_feat_static_cat = num_feat_static_cat\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/TSMixerModel/#tpk.torch.tsmixer.TSMixerModel.num_feat_static_real","title":"num_feat_static_real  <code>instance-attribute</code>","text":"<pre><code>num_feat_static_real = num_feat_static_real\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/TSMixerModel/#tpk.torch.tsmixer.TSMixerModel.num_future_feat","title":"num_future_feat  <code>instance-attribute</code>","text":"<pre><code>num_future_feat = num_future_feat\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/TSMixerModel/#tpk.torch.tsmixer.TSMixerModel.past_length","title":"past_length  <code>instance-attribute</code>","text":"<pre><code>past_length = self.context_length\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/TSMixerModel/#tpk.torch.tsmixer.TSMixerModel.prediction_length","title":"prediction_length  <code>instance-attribute</code>","text":"<pre><code>prediction_length = prediction_length\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/TSMixerModel/#tpk.torch.tsmixer.TSMixerModel.scaler","title":"scaler  <code>instance-attribute</code>","text":"<pre><code>scaler = MeanScaler(dim=-1, keepdim=True)\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/TSMixerModel/#tpk.torch.tsmixer.TSMixerModel.tsmixer_encoder","title":"tsmixer_encoder  <code>instance-attribute</code>","text":"<pre><code>tsmixer_encoder = TSMixerEncoder(input_len=context_length, output_len=prediction_length, past_feat_size=self.num_feat_dynamic_real + 1, future_feat_size=max(1, self.num_future_feat), static_feat_size=sum(self.embedding_dimension) + num_feat_static_real + 1, activation='relu', dropout=dropout_rate, n_block=n_block, hidden_size=hidden_size)\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/TSMixerModel/#tpk.torch.tsmixer.TSMixerModel.forward","title":"forward","text":"<pre><code>forward(feat_static_cat: torch.Tensor, feat_static_real: torch.Tensor, past_time_feat: torch.Tensor, past_target: torch.Tensor, past_observed_values: torch.Tensor, future_time_feat: torch.Tensor) -&gt; Tuple[Any, torch.Tensor, Any]\n</code></pre> <p>Invokes the model on input data, and produce outputs future samples.</p>"},{"location":"api/tpk/torch/tsmixer/TSMixerModel/#tpk.torch.tsmixer.TSMixerModel.forward--parameters","title":"Parameters","text":"<p>feat_static_cat     Tensor of static categorical features,     shape: <code>(batch_size, num_feat_static_cat)</code>. feat_static_real     Tensor of static real features,     shape: <code>(batch_size, num_feat_static_real)</code>. past_time_feat     Tensor of dynamic real features in the past,     shape: <code>(batch_size, past_length, num_feat_dynamic_real)</code>. past_target     Tensor of past target values,     shape: <code>(batch_size, past_length)</code>. past_observed_values     Tensor of observed values indicators,     shape: <code>(batch_size, past_length)</code>. future_time_feat     (Optional) tensor of dynamic real features in the past,     shape: <code>(batch_size, prediction_length, num_feat_dynamic_real)</code>.</p> Source code in <code>tpk/torch/tsmixer/module.py</code> <pre><code>def forward(\n    self,\n    feat_static_cat: torch.Tensor,\n    feat_static_real: torch.Tensor,\n    past_time_feat: torch.Tensor,\n    past_target: torch.Tensor,\n    past_observed_values: torch.Tensor,\n    future_time_feat: torch.Tensor,\n) -&gt; Tuple[Any, torch.Tensor, Any]:\n    \"\"\"\n    Invokes the model on input data, and produce outputs future samples.\n\n    Parameters\n    ----------\n    feat_static_cat\n        Tensor of static categorical features,\n        shape: ``(batch_size, num_feat_static_cat)``.\n    feat_static_real\n        Tensor of static real features,\n        shape: ``(batch_size, num_feat_static_real)``.\n    past_time_feat\n        Tensor of dynamic real features in the past,\n        shape: ``(batch_size, past_length, num_feat_dynamic_real)``.\n    past_target\n        Tensor of past target values,\n        shape: ``(batch_size, past_length)``.\n    past_observed_values\n        Tensor of observed values indicators,\n        shape: ``(batch_size, past_length)``.\n    future_time_feat\n        (Optional) tensor of dynamic real features in the past,\n        shape: ``(batch_size, prediction_length, num_feat_dynamic_real)``.\n    \"\"\"\n    if self.num_future_feat == 0:\n        future_time_feat = torch.zeros_like(future_time_feat)[:, :, [0]]\n    else:\n        future_time_feat = future_time_feat[:, :, : self.num_future_feat]\n    _, _, scale = self.scaler(past_target, past_observed_values)\n\n    scaled_past_target = past_target / scale\n\n    embedded_cat = self.embedder(feat_static_cat)\n    static_feat = torch.cat(\n        (embedded_cat, feat_static_real, scale.log()),\n        dim=-1,\n    )\n    past_feature = torch.cat(\n        (scaled_past_target.unsqueeze(-1), past_time_feat), dim=-1\n    )\n    output = self.tsmixer_encoder(past_feature, future_time_feat, static_feat)\n    distr_args = self.args_proj(output)\n    return distr_args, torch.zeros_like(scale), scale\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/TSMixerModel/#tpk.torch.tsmixer.TSMixerModel.input_shapes","title":"input_shapes","text":"<pre><code>input_shapes(batch_size: int = 1) -&gt; Dict[str, Tuple[int, ...]]\n</code></pre> Source code in <code>tpk/torch/tsmixer/module.py</code> <pre><code>def input_shapes(self, batch_size: int = 1) -&gt; Dict[str, Tuple[int, ...]]:\n    return {\n        \"feat_static_cat\": (batch_size, self.num_feat_static_cat),\n        \"feat_static_real\": (batch_size, self.num_feat_static_real),\n        \"past_time_feat\": (\n            batch_size,\n            self._past_length,\n            self.num_feat_dynamic_real,\n        ),\n        \"past_target\": (batch_size, self._past_length),\n        \"past_observed_values\": (batch_size, self._past_length),\n        \"future_time_feat\": (\n            batch_size,\n            self.prediction_length,\n            self.num_feat_dynamic_real,\n        ),\n    }\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/TSMixerModel/#tpk.torch.tsmixer.TSMixerModel.input_types","title":"input_types","text":"<pre><code>input_types() -&gt; Dict[str, torch.dtype]\n</code></pre> Source code in <code>tpk/torch/tsmixer/module.py</code> <pre><code>def input_types(self) -&gt; Dict[str, torch.dtype]:\n    return {\n        \"feat_static_cat\": torch.long,\n        \"feat_static_real\": torch.float,\n        \"past_time_feat\": torch.float,\n        \"past_target\": torch.float,\n        \"past_observed_values\": torch.float,\n        \"future_time_feat\": torch.float,\n    }\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/ConditionalFeaturalResBlock/","title":"ConditionalFeaturalResBlock","text":""},{"location":"api/tpk/torch/tsmixer/module/ConditionalFeaturalResBlock/#tpk.torch.tsmixer.module.ConditionalFeaturalResBlock","title":"tpk.torch.tsmixer.module.ConditionalFeaturalResBlock","text":"<pre><code>ConditionalFeaturalResBlock(input_len: int, input_size: int, hidden_size: int, output_size: int, static_size: int, activation: str = 'relu', dropout: float = 0)\n</code></pre> <p>             Bases: <code>Module</code></p> Source code in <code>tpk/torch/tsmixer/module.py</code> <pre><code>def __init__(\n    self,\n    input_len: int,\n    input_size: int,\n    hidden_size: int,\n    output_size: int,\n    static_size: int,\n    activation: str = \"relu\",\n    dropout: float = 0,\n):\n    super().__init__()\n    self.input_len = input_len\n    self.static_block = FeaturalResBlock(\n        1, static_size, hidden_size, hidden_size, activation, dropout\n    )\n    self.block = FeaturalResBlock(\n        input_len,\n        input_size + hidden_size,\n        hidden_size,\n        output_size,\n        activation,\n        dropout,\n    )\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/ConditionalFeaturalResBlock/#tpk.torch.tsmixer.module.ConditionalFeaturalResBlock.block","title":"block  <code>instance-attribute</code>","text":"<pre><code>block = FeaturalResBlock(input_len, input_size + hidden_size, hidden_size, output_size, activation, dropout)\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/ConditionalFeaturalResBlock/#tpk.torch.tsmixer.module.ConditionalFeaturalResBlock.input_len","title":"input_len  <code>instance-attribute</code>","text":"<pre><code>input_len = input_len\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/ConditionalFeaturalResBlock/#tpk.torch.tsmixer.module.ConditionalFeaturalResBlock.static_block","title":"static_block  <code>instance-attribute</code>","text":"<pre><code>static_block = FeaturalResBlock(1, static_size, hidden_size, hidden_size, activation, dropout)\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/ConditionalFeaturalResBlock/#tpk.torch.tsmixer.module.ConditionalFeaturalResBlock.forward","title":"forward","text":"<pre><code>forward(x: torch.Tensor, static: torch.Tensor) -&gt; torch.Tensor\n</code></pre> Source code in <code>tpk/torch/tsmixer/module.py</code> <pre><code>def forward(self, x: torch.Tensor, static: torch.Tensor) -&gt; torch.Tensor:\n    static = self.static_block(static.unsqueeze(1))\n    static = torch.repeat_interleave(static, self.input_len, dim=1)\n    x = torch.concat([x, static], dim=2)\n    x = self.block(x)\n    return x\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/ConditionalMixerBlock/","title":"ConditionalMixerBlock","text":""},{"location":"api/tpk/torch/tsmixer/module/ConditionalMixerBlock/#tpk.torch.tsmixer.module.ConditionalMixerBlock","title":"tpk.torch.tsmixer.module.ConditionalMixerBlock","text":"<pre><code>ConditionalMixerBlock(input_len: int, input_size: int, hidden_size: int, output_size: int, static_size: int, activation: str, dropout: float)\n</code></pre> <p>             Bases: <code>Module</code></p> Source code in <code>tpk/torch/tsmixer/module.py</code> <pre><code>def __init__(\n    self,\n    input_len: int,\n    input_size: int,\n    hidden_size: int,\n    output_size: int,\n    static_size: int,\n    activation: str,\n    dropout: float,\n):\n    super().__init__()\n    self.temporal_res_block = TemporalResBlock(\n        input_len, input_size, activation, dropout\n    )\n    self.ffwd_res_block = ConditionalFeaturalResBlock(\n        input_len,\n        input_size,\n        hidden_size,\n        output_size,\n        static_size,\n        activation,\n        dropout,\n    )\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/ConditionalMixerBlock/#tpk.torch.tsmixer.module.ConditionalMixerBlock.ffwd_res_block","title":"ffwd_res_block  <code>instance-attribute</code>","text":"<pre><code>ffwd_res_block = ConditionalFeaturalResBlock(input_len, input_size, hidden_size, output_size, static_size, activation, dropout)\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/ConditionalMixerBlock/#tpk.torch.tsmixer.module.ConditionalMixerBlock.temporal_res_block","title":"temporal_res_block  <code>instance-attribute</code>","text":"<pre><code>temporal_res_block = TemporalResBlock(input_len, input_size, activation, dropout)\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/ConditionalMixerBlock/#tpk.torch.tsmixer.module.ConditionalMixerBlock.forward","title":"forward","text":"<pre><code>forward(x: torch.Tensor, static: torch.Tensor) -&gt; torch.Tensor\n</code></pre> Source code in <code>tpk/torch/tsmixer/module.py</code> <pre><code>def forward(self, x: torch.Tensor, static: torch.Tensor) -&gt; torch.Tensor:\n    x = self.temporal_res_block(x)\n    x = self.ffwd_res_block(x, static)\n    return x\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/FeaturalResBlock/","title":"FeaturalResBlock","text":""},{"location":"api/tpk/torch/tsmixer/module/FeaturalResBlock/#tpk.torch.tsmixer.module.FeaturalResBlock","title":"tpk.torch.tsmixer.module.FeaturalResBlock","text":"<pre><code>FeaturalResBlock(input_len: int, input_size: int, hidden_size: int, output_size: int, activation: str = 'relu', dropout: float = 0)\n</code></pre> <p>             Bases: <code>Module</code></p> Source code in <code>tpk/torch/tsmixer/module.py</code> <pre><code>def __init__(\n    self,\n    input_len: int,\n    input_size: int,\n    hidden_size: int,\n    output_size: int,\n    activation: str = \"relu\",\n    dropout: float = 0,\n):\n    super().__init__()\n    self.linear1 = nn.Linear(in_features=input_size, out_features=hidden_size)\n    self.linear2 = nn.Linear(in_features=hidden_size, out_features=output_size)\n    self.res_linear = None\n    if input_size != output_size:\n        self.res_linear = nn.Linear(\n            in_features=input_size, out_features=output_size\n        )\n    self.activation = getattr(F, activation)\n    self.dropout = nn.Dropout(p=dropout)\n    self.norm = nn.LayerNorm(normalized_shape=[input_len, output_size])\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/FeaturalResBlock/#tpk.torch.tsmixer.module.FeaturalResBlock.activation","title":"activation  <code>instance-attribute</code>","text":"<pre><code>activation = getattr(F, activation)\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/FeaturalResBlock/#tpk.torch.tsmixer.module.FeaturalResBlock.dropout","title":"dropout  <code>instance-attribute</code>","text":"<pre><code>dropout = nn.Dropout(p=dropout)\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/FeaturalResBlock/#tpk.torch.tsmixer.module.FeaturalResBlock.linear1","title":"linear1  <code>instance-attribute</code>","text":"<pre><code>linear1 = nn.Linear(in_features=input_size, out_features=hidden_size)\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/FeaturalResBlock/#tpk.torch.tsmixer.module.FeaturalResBlock.linear2","title":"linear2  <code>instance-attribute</code>","text":"<pre><code>linear2 = nn.Linear(in_features=hidden_size, out_features=output_size)\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/FeaturalResBlock/#tpk.torch.tsmixer.module.FeaturalResBlock.norm","title":"norm  <code>instance-attribute</code>","text":"<pre><code>norm = nn.LayerNorm(normalized_shape=[input_len, output_size])\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/FeaturalResBlock/#tpk.torch.tsmixer.module.FeaturalResBlock.res_linear","title":"res_linear  <code>instance-attribute</code>","text":"<pre><code>res_linear = None\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/FeaturalResBlock/#tpk.torch.tsmixer.module.FeaturalResBlock.forward","title":"forward","text":"<pre><code>forward(x: torch.Tensor) -&gt; Any\n</code></pre> Source code in <code>tpk/torch/tsmixer/module.py</code> <pre><code>def forward(self, x: torch.Tensor) -&gt; Any:\n    res = x if self.res_linear is None else self.res_linear(x)\n    x = self.linear1(x)\n    x = self.activation(x)\n    x = self.dropout(x)\n    x = self.linear2(x)\n    x = self.dropout(x)\n    return self.norm(res + x)\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/MixerBlock/","title":"MixerBlock","text":""},{"location":"api/tpk/torch/tsmixer/module/MixerBlock/#tpk.torch.tsmixer.module.MixerBlock","title":"tpk.torch.tsmixer.module.MixerBlock","text":"<pre><code>MixerBlock(input_len: int, input_size: int, hidden_size: int, output_size: int, activation: str, dropout: float)\n</code></pre> <p>             Bases: <code>Module</code></p> Source code in <code>tpk/torch/tsmixer/module.py</code> <pre><code>def __init__(\n    self,\n    input_len: int,\n    input_size: int,\n    hidden_size: int,\n    output_size: int,\n    activation: str,\n    dropout: float,\n):\n    super().__init__()\n    self.temporal_res_block = TemporalResBlock(\n        input_len, input_size, activation, dropout\n    )\n    self.ffwd_res_block = FeaturalResBlock(\n        input_len,\n        input_size,\n        hidden_size,\n        output_size,\n        activation,\n        dropout,\n    )\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/MixerBlock/#tpk.torch.tsmixer.module.MixerBlock.ffwd_res_block","title":"ffwd_res_block  <code>instance-attribute</code>","text":"<pre><code>ffwd_res_block = FeaturalResBlock(input_len, input_size, hidden_size, output_size, activation, dropout)\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/MixerBlock/#tpk.torch.tsmixer.module.MixerBlock.temporal_res_block","title":"temporal_res_block  <code>instance-attribute</code>","text":"<pre><code>temporal_res_block = TemporalResBlock(input_len, input_size, activation, dropout)\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/MixerBlock/#tpk.torch.tsmixer.module.MixerBlock.forward","title":"forward","text":"<pre><code>forward(x: torch.Tensor) -&gt; torch.Tensor\n</code></pre> Source code in <code>tpk/torch/tsmixer/module.py</code> <pre><code>def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n    x = self.temporal_res_block(x)\n    x = self.ffwd_res_block(x)\n    return x\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/TSMixerEncoder/","title":"TSMixerEncoder","text":""},{"location":"api/tpk/torch/tsmixer/module/TSMixerEncoder/#tpk.torch.tsmixer.module.TSMixerEncoder","title":"tpk.torch.tsmixer.module.TSMixerEncoder","text":"<pre><code>TSMixerEncoder(input_len: int, output_len: int, past_feat_size: int, future_feat_size: int, static_feat_size: int, hidden_size: int, activation: str, dropout: float, n_block: int = 1)\n</code></pre> <p>             Bases: <code>Module</code></p> Source code in <code>tpk/torch/tsmixer/module.py</code> <pre><code>def __init__(\n    self,\n    input_len: int,\n    output_len: int,\n    past_feat_size: int,\n    future_feat_size: int,\n    static_feat_size: int,\n    hidden_size: int,\n    activation: str,\n    dropout: float,\n    n_block: int = 1,\n):\n    super().__init__()\n    self.past_temporal_linear = TemporalLinear(input_len, output_len)\n    self.past_featural_block = ConditionalFeaturalResBlock(\n        input_len=output_len,\n        input_size=past_feat_size,\n        hidden_size=hidden_size,\n        output_size=hidden_size,\n        static_size=static_feat_size,\n        activation=activation,\n        dropout=dropout,\n    )\n    self.future_featural_block = ConditionalFeaturalResBlock(\n        input_len=output_len,\n        input_size=future_feat_size,\n        hidden_size=hidden_size,\n        output_size=hidden_size,\n        static_size=static_feat_size,\n        activation=activation,\n        dropout=dropout,\n    )\n    self.blocks = nn.ModuleList(\n        [\n            ConditionalMixerBlock(\n                input_len=output_len,\n                input_size=(2 * hidden_size) if i == 0 else hidden_size,\n                hidden_size=hidden_size,\n                output_size=hidden_size,\n                static_size=static_feat_size,\n                activation=activation,\n                dropout=dropout,\n            )\n            for i in range(n_block)\n        ]\n    )\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/TSMixerEncoder/#tpk.torch.tsmixer.module.TSMixerEncoder.blocks","title":"blocks  <code>instance-attribute</code>","text":"<pre><code>blocks = nn.ModuleList([ConditionalMixerBlock(input_len=output_len, input_size=2 * hidden_size if i == 0 else hidden_size, hidden_size=hidden_size, output_size=hidden_size, static_size=static_feat_size, activation=activation, dropout=dropout) for i in range(n_block)])\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/TSMixerEncoder/#tpk.torch.tsmixer.module.TSMixerEncoder.future_featural_block","title":"future_featural_block  <code>instance-attribute</code>","text":"<pre><code>future_featural_block = ConditionalFeaturalResBlock(input_len=output_len, input_size=future_feat_size, hidden_size=hidden_size, output_size=hidden_size, static_size=static_feat_size, activation=activation, dropout=dropout)\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/TSMixerEncoder/#tpk.torch.tsmixer.module.TSMixerEncoder.past_featural_block","title":"past_featural_block  <code>instance-attribute</code>","text":"<pre><code>past_featural_block = ConditionalFeaturalResBlock(input_len=output_len, input_size=past_feat_size, hidden_size=hidden_size, output_size=hidden_size, static_size=static_feat_size, activation=activation, dropout=dropout)\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/TSMixerEncoder/#tpk.torch.tsmixer.module.TSMixerEncoder.past_temporal_linear","title":"past_temporal_linear  <code>instance-attribute</code>","text":"<pre><code>past_temporal_linear = TemporalLinear(input_len, output_len)\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/TSMixerEncoder/#tpk.torch.tsmixer.module.TSMixerEncoder.forward","title":"forward","text":"<pre><code>forward(past_feature: torch.Tensor, future_feature: torch.Tensor, static_feature: torch.Tensor) -&gt; torch.Tensor\n</code></pre> Source code in <code>tpk/torch/tsmixer/module.py</code> <pre><code>def forward(\n    self,\n    past_feature: torch.Tensor,\n    future_feature: torch.Tensor,\n    static_feature: torch.Tensor,\n) -&gt; torch.Tensor:\n    past_feature = self.past_temporal_linear(past_feature)\n    past_feature = self.past_featural_block(past_feature, static_feature)\n    future_feature = self.future_featural_block(future_feature, static_feature)\n    x = torch.cat([past_feature, future_feature], dim=2)\n    for block in self.blocks:\n        x = block(x, static_feature)\n    return x\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/TSMixerModel/","title":"TSMixerModel","text":""},{"location":"api/tpk/torch/tsmixer/module/TSMixerModel/#tpk.torch.tsmixer.module.TSMixerModel","title":"tpk.torch.tsmixer.module.TSMixerModel","text":"<pre><code>TSMixerModel(freq: str, context_length: int, prediction_length: int, num_feat_dynamic_real: int, num_future_feat: int, num_feat_static_real: int, num_feat_static_cat: int, cardinality: List[int], distr_output: DistributionOutput, embedding_dimension: Optional[List[int]] = None, n_block: int = 2, hidden_size: int = 128, dropout_rate: float = 0.1, scaling: bool = True)\n</code></pre> <p>             Bases: <code>Module</code></p> <p>Module implementing the TSMixer model, see [SFG17]_.</p> <p>Note: the code of this model is unrelated to the implementation behind <code>SageMaker's TSMixer Forecasting Algorithm &lt;https://docs.aws.amazon.com/sagemaker/latest/dg/deepar.html&gt;</code>_.</p>"},{"location":"api/tpk/torch/tsmixer/module/TSMixerModel/#tpk.torch.tsmixer.module.TSMixerModel--parameters","title":"Parameters","text":"<p>freq     String indicating the sampling frequency of the data to be processed. context_length     Length of the RNN unrolling prior to the forecast date. prediction_length     Number of time points to predict. num_feat_dynamic_real     Number of dynamic real features that will be provided to <code>forward</code>. num_feat_static_real     Number of static real features that will be provided to <code>forward</code>. num_feat_static_cat     Number of static categorical features that will be provided to     <code>forward</code>. cardinality     List of cardinalities, one for each static categorical feature. embedding_dimension     Dimension of the embedding space, one for each static categorical     feature. n_block     Number of layers in the RNN. hidden_size     Size of the hidden layers in the RNN. dropout_rate     Dropout rate to be applied at training time. distr_output     Type of distribution to be output by the model at each time step scaling     Whether to apply mean scaling to the observations (target).</p> Source code in <code>tpk/torch/tsmixer/module.py</code> <pre><code>@validated()  # type: ignore\ndef __init__(\n    self,\n    freq: str,\n    context_length: int,\n    prediction_length: int,\n    num_feat_dynamic_real: int,\n    num_future_feat: int,\n    num_feat_static_real: int,\n    num_feat_static_cat: int,\n    cardinality: List[int],\n    distr_output: DistributionOutput,\n    embedding_dimension: Optional[List[int]] = None,\n    n_block: int = 2,\n    hidden_size: int = 128,\n    dropout_rate: float = 0.1,\n    scaling: bool = True,\n) -&gt; None:\n    super().__init__()\n\n    # assert distr_output.event_shape == ()\n\n    self.context_length = context_length\n    self.prediction_length = prediction_length\n    self.num_feat_dynamic_real = num_feat_dynamic_real\n    self.num_future_feat = num_future_feat\n    self.num_feat_static_cat = num_feat_static_cat\n    self.num_feat_static_real = num_feat_static_real\n    self.embedding_dimension = (\n        embedding_dimension\n        if embedding_dimension is not None or cardinality is None\n        else [min(32, (cat + 1) // 2) for cat in cardinality]\n    )\n    self.past_length = self.context_length\n    self.embedder = FeatureEmbedder(\n        cardinalities=cardinality,\n        embedding_dims=self.embedding_dimension,\n    )\n\n    if scaling:\n        self.scaler = MeanScaler(dim=-1, keepdim=True)\n    else:\n        self.scaler = NOPScaler(dim=-1, keepdim=True)\n\n    self.distr_output = StudentTOutput() if distr_output is None else distr_output\n    self.args_proj = distr_output.get_args_proj(hidden_size)\n\n    self.tsmixer_encoder = TSMixerEncoder(\n        input_len=context_length,\n        output_len=prediction_length,\n        past_feat_size=self.num_feat_dynamic_real + 1,  # target\n        future_feat_size=max(1, self.num_future_feat),\n        static_feat_size=(sum(self.embedding_dimension) + num_feat_static_real + 1),\n        activation=\"relu\",\n        dropout=dropout_rate,\n        n_block=n_block,\n        hidden_size=hidden_size,\n    )\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/TSMixerModel/#tpk.torch.tsmixer.module.TSMixerModel.args_proj","title":"args_proj  <code>instance-attribute</code>","text":"<pre><code>args_proj = distr_output.get_args_proj(hidden_size)\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/TSMixerModel/#tpk.torch.tsmixer.module.TSMixerModel.context_length","title":"context_length  <code>instance-attribute</code>","text":"<pre><code>context_length = context_length\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/TSMixerModel/#tpk.torch.tsmixer.module.TSMixerModel.distr_output","title":"distr_output  <code>instance-attribute</code>","text":"<pre><code>distr_output = StudentTOutput() if distr_output is None else distr_output\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/TSMixerModel/#tpk.torch.tsmixer.module.TSMixerModel.embedder","title":"embedder  <code>instance-attribute</code>","text":"<pre><code>embedder = FeatureEmbedder(cardinalities=cardinality, embedding_dims=self.embedding_dimension)\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/TSMixerModel/#tpk.torch.tsmixer.module.TSMixerModel.embedding_dimension","title":"embedding_dimension  <code>instance-attribute</code>","text":"<pre><code>embedding_dimension = embedding_dimension if embedding_dimension is not None or cardinality is None else [min(32, cat + 1 // 2) for cat in cardinality]\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/TSMixerModel/#tpk.torch.tsmixer.module.TSMixerModel.num_feat_dynamic_real","title":"num_feat_dynamic_real  <code>instance-attribute</code>","text":"<pre><code>num_feat_dynamic_real = num_feat_dynamic_real\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/TSMixerModel/#tpk.torch.tsmixer.module.TSMixerModel.num_feat_static_cat","title":"num_feat_static_cat  <code>instance-attribute</code>","text":"<pre><code>num_feat_static_cat = num_feat_static_cat\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/TSMixerModel/#tpk.torch.tsmixer.module.TSMixerModel.num_feat_static_real","title":"num_feat_static_real  <code>instance-attribute</code>","text":"<pre><code>num_feat_static_real = num_feat_static_real\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/TSMixerModel/#tpk.torch.tsmixer.module.TSMixerModel.num_future_feat","title":"num_future_feat  <code>instance-attribute</code>","text":"<pre><code>num_future_feat = num_future_feat\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/TSMixerModel/#tpk.torch.tsmixer.module.TSMixerModel.past_length","title":"past_length  <code>instance-attribute</code>","text":"<pre><code>past_length = self.context_length\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/TSMixerModel/#tpk.torch.tsmixer.module.TSMixerModel.prediction_length","title":"prediction_length  <code>instance-attribute</code>","text":"<pre><code>prediction_length = prediction_length\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/TSMixerModel/#tpk.torch.tsmixer.module.TSMixerModel.scaler","title":"scaler  <code>instance-attribute</code>","text":"<pre><code>scaler = MeanScaler(dim=-1, keepdim=True)\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/TSMixerModel/#tpk.torch.tsmixer.module.TSMixerModel.tsmixer_encoder","title":"tsmixer_encoder  <code>instance-attribute</code>","text":"<pre><code>tsmixer_encoder = TSMixerEncoder(input_len=context_length, output_len=prediction_length, past_feat_size=self.num_feat_dynamic_real + 1, future_feat_size=max(1, self.num_future_feat), static_feat_size=sum(self.embedding_dimension) + num_feat_static_real + 1, activation='relu', dropout=dropout_rate, n_block=n_block, hidden_size=hidden_size)\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/TSMixerModel/#tpk.torch.tsmixer.module.TSMixerModel.forward","title":"forward","text":"<pre><code>forward(feat_static_cat: torch.Tensor, feat_static_real: torch.Tensor, past_time_feat: torch.Tensor, past_target: torch.Tensor, past_observed_values: torch.Tensor, future_time_feat: torch.Tensor) -&gt; Tuple[Any, torch.Tensor, Any]\n</code></pre> <p>Invokes the model on input data, and produce outputs future samples.</p>"},{"location":"api/tpk/torch/tsmixer/module/TSMixerModel/#tpk.torch.tsmixer.module.TSMixerModel.forward--parameters","title":"Parameters","text":"<p>feat_static_cat     Tensor of static categorical features,     shape: <code>(batch_size, num_feat_static_cat)</code>. feat_static_real     Tensor of static real features,     shape: <code>(batch_size, num_feat_static_real)</code>. past_time_feat     Tensor of dynamic real features in the past,     shape: <code>(batch_size, past_length, num_feat_dynamic_real)</code>. past_target     Tensor of past target values,     shape: <code>(batch_size, past_length)</code>. past_observed_values     Tensor of observed values indicators,     shape: <code>(batch_size, past_length)</code>. future_time_feat     (Optional) tensor of dynamic real features in the past,     shape: <code>(batch_size, prediction_length, num_feat_dynamic_real)</code>.</p> Source code in <code>tpk/torch/tsmixer/module.py</code> <pre><code>def forward(\n    self,\n    feat_static_cat: torch.Tensor,\n    feat_static_real: torch.Tensor,\n    past_time_feat: torch.Tensor,\n    past_target: torch.Tensor,\n    past_observed_values: torch.Tensor,\n    future_time_feat: torch.Tensor,\n) -&gt; Tuple[Any, torch.Tensor, Any]:\n    \"\"\"\n    Invokes the model on input data, and produce outputs future samples.\n\n    Parameters\n    ----------\n    feat_static_cat\n        Tensor of static categorical features,\n        shape: ``(batch_size, num_feat_static_cat)``.\n    feat_static_real\n        Tensor of static real features,\n        shape: ``(batch_size, num_feat_static_real)``.\n    past_time_feat\n        Tensor of dynamic real features in the past,\n        shape: ``(batch_size, past_length, num_feat_dynamic_real)``.\n    past_target\n        Tensor of past target values,\n        shape: ``(batch_size, past_length)``.\n    past_observed_values\n        Tensor of observed values indicators,\n        shape: ``(batch_size, past_length)``.\n    future_time_feat\n        (Optional) tensor of dynamic real features in the past,\n        shape: ``(batch_size, prediction_length, num_feat_dynamic_real)``.\n    \"\"\"\n    if self.num_future_feat == 0:\n        future_time_feat = torch.zeros_like(future_time_feat)[:, :, [0]]\n    else:\n        future_time_feat = future_time_feat[:, :, : self.num_future_feat]\n    _, _, scale = self.scaler(past_target, past_observed_values)\n\n    scaled_past_target = past_target / scale\n\n    embedded_cat = self.embedder(feat_static_cat)\n    static_feat = torch.cat(\n        (embedded_cat, feat_static_real, scale.log()),\n        dim=-1,\n    )\n    past_feature = torch.cat(\n        (scaled_past_target.unsqueeze(-1), past_time_feat), dim=-1\n    )\n    output = self.tsmixer_encoder(past_feature, future_time_feat, static_feat)\n    distr_args = self.args_proj(output)\n    return distr_args, torch.zeros_like(scale), scale\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/TSMixerModel/#tpk.torch.tsmixer.module.TSMixerModel.input_shapes","title":"input_shapes","text":"<pre><code>input_shapes(batch_size: int = 1) -&gt; Dict[str, Tuple[int, ...]]\n</code></pre> Source code in <code>tpk/torch/tsmixer/module.py</code> <pre><code>def input_shapes(self, batch_size: int = 1) -&gt; Dict[str, Tuple[int, ...]]:\n    return {\n        \"feat_static_cat\": (batch_size, self.num_feat_static_cat),\n        \"feat_static_real\": (batch_size, self.num_feat_static_real),\n        \"past_time_feat\": (\n            batch_size,\n            self._past_length,\n            self.num_feat_dynamic_real,\n        ),\n        \"past_target\": (batch_size, self._past_length),\n        \"past_observed_values\": (batch_size, self._past_length),\n        \"future_time_feat\": (\n            batch_size,\n            self.prediction_length,\n            self.num_feat_dynamic_real,\n        ),\n    }\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/TSMixerModel/#tpk.torch.tsmixer.module.TSMixerModel.input_types","title":"input_types","text":"<pre><code>input_types() -&gt; Dict[str, torch.dtype]\n</code></pre> Source code in <code>tpk/torch/tsmixer/module.py</code> <pre><code>def input_types(self) -&gt; Dict[str, torch.dtype]:\n    return {\n        \"feat_static_cat\": torch.long,\n        \"feat_static_real\": torch.float,\n        \"past_time_feat\": torch.float,\n        \"past_target\": torch.float,\n        \"past_observed_values\": torch.float,\n        \"future_time_feat\": torch.float,\n    }\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/TemporalLinear/","title":"TemporalLinear","text":""},{"location":"api/tpk/torch/tsmixer/module/TemporalLinear/#tpk.torch.tsmixer.module.TemporalLinear","title":"tpk.torch.tsmixer.module.TemporalLinear","text":"<pre><code>TemporalLinear(input_len: int, output_len: int, activation: Optional[str] = None, dropout: float = 0)\n</code></pre> <p>             Bases: <code>Module</code></p> Source code in <code>tpk/torch/tsmixer/module.py</code> <pre><code>def __init__(\n    self,\n    input_len: int,\n    output_len: int,\n    activation: Optional[str] = None,\n    dropout: float = 0,\n):\n    super().__init__()\n    self.linear = nn.Linear(in_features=input_len, out_features=output_len)\n    self.activation = None if activation is None else getattr(F, activation)\n    self.dropout = nn.Dropout(p=dropout)\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/TemporalLinear/#tpk.torch.tsmixer.module.TemporalLinear.activation","title":"activation  <code>instance-attribute</code>","text":"<pre><code>activation = None if activation is None else getattr(F, activation)\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/TemporalLinear/#tpk.torch.tsmixer.module.TemporalLinear.dropout","title":"dropout  <code>instance-attribute</code>","text":"<pre><code>dropout = nn.Dropout(p=dropout)\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/TemporalLinear/#tpk.torch.tsmixer.module.TemporalLinear.linear","title":"linear  <code>instance-attribute</code>","text":"<pre><code>linear = nn.Linear(in_features=input_len, out_features=output_len)\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/TemporalLinear/#tpk.torch.tsmixer.module.TemporalLinear.forward","title":"forward","text":"<pre><code>forward(x: torch.Tensor) -&gt; torch.Tensor\n</code></pre> Source code in <code>tpk/torch/tsmixer/module.py</code> <pre><code>def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n    x = self.linear(x.permute(0, 2, 1)).permute(0, 2, 1)\n    x = x if self.activation is None else self.activation(x)\n    x = self.dropout(x)\n    return x\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/TemporalResBlock/","title":"TemporalResBlock","text":""},{"location":"api/tpk/torch/tsmixer/module/TemporalResBlock/#tpk.torch.tsmixer.module.TemporalResBlock","title":"tpk.torch.tsmixer.module.TemporalResBlock","text":"<pre><code>TemporalResBlock(input_len: int, input_size: int, activation: Optional[str] = None, dropout: float = 0)\n</code></pre> <p>             Bases: <code>Module</code></p> Source code in <code>tpk/torch/tsmixer/module.py</code> <pre><code>def __init__(\n    self,\n    input_len: int,\n    input_size: int,\n    activation: Optional[str] = None,\n    dropout: float = 0,\n):\n    super().__init__()\n    self.temporal_linear = TemporalLinear(input_len, input_len, activation, dropout)\n    self.norm = nn.LayerNorm(normalized_shape=[input_len, input_size])\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/TemporalResBlock/#tpk.torch.tsmixer.module.TemporalResBlock.norm","title":"norm  <code>instance-attribute</code>","text":"<pre><code>norm = nn.LayerNorm(normalized_shape=[input_len, input_size])\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/TemporalResBlock/#tpk.torch.tsmixer.module.TemporalResBlock.temporal_linear","title":"temporal_linear  <code>instance-attribute</code>","text":"<pre><code>temporal_linear = TemporalLinear(input_len, input_len, activation, dropout)\n</code></pre>"},{"location":"api/tpk/torch/tsmixer/module/TemporalResBlock/#tpk.torch.tsmixer.module.TemporalResBlock.forward","title":"forward","text":"<pre><code>forward(x: torch.Tensor) -&gt; torch.Tensor\n</code></pre> Source code in <code>tpk/torch/tsmixer/module.py</code> <pre><code>def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n    res = x\n    x = self.temporal_linear(x)\n    return self.norm(res + x)  # type: ignore\n</code></pre>"},{"location":"api/tpk/utils/dataset/DownloadProgressBar/","title":"DownloadProgressBar","text":""},{"location":"api/tpk/utils/dataset/DownloadProgressBar/#tpk.utils.dataset.DownloadProgressBar","title":"tpk.utils.dataset.DownloadProgressBar","text":"<p>             Bases: <code>tqdm</code></p>"},{"location":"api/tpk/utils/dataset/DownloadProgressBar/#tpk.utils.dataset.DownloadProgressBar.update_to","title":"update_to","text":"<pre><code>update_to(b: int = 1, bsize: int = 1, tsize: Optional[int] = None) -&gt; None\n</code></pre> Source code in <code>tpk/utils/dataset.py</code> <pre><code>def update_to(\n    self, b: int = 1, bsize: int = 1, tsize: Optional[int] = None\n) -&gt; None:\n    if tsize is not None:\n        self.total = tsize\n    self.update(b * bsize - self.n)\n</code></pre>"},{"location":"api/tpk/utils/dataset/download_datasets/","title":"Download datasets","text":""},{"location":"api/tpk/utils/dataset/download_datasets/#tpk.utils.dataset.download_datasets","title":"tpk.utils.dataset.download_datasets","text":"<pre><code>download_datasets(*, data_root: Union[Path, str] = 'data', data_sources: Dict[str, List[str]] = data_sources) -&gt; None\n</code></pre> Source code in <code>tpk/utils/dataset.py</code> <pre><code>def download_datasets(\n    *,\n    data_root: Union[Path, str] = \"data\",\n    data_sources: Dict[str, List[str]] = data_sources,\n) -&gt; None:\n    for dataset, urls in data_sources.items():\n        for url in tqdm(urls):\n            filename = Path(data_root) / dataset / url.split(\"/\")[-1].split(\"?\")[0]\n            filename.parent.mkdir(parents=True, exist_ok=True)\n            if not filename.exists():\n                download_url(url, filename)\n            else:\n                print(f\"File {filename} already exists. Skipping download.\")\n    print(\"All files downloaded.\")\n</code></pre>"},{"location":"api/tpk/utils/dataset/download_url/","title":"Download url","text":""},{"location":"api/tpk/utils/dataset/download_url/#tpk.utils.dataset.download_url","title":"tpk.utils.dataset.download_url","text":"<pre><code>download_url(url: str, output_path: Path) -&gt; None\n</code></pre> Source code in <code>tpk/utils/dataset.py</code> <pre><code>def download_url(url: str, output_path: Path) -&gt; None:\n    with DownloadProgressBar(\n        unit=\"B\", unit_scale=True, miniters=1, desc=str(output_path).split(\"/\")[-1]\n    ) as t:\n        # nosemgrep: python.lang.security.audit.dynamic-urllib-use-detected.dynamic-urllib-use-detected\n        urllib.request.urlretrieve(\n            url,\n            filename=output_path,\n            reporthook=t.update_to,  # nosec: [B310:blacklist]\n        )\n</code></pre>"}]}